
@article{aloufi_paralinguistic_2022,
	title = {Paralinguistic Privacy Protection at the Edge},
	issn = {2471-2566},
	url = {https://doi.org/10.1145/3570161},
	doi = {10.1145/3570161},
	abstract = {Voice user interfaces and digital assistants are rapidly entering our lives and becoming singular touch points spanning our devices. These always-on services capture and transmit our audio data to powerful cloud services for further processing and subsequent actions. Our voices and raw audio signals collected through these devices contain a host of sensitive paralinguistic information that is transmitted to service providers regardless of deliberate or false triggers. As our emotional patterns and sensitive attributes like our identity, gender, well-being, are easily inferred using deep acoustic models, we encounter a new generation of privacy risks by using these services. One approach to mitigate the risk of paralinguistic-based privacy breaches is to exploit a combination of cloud-based processing with privacy-preserving, on-device paralinguistic information learning and filtering before transmitting voice data. In this paper we introduce {EDGY}, a configurable, lightweight, disentangled representation learning framework that transforms and filters high-dimensional voice data to identify and contain sensitive attributes at the edge prior to offloading to the cloud. We evaluate {EDGY}’s on-device performance and explore optimization techniques, including model quantization and knowledge distillation, to enable private, accurate and efficient representation learning on resource-constrained devices. Our results show that {EDGY} runs in tens of milliseconds with 0.2\% relative improvement in ‘zero-shot’ {ABX} score or minimal performance penalties of approximately 5.95\% word error rate ({WER}) in learning linguistic representations from raw voice signals, using a {CPU} and a single-core {ARM} processor without specialized hardware.},
	journaltitle = {{ACM} Transactions on Privacy and Security},
	author = {Aloufi, Ranya and Haddadi, Hamed and Boyle, David},
	urldate = {2022-11-21},
	date = {2022-11},
	keywords = {Deep Learning, Disentangled Representation Learning, Internet of Things ({IoT}), Model Optimization, Privacy, Speech Analysis, Voice Synthesis, Voice User Interface},
}

@article{du_scientific_2022,
	title = {Scientific Workflows in {IoT} Environments: A Data Placement Strategy Based on Heterogeneous Edge-Cloud Computing},
	volume = {13},
	issn = {2158-656X},
	url = {https://doi.org/10.1145/3531327},
	doi = {10.1145/3531327},
	shorttitle = {Scientific Workflows in {IoT} Environments},
	abstract = {In Industry 4.0 and Internet of Things ({IoT}) environments, the heterogeneous edge-cloud computing paradigm can provide a more proper solution to deploy scientific workflows compared to cloud computing or other traditional distributed computing. Owing to the different sizes of scientific datasets and the privacy issue concerning some of these datasets, it is essential to find a data placement strategy that can minimize data transmission time. Some state-of-the-art data placement strategies combine edge computing and cloud computing to distribute scientific datasets. However, the dynamic distribution of newly generated datasets to appropriate datacenters and exiting the spent datasets are still a challenge during workflows execution. To address this challenge, this study not only constructs a data placement model that includes shared datasets within the individual and among multiple workflows across various geographical regions, but also proposes a data placement strategy ({DYM}-{RL}-{DPS}) based on algorithms of two stages. First, during the build-time stage of workflows, we use the discrete particle swarm optimization algorithm with differential evolution to pre-allocate initial datasets to proper datacenters. Then, we reformulate the dynamic datasets distribution problem as a Markov decision process and provide a reinforcement learning–based approach to learn the data placement strategy in the runtime stage of scientific workflows. Through using the heterogeneous edge-cloud computing architecture to simulate {IoT} environments, we designed comprehensive experiments to demonstrate the superiority of {DYM}-{RL}-{DPS}. The results of our strategy can effectively reduce the data transmission time as compared to other strategies.},
	pages = {42:1--42:26},
	number = {4},
	journaltitle = {{ACM} Transactions on Management Information Systems},
	author = {Du, Xin and Tang, Songtao and Lu, Zhihui and Gai, Keke and Wu, Jie and Hung, Patrick C. K.},
	urldate = {2022-11-21},
	date = {2022-08},
	keywords = {data-sharing, Heterogeneous edge-cloud computing, {IoT} environments, scientific workflows},
}

@article{shumba_leveraging_2022,
	title = {Leveraging {IoT}-Aware Technologies and {AI} Techniques for Real-Time Critical Healthcare Applications},
	volume = {22},
	pages = {7675},
	number = {19},
	journaltitle = {Sensors},
	author = {Shumba, Angela-Tafadzwa and Montanaro, Teodoro and Sergi, Ilaria and Fachechi, Luca and De Vittorio, Massimo and Patrono, Luigi},
	date = {2022},
}

@inproceedings{acostsa_multi-user_2022,
	title = {Multi-User Privacy with Voice-Controlled Digital Assistants},
	doi = {10.1109/PerComWorkshops53856.2022.9767270},
	abstract = {With the help of Voice-controlled Digital Assistants ({VCDAs}), end users can perform various tasks, such as creating shopping lists, setting reminders, or controlling smart home devices via voice commands. However, in multi-user environments, the different end users of {VCDAs} may not have access to the same controls to protect their privacy. The primary end users who set up {VCDAs} usually have full control over the data collected by {VCDAs}, including text transcripts and audio recordings of the other end users. In order for these secondary end users to gain access to privacy settings, they must also create an account with the appropriate manufacturer and accept an invitation from the primary end user to join the respective {VCDA}. As a result, they depend on the primary end user and the creation of a user account to be able to protect their privacy. Through a user account, however, personal information, such as name, address, or age can be linked to audio recordings, that poses additional privacy risks to secondary end users. For both primary and secondary end users, audio recordings are still maintained on cloud servers operated by manufacturers, resulting in a lack of transparency for all end users. In this paper, we thus propose an approach to improve the protection of both primary and secondary end users that reaches from the device set-up to its utilization. Our approach is based on the concept of a local registration and offline storage of voice commands.},
	pages = {30--33},
	booktitle = {2022 {IEEE} International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events ({PerCom} Workshops)},
	author = {Acostsa, Luca Hernández and Reinhardt, Delphine},
	date = {2022-03},
	keywords = {Privacy, Audio recording, authentication, Conferences, Data privacy, multi-user environment, Performance evaluation, Pervasive computing, privacy, Smart homes, voice assistants},
}

@article{ergun_dynamic_2022,
	title = {Dynamic Reliability Management of Multi-Gateway {IoT} Edge Computing Systems},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2022.3185082},
	abstract = {The emerging paradigm of edge computing envisions to overcome the shortcomings of cloud-centric Internet of Things ({IoT}) by providing data processing and storage capabilities closer to the source of data. Accordingly, {IoT} edge devices, with the increasing demand of computation workloads on them, are prone to failures more than ever. Hard failures in hardware due to aging and reliability degradation are particularly important since they are irrecoverable, requiring maintenance for the replacement of defective parts, at high costs. In this paper, we propose a novel dynamic reliability management ({DRM}) technique for multi-gateway {IoT} edge computing systems to mitigate degradation and defer early hard failures. Taking advantage of the edge computing architecture, we utilize gateways for computation offloading with the primary goal of maximizing the battery lifetime of edge devices, while satisfying the Quality of Service ({QoS}) and reliability requirements. We present a two-level management scheme, which work together to label=(*) choose the offloading rates of edge devices, assign edge devices to gateways, and decide multi-hop data flow routes and rates in the network. The offloading rates are selected by a hierarchical multi-timescale distributed controller. We assign edge devices by solving a bottleneck generalized assignment problem ({BGAP}) and compute optimal flows in a fully-distributed fashion, leveraging the subgradient method. Our results, based on real measurements and trace-driven simulation demonstrate that the proposed scheme can achieve a similar battery lifetime and better {QoS} compared to the state-of-the-art approaches while satisfying reliability requirements, where other approaches fail by a large margin.},
	pages = {1--1},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Ergun, Kazim and Ayoub, Raid and Mercati, Pietro and Rosing, Tajana},
	date = {2022},
	keywords = {Batteries, computation offloading, constrained devices, Degradation, device management, Edge computing, Internet of Things, Logic gates, optimization and control, Quality of service, Reliability},
}

@article{gutierrez-torre_automatic_2022,
	title = {Automatic Distributed Deep Learning Using Resource-Constrained Edge Devices},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3098973},
	abstract = {Processing data generated at high volume and speed from the Internet of Things, smart cities, domotic, intelligent surveillance, and e-healthcare systems require efficient data processing and analytics services at the Edge to reduce the latency and response time of the applications. The fog computing edge infrastructure consists of devices with limited computing, memory, and bandwidth resources, which challenge the construction of predictive analytics solutions that require resource-intensive tasks for training machine learning models. In this work, we focus on the development of predictive analytics for urban traffic. Our solution is based on deep learning techniques localized in the Edge, where computing devices have very limited computational resources. We present an innovative method for efficiently training the gated recurrent-units ({GRUs}) across available resource-constrained {CPU} and {GPU} Edge devices. Our solution employs distributed {GRU} model learning and dynamically stops the training process to utilize the low-power and resource-constrained Edge devices while ensuring good estimation accuracy effectively. The proposed solution was extensively evaluated using low-powered {ARM}-based devices, including Raspberry Pi v3 and the low-powered {GPU}-enabled device {NVIDIA} Jetson Nano, and also compared them with Single-{CPU} Intel Xeon machines. For the evaluation experiments, we used real-world Floating Car Data. The experiments show that the proposed solution delivers excellent prediction accuracy and computational performance on the Edge when compared to the baseline methods.},
	pages = {15018--15029},
	number = {16},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Gutierrez-Torre, Alberto and Bahadori, Kiyana and Baig, Shuja-Ur-Rehman and Iqbal, Waheed and Vardanega, Tullio and Berral, Josep Lluís and Carrera, David},
	date = {2022-08},
	keywords = {Internet of Things ({IoT}), Internet of Things, Analytics, big data, cloud computing, Computational modeling, Data models, Deep learning, edge computing, fog computing, Neural networks, resource management, Smart cities, Training},
}

@article{gomez-carmona_optimizing_2022,
	title = {Optimizing Computational Resources for Edge Intelligence Through Model Cascade Strategies},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3118845},
	abstract = {As the number of interconnected devices increases and more artificial intelligence ({AI}) applications upon the Internet of Things ({IoT}) start to flourish, so does the environmental cost of the computational resources needed to send and process all the generated data. Therefore, promoting the optimization of {AI} applications is a key factor for the sustainable development of {IoT} solutions. Paradigms such as Edge Computing are progressively proposed as a solution in the {IoT} field, becoming an alternative to delegate all the computation to the Cloud. However, bringing the computation to the local stage is limited by the resources’ availability of the devices hosted at the Edge of the network. For this reason, this work presents an approach that simplifies the complexity of supervised learning algorithms at the Edge. Specifically, it separates complex models into multiple simpler classifiers forming a cascade of discriminative models. The suitability of this proposal in a human activity recognition ({HAR}) context is assessed by comparing the performance of three different variations of this strategy. Furthermore, its computational cost is analyzed in several resource-constrained Edge devices in terms of processing time. The experimental results show the viability of this approach to outperform other ensemble methods, i.e., the Stacking technique. Moreover, it substantially reduces the computational cost of the classification tasks by more than 60\% without a significant accuracy loss (around 3.5\%). This highlights the potential of this strategy to reduce resource and energy requirements in {IoT} architectures and promote more efficient and sustainable classification solutions.},
	pages = {7404--7417},
	number = {10},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Gómez-Carmona, Oihane and Casado-Mansilla, Diego and López-de-Ipiña, Diego and García-Zubia, Javier},
	date = {2022-05},
	keywords = {Internet of Things ({IoT}), Edge computing, Internet of Things, Computational modeling, Cloud computing, edge intelligence, embedded systems, ensemble learning, machine learning ({ML}), optimization, Optimization, Predictive models, Sustainable development, Task analysis},
}

@article{frasser_fully_2022,
	title = {Fully Parallel Stochastic Computing Hardware Implementation of Convolutional Neural Networks for Edge Computing Applications},
	issn = {2162-2388},
	doi = {10.1109/TNNLS.2022.3166799},
	abstract = {Edge artificial intelligence ({AI}) is receiving a tremendous amount of interest from the machine learning community due to the ever-increasing popularization of the Internet of Things ({IoT}). Unfortunately, the incorporation of {AI} characteristics to edge computing devices presents the drawbacks of being power and area hungry for typical deep learning techniques such as convolutional neural networks ({CNNs}). In this work, we propose a power-and-area efficient architecture based on the exploitation of the correlation phenomenon in stochastic computing ({SC}) systems. The proposed architecture solves the challenges that a {CNN} implementation with {SC} ({SC}-{CNN}) may present, such as the high resources used in binary-to-stochastic conversion, the inaccuracy produced by undesired correlation between signals, and the complexity of the stochastic maximum function implementation. To prove that our architecture meets the requirements of edge intelligence realization, we embed a fully parallel {CNN} in a single field-programmable gate array ({FPGA}) chip. The results obtained showed a better performance than traditional binary logic and other {SC} implementations. In addition, we performed a full {VLSI} synthesis of the proposed design, showing that it presents better overall characteristics than other recently published {VLSI} architectures.},
	pages = {1--11},
	journaltitle = {{IEEE} Transactions on Neural Networks and Learning Systems},
	author = {Frasser, Christiam F. and Linares-Serrano, Pablo and de los Ríos, Iván Díez and Morán, Alejandro and Skibinsky-Gitlin, Erik S. and Font-Rosselló, Joan and Canals, Vincent and Roca, Miquel and Serrano-Gotarredona, Teresa and Rosselló, Josep L.},
	date = {2022},
	keywords = {Internet of Things, Logic gates, Computer architecture, Convolutional neural networks, Convolutional neural networks ({CNNs}), Correlation, edge computing ({EC}), Europe, Hardware, stochastic computing ({SC}).},
}

@article{zhu_federated_2022,
	title = {Federated Multiagent Actor–Critic Learning for Age Sensitive Mobile-Edge Computing},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3078514},
	abstract = {As an emerging technique, mobile-edge computing ({MEC}) introduces a new scheme for various distributed communication-computing systems, such as industrial Internet of Things ({IoT}), vehicular communication, smart city, etc. In this work, we mainly focus on the timeliness of the {MEC} systems where the freshness of the data and computation tasks is significant. First, we formulate a kind of age-sensitive {MEC} models and define the average Age-of-Information ({AoI}) minimization problems of interests. Then, a novel mixed-policy-based multimodal deep reinforcement learning ({RL}) framework, called heterogeneous multiagent actor–critic (H-{MAAC}), is proposed as a paradigm for joint collaboration in the investigated {MEC} systems, where edge devices and center controller learn the interactive strategies through their own observations. To improve the system performance, we develop the corresponding online algorithm by introducing the edge federated learning mode into the multiagent cooperation whose advantages on learning convergence can be guaranteed theoretically. To the best of our knowledge, it is the first joint {MEC} collaboration algorithm that combines the edge federated mode with the multiagent actor–critic {RL}. Furthermore, we evaluate the proposed approach and compare it with popular {RL}-based methods. As a result, the proposed algorithm not only outperforms the baselines on average system age, but also promotes the stability of training process. Besides, the simulation outcomes provide several insights for collaboration designs over {MEC} systems.},
	pages = {1053--1067},
	number = {2},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Zhu, Zheqi and Wan, Shuo and Fan, Pingyi and Letaief, Khaled B.},
	date = {2022-01},
	keywords = {Edge computing, Computational modeling, Data models, Task analysis, Collaboration, Distributed databases, Federated learning ({FL}), joint collaboration, mixed policies, mobile-edge computing ({MEC}), multiagent deep reinforcement learning ({RL}), multimodal learning, Reinforcement learning},
}

@article{zheng_distributed_2022,
	title = {Distributed and Privacy Preserving Graph Data Collection in Internet of Thing Systems},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3112186},
	abstract = {Internet of Thing ({IoT}) systems have been treated as a novel platform for graph data acquisition. Contents like dynamic network topology, organization and control flows, and interactions among monitored objects all contribute to the huge volumes of graph data generated in {IoT}. These data are believed to brought significant benefits to both the operation and functionalities of {IoT} systems, especially when combined with cutting-edge Artificial Intelligence techniques. However, these graph data are usually locally collected by data contributors with sensing devices, which could be both partially overlapped as they record same environment, and sensitive as they can indicate private physical status of contributors. Considering all challenges, current solutions for graph data collection in {IoT} are incapable. Therefore, this article proposes a novel framework for privacy-preserving distributed graph data collection for {IoT}. The framework allows the graphs kept by data contributors to be partially overlapped, and can help the data broker to efficiently derive the universal view by combining these graphs. The differential privacy is applied for privacy preservation during data collection. The proposed problem aims at minimizing the total bandwidth consumption for graph collection, which is proved to be {NP}-complete. Then three algorithms are proposed for different circumstances, based on the diverse knowledge and purposes held by the data broker. Finally, both theoretical and numerical analysis have demonstrated the advancement of these methods.},
	pages = {9301--9309},
	number = {12},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Zheng, Xu and Tian, Ling and Hui, Bei and Liu, Xin},
	date = {2022-06},
	keywords = {Internet of Things ({IoT}), Internet of Things, Data models, Distributed databases, Data collection, Distributed data processing, graph data collection, Monitoring, Network topology, privacy preservation, Sensors},
}

@inproceedings{saadat_rl-assisted_2022,
	title = {{RL}-Assisted Energy-Aware User-Edge Association for {IoT}-based Hierarchical Federated Learning},
	doi = {10.1109/IWCMC55113.2022.9824994},
	abstract = {The extremely heavy global reliance on {IoT} devices is causing enormous amounts of data to be gathered and shared in {IoT} networks. Such data need to efficiently be used in training and deploying of powerful artificially intelligent models for better future event detection and decision making. However, {IoT} devices suffer from many limitations regarding their energy budget, computational power, and storage space. Therefore, efficient solutions have to be studied and proposed for addressing these limitations. In this paper, we propose an energy-efficient Hierarchical Federated Learning ({HFL}) framework with optimized client-edge association and resource allocation. This was done by formulating and solving a communication energy minimization problem that takes into consideration the data distribution of the clients and the communication latency between the clients and edges. We also implement an alternative less complex solution leveraging Reinforcement Learning ({RL}) that provides a fast user-edge association and resource allocation response in highly dynamic {HFL} networks. The proposed two solutions are compared with several state-of-the-art client-edge association techniques, leveraging {MNIST} dataset. Moreover, we study the trade-off between minimizing the per-round energy consumption and Kullback-Leibler Divergence ({KLD}) of the data distribution, and its effect on the total energy consumption.},
	pages = {548--553},
	booktitle = {2022 International Wireless Communications and Mobile Computing ({IWCMC})},
	author = {Saadat, Hassan and Allahham, Mhd Saria and Abdellatif, Alaa Awad and Erbad, Aiman and Mohamed, Amr},
	date = {2022-05},
	keywords = {Training, Reinforcement learning, Collaborative work, Energy consumption, Energy efficiency, Energy minimization, Hierarchical federated learning, Internet of things, Minimization, Resource allocation, Wireless communication},
}

@inproceedings{shi_query_2022,
	title = {Query Recombination: To Process a Large Number of Concurrent Top-k Queries towards {IoT} Data on an Edge Server},
	doi = {10.1109/ICDCS54860.2022.00060},
	abstract = {Multi-access Edge Computing is an important technique in the Internet of Things ({IoT}). It can help people observe the physical world by caching {IoT} data at an edge server and provide data query services. In this paper, we investigate how to process numerous concurrent top-k queries on an edge server. Since the computation resource of an edge server is limited and costly, processing concurrent top-k queries in the edge is totally different from that in the cloud. Researchers always focus on reducing time/space complexity of processing single top-k query in the cloud. However, how to process numerous top-k queries on an edge server in a cost-efficient manner still remains an open problem. In order to solve the problem, we propose the query recombination concept which aims at using the correlation of queries to reduce resource consumption of query processing. By adopting query recombination, we can make use of a small set of queries to answer the other queries and reduce resource consumption as well. We prove that constructing an optimal query recombination is {NP}-hard. Three approximate algorithms are proposed accordingly. Simulations are carried out to evaluate the performance of the proposed algorithms further, and the results show that the proposed algorithms are effective and efficient.},
	pages = {559--569},
	booktitle = {2022 {IEEE} 42nd International Conference on Distributed Computing Systems ({ICDCS})},
	author = {Shi, Tuo and Cai, Zhipeng and Li, Yingshu},
	date = {2022-07},
	keywords = {Cloud computing, Correlation, Approximation algorithms, Costs, Multi-access edge computing, Query processing, Simulation},
}

@inproceedings{babou_hec-nervenet_2022,
	title = {{HEC}-{NerveNet}: A Resilient Edge Cloud Architecture for Beyond 5G Networks},
	doi = {10.1109/ICCWorkshops53468.2022.9814556},
	abstract = {Edge computing system is facing real challenges with the evolution of new information and communication technologies ({ICT}). In addition, with the advent of Internet of Things ({IoT}) and real-time services, current edge computing system is becoming an architecture that is inappropriate for some services that require ultra low-latency and very high throughput. In order to meet all the requirements of these services, a new edge computing architecture is required. For this purpose, Home Edge Computing ({HEC}) architecture has been proposed. However, edge computing system has encountered some issues such as resource limitation on home servers. Furthermore, most distributed systems (e.g. {HEC}) operate in online mode. In other words, once failures occur in the Internet (remote servers), applications/services will be not longer accessible. In this paper, we propose {HEC}-{NerveNet} architecture, a technique based on the {HEC} architecture and {NerveNet} technology ({HEC}-N), to allow users to have continuity of services (resilient), even if they do not access to the remote servers (cloud computing). As a reminder, {NerveNet} is a resilient distributed architecture that we proposed in 2011 after the natural disaster in Japan. It allows maintaining connectivity and services in case of network failure. In addition, {NerveNet} solution allows the automatic clustering, and fast recovery thanks to the mesh topology on {NerveNet} network. This can overcome the need to manually create clusters in the {HEC} architecture. In the simulation, we prove that our proposal ({HEC}- N) is very suitable for resilient architecture and the need for future generation networks (beyond 5G/6G networks) with improving the metrics such as ultra-low latency and very high throughput compared with the current {HEC} and {NerveNet} systems.},
	pages = {295--300},
	booktitle = {2022 {IEEE} International Conference on Communications Workshops ({ICC} Workshops)},
	author = {Babou, Cheikh Saliou Mbacke and Owada, Yasunori and Inoue, Masugi and Takizawa, Kenichi and Kuri, Toshiaki},
	date = {2022-05},
	keywords = {Conferences, edge computing, Cloud computing, Computer architecture, {HEC}-{NerveNet} ({HEC}-N), Home Edge Computing ({HEC}), Information and communication technology, {NerveNet}, Real-time systems, resilient system, Throughput, Topology},
}

@article{ma_greenedge_2022,
	title = {{GreenEdge}: Joint Green Energy Scheduling and Dynamic Task Offloading in Multi-Tier Edge Computing Systems},
	volume = {71},
	issn = {1939-9359},
	doi = {10.1109/TVT.2022.3147027},
	abstract = {As mobile edge computing ({MEC}) emerges as a paradigm to meet the ever-increasing computation demands from real-time Internet of Things ({IoT}) applications in 5 G era, the development trends of which are mainly divided into two, with one being {MEC} with advanced computing architectures, and the other being {MEC} with high efficiency for sustainable operations. We are committed to taking advantage of these two trends to explore a novel multi-tier edge computing scenario with hierarchical task offloading and green energy provisioning via leveraging the energy harvesting ({EH}) technique. Specifically, we focus on the key problem of joint task offloading and energy scheduling in such green multi-tier edge computing systems. We aim to minimize the task execution cost by jointly considering the system cost that covers latency, energy consumption, and cloud rental fees. By formulating the problem as a stochastic optimization problem, we invoke the Lyapunov technique to decompose the long-term optimization problem into a series of one-slot optimization problems which only use the current system information. To solve the one-slot optimization problem which is a mixed-integer linear problem ({MILP}) proved to be {NP}-hard, we first relax the integer variables into real ones to obtain the optimal fractional solutions. Considering the capacity of the physical resources of each edge server, we propose a resource-constrained randomized dependent rounding algorithm to properly round up or down the fractional variables to get a feasible yet near-optimal solution. We conduct rigorous theoretical analysis and extensive simulations to verify the superior performance of the proposed schemes.},
	pages = {4322--4335},
	number = {4},
	journaltitle = {{IEEE} Transactions on Vehicular Technology},
	author = {Ma, Huirong and Huang, Peng and Zhou, Zhi and Zhang, Xiaoxi and Chen, Xu},
	date = {2022-04},
	keywords = {Internet of Things, Optimization, Task analysis, Costs, Energy harvesting, green energy scheduling, Green products, Multi-tier edge computing, randomized dependent rounding, Servers, task offloading},
}

@article{yu_edge_2022,
	title = {Edge computing-assisted {IoT} framework with an autoencoder for fault detection in manufacturing predictive maintenance},
	issn = {1941-0050},
	doi = {10.1109/TII.2022.3178732},
	abstract = {The Industrial Internet of Things ({IIoT}) enables intelligent predictive maintenance in smart manufacturing by incorporating {IoT} technologies, big data techniques, artificial intelligence, cloud computing and other ever-developing enabling technologies. Although a large body of research has been conducted on {IIoT} based predictive maintenance, most work focuses on addressing only a part of the problem. However, predictive maintenance involves an ecosystem from ingesting data from sensors to displaying the results on a dashboard for engineers to visualize. This paper proposes a complete and optimized {IoT} big data ecosystem embedded into a three-layer architecture, consisting of an edge layer, a cloud layer and an application layer. On top of the architecture, different layers are integrated seamlessly to address reliability, scalability, and reliability issues. An edge computing assisted autoencoder is introduced and enabled by being deployed in a distributed manner to improve both performance and efficiency. For practical interest, we also provide an application programming interface ({API})-oriented implementation guideline for readers. To verify the proposed ecosystem, a real case study from industry is conducted to demonstrate the performance gain of edge computing-based {IoT} systems in conjunction with the autoencoder-based deep learning technique.},
	pages = {1--1},
	journaltitle = {{IEEE} Transactions on Industrial Informatics},
	author = {Yu, Wenjin and Liu, Yuehua and Dillon, Tharam S and Rahayu, Wenny},
	date = {2022},
	keywords = {Edge computing, cloud computing, edge computing, Cloud computing, Computer architecture, big data analytics, Ecosystems, fault detection, Fault detection, Industrial Internet of Things, Maintenance engineering, manufacturing ecosystem, Predictive maintenance},
}

@article{huang_distributed_2022,
	title = {Distributed Offloading in Overlapping Areas of Mobile-Edge Computing for Internet of Things},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2022.3143539},
	abstract = {With the maturity of 5G cellular communication systems and mobile-edge computing ({MEC}), a large number of base stations ({BSs}) with edge-computing servers are densely deployed. There are extensive overlapping coverage areas among the {BSs} in which some heavy computational tasks from Internet of Things ({IoT}) devices can be divided and offloaded to multiple {BSs} via the coordinated multipoint ({CoMP}) technique for parallel processing. However, it is a challenging issue about how to make proper task offloading decisions among multiple connected {BSs} while satisfying delay requirements of multiple devices. To address this challenge, this article presents an efficient multidevice and multi-{BSs} task offloading scheme with the goal of minimizing the delay for completing the tasks of the devices. By conducting quantitative analysis of local delay and offloading delay, a nonlinear and nonconvex delay optimization offloading problem, which is based on the theory of noncooperative game, is formulated. We prove the existence of Nash equilibrium by analyzing the feature of the proposed offloading problem and further propose a distributed task offloading algorithm called {DOLA}. Finally, simulation experiments based on real-world data set from the Melbourne {CBD} area of Australia are conducted to validate the efficacy of our {DOLA} algorithm. Comparison experiments are also carried out to demonstrate the superiority of {DOLA} in comparison with some existing schemes.},
	pages = {13837--13847},
	number = {15},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Huang, Jiwei and Wang, Ming and Wu, Yuan and Chen, Ying and Shen, Xuemin},
	date = {2022-08},
	keywords = {Internet of Things ({IoT}), Performance evaluation, Internet of Things, Cloud computing, Optimization, Task analysis, mobile-edge computing ({MEC}), Servers, Delays, Distributed task offloading, Nash equilibrium},
}

@inproceedings{li_kneescale_2022,
	title = {{KneeScale}: Efficient Resource Scaling for Serverless Computing at the Edge},
	doi = {10.1109/CCGrid54584.2022.00027},
	abstract = {Serverless computing is a promising paradigm for delivering services to the Internet of Things ({IoT}) applications at the edge of the network. Its event-triggered computation, as well as fine-grained and agile resource scaling, is well-suited for a resource-constrained edge computing environment. However, general-purpose auto-scalers that are predominant in the cloud settings perform poorly for serverless computing at the Edge. This is mainly due to the difficulty in quickly determining the optimal resource allocation under resource-budget constraints and dynamic workloads. In this paper, we present an adaptive auto-scaler, {KneeScale}, that dynamically adjusts the number of replicas for serverless functions to reach a point at which the relative cost to increase resource allocation is no longer worth the corresponding performance benefit. We have designed and implemented {KneeScale} as lightweight system software that utilizes Kubernetes for resource management. Experimental results with a function-as-a-service ({FaaS}) benchmark, {FunetionBeneh}, and an open-source serverless computing platform, {OpenFaaS}, demonstrate the superior performance and resource efficiency of {KneeScale}. It outperforms Kubernetes Horizontal Pod {AutoScaler} ({HPA}) and {OpenFaaS} built-in scheduler in terms of cumulative performance under a given resource budget by up to 32 \% and 106 \% respectively. {KneeScale} achieves higher cumulative throughput than both competing techniques, lower latencies than {OpenFaaS} built-in scheduler, and similar latencies compared to {HPA} for a variety of serverless functions.},
	pages = {180--189},
	booktitle = {2022 22nd {IEEE} International Symposium on Cluster, Cloud and Internet Computing ({CCGrid})},
	author = {Li, Xue and Kang, Peng and Molone, Jordan and Wang, Wei and Lama, Palden},
	date = {2022-05},
	keywords = {Costs, Throughput, Benchmark testing, Dynamic scheduling, Edge, {FAA}, Resource Scaling, Serverless computing, Serverless Computing, System software},
}

@article{hu_online_2022,
	title = {Online computation offloading and trajectory scheduling for {UAV}-enabled wireless powered mobile edge computing},
	volume = {19},
	issn = {1673-5447},
	doi = {10.23919/JCC.2022.04.019},
	abstract = {The unmanned aerial vehicle ({UAV})-enabled mobile edge computing ({MEC}) architecture is expected to be a powerful technique to facilitate 5G and beyond ubiquitous wireless connectivity and diverse vertical applications and services, anytime and anywhere. Wireless power transfer ({WPT}) is another promising technology to prolong the operation time of low-power wireless devices in the era of Internet of Things ({IoT}). However, the integration of {WPT} and {UAV}-enabled {MEC} systems is far from being well studied, especially in dynamic environments. In order to tackle this issue, this paper aims to investigate the stochastic computation offloading and trajectory scheduling for the {UAV}-enabled wireless powered {MEC} system. A {UAV} offers both {RF} wireless power transmission and computation services for {IoT} devices. Considering the stochastic task arrivals and random channel conditions, a long-term average energy-efficiency ({EE}) minimization problem is formulated. Due to non-convexity and the time domain coupling of the variables in the formulated problem, a low-complexity online computation offloading and trajectory scheduling algorithm ({OCOTSA}) is proposed by exploiting Lyapunov optimization. Simulation results verify that there exists a balance between {EE} and the service delay, and demonstrate that the system {EE} performance obtained by the proposed scheme outperforms other benchmark schemes.},
	pages = {257--273},
	number = {4},
	journaltitle = {China Communications},
	author = {Hu, Han and Zhou, Xiang and Wang, Qun and Hu, Rose Qingyang},
	date = {2022-04},
	keywords = {Internet of Things, Optimization, Task analysis, Energy consumption, Wireless communication, Delays, energy efficiency, mobile edge computing, Trajectory, trajectory scheduling, {UAV}-enabled, wireless power transfer},
}

@article{li_online_2022,
	title = {Online Cognitive Data Sensing and Processing Optimization in Energy-Harvesting Edge Computing Systems},
	volume = {21},
	issn = {1558-2248},
	doi = {10.1109/TWC.2022.3151509},
	abstract = {Mobile edge computing ({MEC}) has recently become a prevailing technique to alleviate the intensive computation burden in Internet of Things ({IoT}) networks. However, the limited device battery capacity and stringent spectrum resource significantly restrict the data processing performance of {MEC}-enabled {IoT} networks. To address the two performance limitations, we consider in this paper an {MEC}-enabled {IoT} system with a wireless device ({WD}) replenishing its battery by means of energy harvesting ({EH}) and opportunistically accessing the licensed spectrum of an overlaid primary communication link to offload its sensing data to an {MEC} server ({MS}) for edge processing. Under time-varying fading channel, random energy arrivals, and stochastic {ON}-{OFF} state of the primary link, we aim to design an online algorithm to jointly control the cognitive data sensing rate and processing method (i.e., local and edge processing) without knowing future system information. In particular, we aim to maximize the long-term average sensing rate of the {WD} subject to quality of service ({QoS}) requirement of primary link, average power constraint of {MS} and data queue stability of both {MS} and {WD}. We formulate the problem as a multi-stage stochastic optimization and propose an online algorithm named {PLySE} that applies the perturbed Lyapunov optimization technique to decompose the original problem into per-slot deterministic optimization problems. For each per-slot problem, we derive the closed-form optimal solution of data sensing and processing control to facilitate low-complexity real-time implementation. Interestingly, our analysis finds that the optimal solution exhibits an threshold-based structure related to the current energy state, secondary queueing backlogs and primary link activity. Simulation results collaborate with our analysis and demonstrate more than 46.7\% data sensing rate improvement of the proposed {PLySE} over representative benchmark methods.},
	pages = {6611--6626},
	number = {8},
	journaltitle = {{IEEE} Transactions on Wireless Communications},
	author = {Li, Xian and Bi, Suzhi and Quan, Zhi and Wang, Hui},
	date = {2022-08},
	keywords = {Batteries, Internet of Things, Quality of service, Optimization, Task analysis, Sensors, Energy harvesting, cognitive radio system, energy harvesting, Mobile edge computing, online optimization algorithm},
}

@inproceedings{ba_monitoring_2022,
	title = {Monitoring of {IoT} Systems at the Edges with Transformer-based Graph Convolutional Neural Networks},
	doi = {10.1109/EDGE55608.2022.00018},
	abstract = {Internet of Things ({IoT}) systems are complex, and consist of distributed and interdependent components, making the modeling, prediction and monitoring of their behavior a critical challenge. This challenge is specifically exacerbated by the need to develop precise models that inherently consider the domain knowledge about the underlying physical structure, and the causal interdependencies between the various components of {IoT} systems. In this paper, we present an approach that is capable of leading to improved modeling and monitoring at the edges. To this end, we consider an {IoT} system as a network that can be represented by a graph. Then, we develop an approach that combines a semantic knowledge graph with a Transformer-based neural networks, under a Graph Convolutional Neural Networks ({GCNN}). Our {GCNN} produces features that are subsequently used with the Transformer to learn the parameters of an {IoT} model. We exploit the parameters of the model for monitoring and anomaly detection. We validate our approach using a real robot workcell for anomaly detection during a pick and place process, and we demonstrate that our approach outperforms other competitive techniques.},
	pages = {41--49},
	booktitle = {2022 {IEEE} International Conference on Edge Computing and Communications ({EDGE})},
	author = {Ba, Amadou and Lorenzi, Fabio and Ploennigs, Joern},
	date = {2022-07},
	keywords = {Internet of Things, Neural networks, Predictive models, Convolutional neural networks, Edge, Anomaly Detection, Graph Neural Networks, Image edge detection, {IoT}, Semantics, Time Series, Transformer, Transformers},
}

@article{irtija_energy_2022,
	title = {Energy Efficient Edge Computing Enabled by Satisfaction Games and Approximate Computing},
	volume = {6},
	issn = {2473-2400},
	doi = {10.1109/TGCN.2021.3122911},
	abstract = {In this paper, we introduce an energy efficient edge computing solution to collaboratively utilize Multi-access Edge Computing ({MEC}) and Fully Autonomous Aerial Systems ({FAAS}) to support the computing demands of the Internet of Things ({IoT}) nodes residing in Areas of Interest ({AoIs}) and executing machine learning tasks. The Satisfaction Games are adopted to determine whether the nodes’ optimal partial task should be offloaded to the {MEC} server or to a hovering {FAAS} above the {AoI}. The decision is taken by considering {IoT} nodes’ latency, energy consumption, and acceptable level of Deep Neural Network ({DNN}) inference accuracy drop constraints. We exploit the error resilience of {DNNs} and we enhance the {FAAS} with a heterogeneous approximate {DNN} accelerator that supports different computational precision and throughput, thus allowing to intelligently adapt to different computing demands. A reinforcement learning-based technique is introduced to enable the {FAAS} to autonomously optimize its trajectory, aiming at increasing the {IoT} nodes’ satisfaction of their computing demands, while accounting for its flying and data processing energy cost. Our experimental results show the benefits of {FAAS}, {MEC}, and approximate computing in terms of increasing the number of satisfied users by 40\% under a maximum accuracy drop of only 1\%.},
	pages = {281--294},
	number = {1},
	journaltitle = {{IEEE} Transactions on Green Communications and Networking},
	author = {Irtija, Nafis and Anagnostopoulos, Iraklis and Zervakis, Georgios and Tsiropoulou, Eirini Eleni and Amrouch, Hussam and Henkel, Jörg},
	date = {2022-03},
	keywords = {Edge computing, Internet of Things, Quality of service, Task analysis, Energy consumption, {FAA}, energy efficiency, Trajectory, approximate computing, Approximate computing, deep neural networks accelerators, reinforcement learning, satisfaction games},
}

@article{avasalcai_edgeflowdeveloping_2022,
	title = {{EdgeFlow}—Developing and Deploying Latency-Sensitive {IoT} Edge Applications},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3101449},
	abstract = {Demanding latency-sensitive {IoT} applications have stringent requirements, such as low latency, better privacy, and security. To meet such requirements, researchers proposed a new paradigm, i.e., edge computing. Edge computing consists of distributed computational resources and enables the execution of {IoT} applications closer to the edge of the network. However, the distributed nature of this paradigm makes the application deployment and development process more challenging since the developer must divide the application’s functionality into multiple parts, assigning for each a set of requirements. As a result, the developer must: 1) define the application’s requirements and validate them at design time and 2) find a deployment strategy on the target edge computing platform. In this article, we propose {EdgeFlow}, a new {IoT} framework capable of assisting the developer in the application development process. Specifically, we introduce a methodology for latency-sensitive {IoT} applications development and deployment, consisting of three different stages, i.e., the development, validation, and deployment. To this end, we propose an extension of the flow-based programming paradigm with new timing requirements and provide a resource allocation technique to assist with the deployment and validation of latency-sensitive {IoT} applications. Finally, we evaluate {EdgeFlow} by: 1) presenting the application development methodology and 2) performing a quantitative evaluation demonstrating our resource allocation technique’s capabilities to find feasible and optimal deployment strategies. The experimental results illustrate the effectiveness of our methodology to assist the developer throughout the entire application development process.},
	pages = {3877--3888},
	number = {5},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Avasalcai, Cosmin and Zarrin, Bahram and Dustdar, Schahram},
	date = {2022-03},
	keywords = {Edge computing, Internet of Things, Computational modeling, resource management, Cloud computing, Task analysis, Computer architecture, flow-based programming ({FBP}), Internet of Things ({IoT}) application development, Resource management},
}

@inproceedings{padidem_studying_2022,
	title = {Studying Offloading Optimization for Energy-Latency Tradeoff with Collaborative Edge Computing},
	doi = {10.1109/IMCOM53663.2022.9721745},
	abstract = {Since the past few years, mobile communication technology is developing very rapidly, Internet of Things ({IoT}) are getting very popular. Simultaneously, the idea of being smart city and smart home is growing which implies the popularization of smart cars with the ability to drive autonomously. To meet the needs of these rapidly developing industries, huge amount of computing resources are needed to be consumed. Mobile edge computing is one of the most effective solution to the problem of consuming huge amount of power for the complex computations. Elements of mobile edge cloud computing are small to large mobile user devices including {IoT}-enabled devices. These devices mostly rely on the battery for computational tasks and if the tasks are complex, battery is drained quickly. So to tackle the complex application tasks, a much more advanced computation is required. Additionally, storage, data communication and efficient energy consuming techniques must be used. One of the major challenges while developing energy efficient network is computation offloading and latency minimization. Previous work shows that any one of the challenges can only be achieved if there is good energy efficiency then the latency is more and if there is minimum latency, but the energy consumed is more. In this paper, we are going to suggest specific areas in the collaborative cloud architecture that needs to be improved for achieving both energy efficiency as well as latency minimization. For that, we have implemented various scenarios and observe the areas of improvement.},
	pages = {1--6},
	booktitle = {2022 16th International Conference on Ubiquitous Information Management and Communication ({IMCOM})},
	author = {Padidem, Pranathi and Lee, Ahyoung},
	date = {2022-01},
	keywords = {Smart homes, Batteries, Internet of Things, Smart cities, Cloud computing, Collaboration, Energy efficiency, Minimization, energy efficiency, collaborative edge computing, latency minimization, offloading},
}

@inproceedings{attarha_service_2022,
	title = {Service Management for Enabling Self-Awareness in Low-Power {IoT} Edge Devices},
	doi = {10.1109/PerComWorkshops53856.2022.9767362},
	abstract = {In the context of Internet-of-Things ({IoT}), efficient and flexible service management techniques are essential to improve performance and cost-effectiveness. In this regard, it is crucial to equip the {IoT} devices with tools that allow a flexible, well-performing, and automated way of efficient services provisioning. Current {IoT} low-power edge devices have been designed in a way that embedded services can not be monitored and re-configured during the run-time. Hence, finding a trade-off between design requirements, specific performance targets, and services manageability are necessary. The presented project focuses on the idea of service isolation and modularisation at the level of edge devices to observe {IoT} services and manage them under real-time requirements in extremely resource-constrained {IoT} environments.},
	pages = {146--147},
	booktitle = {2022 {IEEE} International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events ({PerCom} Workshops)},
	author = {Attarha, Shadi and Förster, Anna},
	date = {2022-03},
	keywords = {Conferences, Performance evaluation, Pervasive computing, Internet of Things, Monitoring, Real-time systems, Flexibility, Internet-of-Things ({IoT}), Service isolation, Service Management},
}

@inproceedings{ahmed_ris_2022,
	title = {{RIS} Panel-assisted Enhanced Edge Computing for Batteryless {IoT} Sensors},
	doi = {10.1109/ICC45855.2022.9838929},
	abstract = {Reconfigurable intelligent surfaces ({RISs}) have emerged as an efficient and cost-effective technique to enhance a great variety of possible performances of the Internet of Things ({IoT}) systems by re-configuring the propagation environment. Motivated by this, we investigate the {RIS}-assisted edge computing systems for batteryless {IoT} sensors (b-{IoT}) under Rician fading channel conditions. We consider a fixed time frame divided into three slots. A b-{IoT} sensor harvests energy from radio frequency signals from a nearby base station ({BS}) during the first time slot. While performing local computation, the b-{IoT} sensor offloads computation bits to the {BS} and an {IoT} sensor using device-to-device communications protocol in the second and final time slots, respectively. An offloading ratio differentiates the fraction of computational bits, offloaded to {BS} and {IoT} sensors. We formulate the optimization problem with the convex sum of computational bits as objective function and energy consumption, offloading ratio, and energy harvesting constraints. We propose a gradient descent-based iterative algorithm to solve the optimization problem. Simulation assessments depict {RIS} panel-assisted edge computing, and energy harvesting enhances the performance by more than 90\% compared to the traditional baseline schemes, such as networks with no {RIS} panel.},
	pages = {5676--5681},
	booktitle = {{ICC} 2022 - {IEEE} International Conference on Communications},
	author = {Ahmed, Shakil and Kamal, Ahmed E.},
	date = {2022-05},
	keywords = {edge computing, Sensors, Energy consumption, Simulation, Energy harvesting, energy harvesting, assive elements, {IoT} sensor, Iterative methods, Rician channels, {RIS} panel, Sensor systems},
}

@article{tianqing_resource_2022,
	title = {Resource Allocation in {IoT} Edge Computing via Concurrent Federated Reinforcement Learning},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3086910},
	abstract = {Resource allocation is a fundamental research issue in {IoT} edge computing, and reinforcement learning is fast becoming a common solution. The majority of the current techniques involve decision makers who determine how and where resources should be distributed. In a standard cloud system, this decision maker is a central server. In an edge system, the decision maker is an edge host. Both approaches have drawbacks. Edge hosts do not always have access to enough global information to create the most optimal resource allocation strategy. Central servers do but at the cost of privacy. A solution is needed that can do both. This article, therefore, presents a novel resource allocation method called concurrent federated reinforcement learning. The scheme inherits the privacy protection of federated learning, the complex problem solving power of reinforcement learning and adds concurrency in the form of joint decision making so the resource allocation strategies work to the benefit of the global system. The experiments demonstrate that the approach provides the state-of-the-art performance in system-wide utility, speed of task completion, and resource utilization.},
	pages = {1414--1426},
	number = {2},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Tianqing, Zhu and Zhou, Wei and Ye, Dayong and Cheng, Zishuo and Li, Jin},
	date = {2022-01},
	keywords = {Privacy, Internet of Things, Computational modeling, Task analysis, Reinforcement learning, privacy preservation, Servers, Resource management, Deep reinforcement learning, resources allocation},
}

@article{an_joint_2022,
	title = {Joint Task Offloading and Resource Allocation for {IoT} Edge Computing With Sequential Task Dependency},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2022.3150976},
	abstract = {Incorporating mobile-edge computing ({MEC}) in the Internet of Things ({IoT}) enables resource-limited {IoT} devices to offload their computation tasks to a nearby edge server. In this article, we investigate an {IoT} system assisted by the {MEC} technique with its computation task subjected to sequential task dependency, which is critical for video stream processing and other intelligent applications. To minimize energy consumption per {IoT} device while limiting task processing delay, task offloading strategy, communication resource, and computation resource are optimized jointly under both slow and fast-fading channels. In slow fading channels, an optimization problem is formulated, which is nonconvex and involves one integer variable. To solve this challenging problem, we decompose it as a 1-D search of task offloading decision problem and a nonconvex optimization problem with task offloading decision given. Through mathematical manipulations, the nonconvex problem is transformed to be a convex one, which is shown to be solvable only with the simple Golden search method. In fast-fading channels, optimal online policies depending on the instant channel state are derived even though they are entangled. In addition, it is proved that the derived policy will converge to the offline policy when the channel coherence time is low, which can help save extra computation complexity. Numerical results verify the correctness of our analysis and the effectiveness of our proposed strategies over the existing methods.},
	pages = {16546--16561},
	number = {17},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {An, Xuming and Fan, Rongfei and Hu, Han and Zhang, Ning and Atapattu, Saman and Tsiftsis, Theodoros A.},
	date = {2022-09},
	keywords = {Internet of Things ({IoT}), Internet of Things, Optimization, Task analysis, mobile-edge computing ({MEC}), Energy consumption, Servers, task offloading, Resource management, Fading channels, resource allocation, sequential task dependency},
}

@article{han_joint_2022,
	title = {Joint Subcarrier and Transmission Power Allocation in {OFDMA}-Based {WPT} System for Mobile-Edge Computing in {IoT} Environment},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3103768},
	abstract = {Mobile-edge computing ({MEC}) is expected to play an important role in the next-generation of Internet-of-Things ({IoT}) services with artificial intelligence ({AI}) by providing the sustainable computation capability of resource-constrained {IoT} devices. Since the finite battery lifetime has been a longstanding challenge of the {MEC} system for {IoT} services, the wireless power transfer ({WPT}) technology has been recently developed for the {MEC} system in order to support the perpetual operation of {IoT} devices. In this article, we introduce two resource allocation problems for {OFDMA}-based {WPT}-{MEC} systems: 1) a max–min energy fairness ({MMEF}) problem and 2) a power sum maximization ({PSM}) problem. These problems ensure high-performance computations for {AI}-based applications, where the network reliability and the tremendous power consumption may be required. Moreover, we incorporate a logarithmic nonlinear energy harvesting ({EH}) model into our formulated problems, which lead to nonconvex mixed-integer nonlinear programming ({MINLP}) problems. In order to resolve these {NP}-hard problems, we convert the proposed problems into their equivalent convex forms by applying the continuous relaxation method. The near-optimal solutions are thereby obtained in closed-form expressions by leveraging the Lagrangian duality method for each relaxed problem. Numerical results are presented to validate the merits of the proposed algorithms of {MMEF}\&{PSM} over the alternative benchmark algorithm and provide significant insights on the effects of the key system parameters, including the number of {IoT} devices and power transmission subcarriers.},
	pages = {15039--15052},
	number = {16},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Han, Jaeseob and Lee, Gyeong Ho and Park, Sangdon and Choi, Jun Kyun},
	date = {2022-08},
	keywords = {Internet of Things ({IoT}), Internet of Things, mobile-edge computing ({MEC}), Wireless communication, Energy harvesting, Servers, Resource management, resource allocation, Convex optimization, energy fairness, energy-efficient processing, logarithmic nonlinear energy harvesting ({EH}), orthogonal frequency-division multiple access, Power transmission, Radio frequency, wireless power transfer ({WPT})},
}

@article{yang_intelligent-reflecting-surface-aided_2022,
	title = {Intelligent-Reflecting-Surface-Aided Mobile Edge Computing With Binary Offloading: Energy Minimization for {IoT} Devices},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2022.3173027},
	abstract = {Mobile edge computing ({MEC}) is envisioned as a promising technique to support computation-intensive and time-critical applications in future Internet of Things ({IoT}) era. However, the uplink transmission performance will be highly impacted by the hostile wireless channel, the low bandwidth, and the low transmission power of {IoT} devices. Recently, intelligent reflecting surface ({IRS}) has drawn much attention because of its capability to control the wireless environments so as to enhance the spectrum and energy efficiencies of wireless communications. In this article, we consider an {IRS}-aided multidevice {MEC} system where each {IoT} device follows the binary offloading policy, i.e., a task has to be computed as a whole either locally or remotely at the edge server. We aim to minimize the total energy consumption of devices by jointly optimizing the binary offloading modes, the {CPU} frequencies, the offloading powers, the offloading times, and the {IRS} phase shifts for all devices. Two algorithms, which are greedy based and penalty based, are proposed to solve the challenging nonconvex and discontinuous problem. It is found that the penalty-based method has only linear complexity with respect to the number of devices, but it performs close to the greedy-based method with cubic complexity with respect to the number of devices. Furthermore, binary offloading via {IRS} indeed saves more energy compared to the case without {IRS}.},
	pages = {12973--12983},
	number = {15},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Yang, Yizhen and Gong, Yi and Wu, Yik-Chung},
	date = {2022-08},
	keywords = {Internet of Things, Task analysis, Energy consumption, Minimization, Wireless communication, Servers, Binary offloading, energy minimization, intelligent reflecting surface ({IRS}), Internet of Things ({IoT}) devices, mobile edge computing ({MEC}), Time-frequency analysis},
}

@inproceedings{islam_gas_2022,
	title = {A Gas Cylinder Monitoring System: A Benign Transportation Sector Based on {IoT} and Edge Computing},
	doi = {10.1109/DASA54658.2022.9765300},
	abstract = {Hydrocarbon ({HC}) based Compressed Natural Gas ({CNG}) gas is highly flammable and can be threatening if not maintained and monitored correctly. Failure to detect gas leakage leads to property damage and poses a severe threat to human life. In this paper, we focused on the safety measures of {CNG}-based automobiles in Bangladesh’s transportation sector. {CNG}-run vehicles are causing a high risk of explosion, and if not regulated and monitored consistently, the gas cylinder can explode, causing massive damages. Also, the manual inspection may not always be precise and often produce severe consequences. Therefore, we have proposed an {IoT} and Edge computing-based system to supervise any leakage and the cylinder’s comprehensive monitoring. The system is embedded with the Edge technique, thus, capable of handling bandwidth and latency issues. {IoT}-enabled sensors continuously collect data in our system, and if there is a sense of risk detected in the {CNG} cylinder, the system can send a necessary alert to the authorized person.},
	pages = {506--510},
	booktitle = {2022 International Conference on Decision Aid Sciences and Applications ({DASA})},
	author = {Islam, Mahbubul and Amin, Saddam Al and Azad, Md. Abul Kalam and Mainuddin Ahmed, Gazi Sikandar and Muzahidul Islam, A. K. M.},
	date = {2022-03},
	keywords = {Sensors, Image edge detection, Sensor systems, Edge Computing, Gas Leakage Detection, Hydrocarbons, Inspection, {IoT} based Gas Cylinder, Manuals, Transportation, Transportation Sector},
}

@article{ren_demand-driven_2022,
	title = {A Demand-Driven Incremental Deployment Strategy for Edge Computing in {IoT} Network},
	volume = {9},
	issn = {2327-4697},
	doi = {10.1109/TNSE.2021.3120270},
	abstract = {Edge Computing brings great opportunities to enable the Internet of Things ({IoT}) vision. But the physical edge server deployment problem still poses a major challenge, which dramatically affects the service ability and service cost of edge computing. Previous work mostly assume that the edge servers are installed at one time. However, due to ever-increasing services, limited budget and evolving techniques, it is more reasonable to deploy edge servers in a gradual fashion. In this paper, we propose a demand-driven incremental deployment strategy ({DDID}) to resolve this problem. First, a novel demand model is designed to quantify the rigid and non-rigid demand of {IoT} services for edge computing. Then, we formulate the edge server multi-period deployment problem as a bi-level integer linear program model. The lower-level placement is to minimize the overall deployment cost throughout a planning horizon. We adopt a subgradient optimization with Lagrangian dual to solve this subproblem. In the upper-level allocation, due to the capacity limitation, we adopt a best-effort tuning scheme to prioritize the high demand services with multiple objectives. This subproblem is addressed by an improved {MOEA}/D (Multi-objective Evolutionary Algorithm Based on Decomposition). Finally, we evaluate the {DDID} in synthetic topologies. Experimental results show that, compared to the one-time deployment method, it reduces the deployment cost by 18\% on average with acceptable service ability loss for edge computing.},
	pages = {416--430},
	number = {2},
	journaltitle = {{IEEE} Transactions on Network Science and Engineering},
	author = {Ren, Wei and Sun, Yan and Luo, Hong and Guizani, Mohsen},
	date = {2022-03},
	keywords = {Internet of Things ({IoT}), Edge computing, Internet of Things, Computational modeling, Optimization, Costs, Servers, multi-period deployment, placement and allocation, Planning},
}

@article{zakarya_epcaware_2022,
	title = {{epcAware}: A Game-Based, Energy, Performance and Cost-Efficient Resource Management Technique for Multi-Access Edge Computing},
	volume = {15},
	issn = {1939-1374},
	doi = {10.1109/TSC.2020.3005347},
	abstract = {Internet of Things ({IoT}) is producing an extraordinary volume of data daily, and it is possible that the data may become useless while on its way to the cloud, due to long distances. Fog/edge computing is a new model for analysing and acting on time-sensitive data, adjacent to where it is produced. Further, cloud services provided by large companies such as Google, can also be localised to improve response time and service agility. This is accomplished through deploying small-scale datacentres in various locations, where needed in proximity of users; and connected to a centralised cloud that establish a multi-access edge computing ({MEC}). The {MEC} setup involves three parties, i.e., service providers ({IaaS}), application providers ({SaaS}), network providers ({NaaS}); which might have different goals, therefore, making resource management difficult. Unlike existing literature, we consider resource management with respect to all parties; and suggest game-theoretic resource management techniques to minimise infrastructure energy consumption and costs while ensuring applications’ performance. Our empirical evaluation, using Google’s workload traces, suggests that our approach could reduce up to 11.95 percent energy consumption, and \{{\textbackslash}textbackslashtextbackslashsim{\textbackslash}∼17.86\% user costs with negligible loss in performance. Moreover, {IaaS} can reduce up to 20.27 percent energy bills and {NaaS} can increase their costs-savings up to 18.52 percent as compared to other methods.},
	pages = {1634--1648},
	number = {3},
	journaltitle = {{IEEE} Transactions on Services Computing},
	author = {Zakarya, Muhammad and Gillam, Lee and Ali, Hashim and Rahman, Izaz Ur and Salah, Khaled and Khan, Rahim and Rana, Omer and Buyya, Rajkumar},
	date = {2022-05},
	keywords = {Edge computing, Internet of Things, Quality of service, Cloud computing, Energy consumption, energy efficiency, Resource management, game theory, Google, multi-access edge computing, performance, Time factors},
}

@inproceedings{zhang_machine_2022,
	title = {Machine Learning Driven Latency Optimization for Application-aware Edge Computing-based {IoTs}},
	doi = {10.1109/ICC45855.2022.9838829},
	abstract = {Most {IoT} devices have limited or no computing capability while many emerging {IoT} applications require both computing and communications services. Moreover, low latency requirements of numerous applications such as autonomous driving and augmented reality are becoming critical. In this paper, we propose a novel framework that can utilize the edge-computing facilities and the full-duplex technique at the edge nodes to address computing and communication services with low latency to {IoT} terminals for different applications. We then formulate an application-aware edge-computing problem for {IoTs} with the target to minimize the average latency. We propose a machine learning algorithm to solve this problem by achieving the best user-edge-node assignment and developing an optimal assignment and scheduling algorithm for the communication and computing resources. We evaluate the performance of the proposed machine learning algorithm (via Python and Tensor ow) and present results and comparison with other methods.},
	pages = {183--188},
	booktitle = {{ICC} 2022 - {IEEE} International Conference on Communications},
	author = {Zhang, Liang and Jabbari, Bijan},
	date = {2022-05},
	keywords = {Internet of Things ({IoT}), Conferences, machine learning ({ML}), optimization, Delays, 5G, 6G, artificial intelligence ({AI}), Full-duplex system, {IoT} applications, latency, Machine learning, Machine learning algorithms, Scheduling algorithms, Tensors},
}

@article{peng_efficient_2022,
	title = {An Efficient Privacy-Preserving Aggregation Scheme for Multidimensional Data in {IoT}},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3083136},
	abstract = {Internet of Things ({IoT}) enables terminal devices connecting with the Internet and provides various intelligent applications by analyzing devices data. As a typical {IoT} technique, edge computing provides a three-tier architecture to reduce communications and improve efficiency. Specifically, edge nodes are responsible for collecting and aggregating device data, and then send processed results to the cloud for subsequent analysis. However, the data aggregation function will compromise the privacy of device data. In this article, we proposed an efficient privacy-preserving multidimensional data aggregation scheme for {IoT}, called {PMDA}. The scheme uses the Chinese remainder theorem to design a homomorphic encryption method that encryptes a multiple-dimensional small integer vector into one ciphertext and keeps linear homomorphic properties per dimension. Combining with the signature mechanism and the batch verification method, the scheme guarantees nonrepudiation of device data and enhance verification efficiency at edge nodes. Through theoretical analysis, we demonstrate that the proposed scheme can achieve correctness, privacy, authentication, and integrity. After performance evaluation, we demonstrate that our scheme is superior to other schemes in terms of computation and communication costs. In particular, as the message dimension increases, our scheme computation costs almost a tenth of others at the 80-bits security level.},
	pages = {589--600},
	number = {1},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Peng, Cong and Luo, Min and Wang, Huaqun and Khan, Muhammad Khurram and He, Debiao},
	date = {2022-01},
	keywords = {Internet of Things ({IoT}), Edge computing, Internet of Things, edge computing, Sensors, Cryptography, Data aggregation, Encryption, privacy preserving, Security},
}

@article{yang_secure_2022,
	title = {Secure and Lightweight Authentication for Mobile-Edge Computing-Enabled {WBANs}},
	volume = {9},
	issn = {2327-4662},
	doi = {10.1109/JIOT.2021.3138989},
	abstract = {Wireless body area networks ({WBANs}) technology nowadays has become a promising networking paradigm in the Internet of Things ({IoT}) as it can provide people with high quality of life and high level of medical service. In order to ensure the security and privacy of patients’ sensitive biomedical data and the efficiency of message processing across different devices, it is critical to provide a secure and lightweight authentication scheme for {WBANs}. In this article, we propose an extra lightweight authentication scheme for mobile-edge computing-enabled {WBANs}. Two different authentication phases based on the modular square roots technique are designed: one is the intra-{BAN} authentication between the sensor node and edge node ({EN}), and the other is the inter-{BAN} authentication between {EN} and application provider. The proposed scheme offers robust security by providing comprehensive security analysis. Performance is also evaluated in terms of computation, communication, and storage costs. The evaluation results demonstrate that the proposed scheme achieves a reduction of at least 90\% in computation cost and at least 30\% in communication cost when compared to four other related schemes.},
	pages = {12563--12572},
	number = {14},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Yang, Xu and Yi, Xun and Khalil, Ibrahim and Luo, Junwei and Bertino, Elisa and Nepal, Surya and Huang, Xinyi},
	date = {2022-07},
	keywords = {Internet of Things ({IoT}), privacy, Internet of Things, Cloud computing, Sensors, Costs, Cryptography, Security, Authentication, efficiency, security, wireless body area network ({WBAN})},
}

@inproceedings{sivasangari_integrated_2022,
	title = {Integrated Security Framework for Healthcare Using Blockchain and Fog Computing},
	doi = {10.1109/PARC52418.2022.9726539},
	abstract = {Edge computing is a promising paradigm that enhances the capabilities of cloud computing in healthcare. In order to continue patronizing the computing services, it is essential to conserve a good atmosphere free from all kinds of security and privacy breaches. The security and privacy issues associated with the edge computing environment have narrowed the overall acceptance of the technology as a reliable paradigm. Edge computing is a promising model for improving cloud computing’s capabilities. It is important to maintain a positive climate free of all forms of protection and privacy violations in order to continue using computing services. The edge computing environment’s security and privacy concerns have hampered the technology’s overall acceptance as a reliable paradigm.The blockchain technology emerges as a viable solution because it provides influential features such as continuous secrecy, authentication, and robustness. This proposed work propose a blockchain-enabled distributed security architecture based on edge cloud. Security attacks are detected at the cloud layer, and as a result, security attacks at the {IoT} network’s edge layer are decreased. The gateway provides dynamic network traffic flow management, which aids in the detection of security attacks by identifying suspicious network traffic flows and reducing security attacks by blocking suspicious flows.For the next-generation {IoT}, the proposed security architecture has specified state-of-the-art contributions. The proposed algorithm is based on {ECC} based proxy encryption technique. Proxy re-encryption is a modern encryption scheme designed for protection in a distributed environment, including such smart applications that use the Internet of Things.},
	pages = {1--5},
	booktitle = {2022 2nd International Conference on Power Electronics \& {IoT} Applications in Renewable Energy and its Control ({PARC})},
	author = {Sivasangari, A. and Sonti, V J K Kishor and Ajitha, P. and Deepa, D. and Vignesh, R.},
	date = {2022-01},
	keywords = {Cloud computing, Computer architecture, Image edge detection, {IoT}, Encryption, security, blockchain, Blockchains, Medical services, Telecommunication traffic},
}

@article{lin_ai-based_2022,
	title = {{AI}-Based Mean Field Game against Resource-Consuming Attacks in Edge Computing},
	issn = {1550-4859},
	url = {https://doi.org/10.1145/3519303},
	doi = {10.1145/3519303},
	abstract = {With the rapid development of edge computing, it has formed a new paradigm for providing the nearest end service close to the data source. However, insufficient supply of resources makes edge computing devices vulnerable to attacks, especially sensitive to resource-consuming attacks. This paper first designs system function module, aiming to deal with resource-consuming attacks based on the general three-layer architecture of edge computing. Combined with the mean field game, an anti-attack model is designed to transform the security defense problem of large terminal-edge-cloud devices into the mean field countermeasure problem, and the self-organizing neural network is used to approximate the mean field coupling equation. On this basis, a distributed {AI}-driven resource-consuming attack security defense ({ARASD}) algorithm is designed to obtain the optimal solution for devices security interaction, thereby improving the system’s anti-attack ability. Finally, the effectiveness of the self-organizing neural network is verified through numerical simulation, and the parameters such as the number of initial terminal-edge-cloud devices and the number of iterations of different security defense algorithms are evaluated. The results show that the {ARASD} algorithm can achieve better resistance to resource-consuming attacks than other state-of-the-art algorithms in a large-scale edge computing architecture.},
	journaltitle = {{ACM} Transactions on Sensor Networks},
	author = {Lin, Kai and Liu, Jiayi and Han, Guangjie},
	urldate = {2022-11-21},
	date = {2022-07},
	keywords = {Edge computing, Artificial intelligence, Mean field game, Security defense},
}

@inproceedings{mahmoud_distributed_2022,
	location = {New York, {NY}, {USA}},
	title = {Distributed Edge Computing to Assist {LPWAN}: Fog-{MEC} Model},
	isbn = {978-1-4503-8734-7},
	url = {https://doi.org/10.1145/3508072.3508192},
	doi = {10.1145/3508072.3508192},
	series = {{ICFNDS} 2021},
	shorttitle = {Distributed Edge Computing to Assist {LPWAN}},
	abstract = {Low power wide area network ({LPWAN}) is one of the main Internet of Things ({IoT}) networks that is widely used for the outdoor-{IoT} applications. A main feature with such networks is the long-range coverage that enables the dense deployment over such networks. However, the introduction of massive number of {IoT} devices puts many constraints and limitations on the design and development of such networks. A promising solution for a part of such challenges is the introduction of distributed computing technology to enable this massive number of deployed devices. This work considers such deployment of heterogeneous forms of distributed computing units to assist the design and development of {LPWAN} networks for dense deployed applications. Two main forms of the distributed computing are considered in this work; multiple access edge computing ({MEC}), and fog computing. The integration of fog and {MEC} units is introduced in a way that achieves higher latency, energy, and availability efficiency. A proof-of-concept of the developed model is introduced for dense deployment scenarios. The developed fog-{MEC} model is evaluated for {LPWAN} for heterogeneous simulation scenarios, and the simulation results validate the developed model.},
	pages = {587--594},
	booktitle = {The 5th International Conference on Future Networks \& Distributed Systems},
	publisher = {Association for Computing Machinery},
	author = {Mahmoud, Mona and Ashraf Ateya, Abdelhamied and Muthanna, Ammar and Zaghloul, Adel and Kirichek, Ruslan and Koucheryavy, Andrey},
	urldate = {2022-11-21},
	date = {2022-04},
	keywords = {Internet of Things, Fog, Latency, {LPWAN}, {MEC}},
}

@article{tan_joint_2022,
	title = {Joint Offloading and Resource Allocation Based on {UAV}-Assisted Mobile Edge Computing},
	volume = {18},
	issn = {1550-4859},
	url = {https://doi.org/10.1145/3476512},
	doi = {10.1145/3476512},
	abstract = {Due to the birth of various new Internet of Things devices, the rapid increase of users, and the limited coverage of infrastructure, computing resources will inevitably become insufficient. Therefore, we consider an unmanned aerial vehicle ({UAV})–assisted mobile edge computing system with multiple users, an edge server, a remote cloud server, and an {UAV}. A {UAV}, as a relay node, can provide users with extensive communications and certain computing capabilities. Our proposed scheme aims to optimize the unloading decision of the tasks among all users and the allocation of computing and communication resources to minimize overall energy consumption and costs of computing and maximum delay. To solve the joint optimization problem, we propose an efficient {USS} algorithm, which includes a {UAV} position optimization algorithm, semi-qualitative relaxation method, and self-adaptive adjustment method. Our numerical results show that the proposed algorithm can significantly reduce the unloading cost of multi-user tasks compared with four other unloading decisions, such as traditional cloud computing, which uses only the edge server.},
	pages = {36:1--36:21},
	number = {3},
	journaltitle = {{ACM} Transactions on Sensor Networks},
	author = {Tan, Tiao and Zhao, Ming and Zeng, Zhiwen},
	urldate = {2022-11-21},
	date = {2022-04},
	keywords = {Mobile edge computing, joint optimization problem, unloading decision, unmanned aerial vehicle ({UAV}), {USS} algorithm},
}

@inproceedings{jiang_optimization_2022,
	location = {New York, {NY}, {USA}},
	title = {Optimization method of edge computing terminal deployment considering node division in Electric Internet of Things},
	isbn = {978-1-4503-9662-2},
	url = {https://doi.org/10.1145/3559795.3559811},
	doi = {10.1145/3559795.3559811},
	series = {{BIOTC} '22},
	abstract = {The massive intelligent devices emerging in the Electric Internet of Things have increased demand for computing resources, but it is difficult to configure computing devices for each data point in the actual system. When using edge computing terminal to solve the above problems, the terminal faces the problem of which data points should be controlled by the terminal and where the terminal should be deployed. This paper proposes an optimization method for the deployment of edge computing terminals considering node division in the Electric Internet of Things, aiming at minimizing the delay when processing tasks. Firstly, the information processing architecture based on the cooperation of multiple edge computing terminals is described, and the logical relationship of task processing is fully considered. Secondly, the optimization model of edge computing terminal deployment and its solution are proposed. Finally, the effectiveness and feasibility of the proposed model and method are verified by numerical simulation.},
	pages = {115--120},
	booktitle = {Proceedings of the 2022 4th Blockchain and Internet of Things Conference},
	publisher = {Association for Computing Machinery},
	author = {Jiang, Lin and Li, Wenhui and Fu, Bo and Bai, Lin},
	urldate = {2022-11-21},
	date = {2022-10},
	keywords = {cooperation, deployment, edge computing terminal, Electric Internet of Things},
}

@inproceedings{song_cascade_2022,
	location = {New York, {NY}, {USA}},
	title = {Cascade: An Edge Computing Platform for Real-time Machine Intelligence},
	isbn = {978-1-4503-9280-8},
	url = {https://doi.org/10.1145/3524053.3542741},
	doi = {10.1145/3524053.3542741},
	series = {{ApPLIED} '22},
	shorttitle = {Cascade},
	abstract = {Intelligent {IoT} is a prerequisite for societal priorities such as a smart power grid, smart urban infrastructures and smart highways. These applications bring requirements such as real-time guarantees, data and action consistency, fault-tolerance, high availability, temporal data indexing, scalability, and even self-organization and self-stabilization. Existing platforms are oriented towards asynchronous, out of band upload of data to the cloud: Important functionality, but not enough to address the need. Cornell's Cascade project seeks to close the gap by creating a new platform for hosting {ML} and {AI}, optimized to achieve sharply lower delay and substantially higher bandwidth than in any existing platform. At the same time, Cascade introduces much stronger guarantees - a mix that we believe will be particularly appealing in applications where events should trigger a quick and trustworthy response. This short paper is intended as a brief overview of the effort, with details to be published elsewhere.},
	pages = {2--6},
	booktitle = {Proceedings of the 2022 Workshop on Advanced tools, programming languages, and {PLatforms} for Implementing and Evaluating algorithms for Distributed systems},
	publisher = {Association for Computing Machinery},
	author = {Song, Weijia and Yang, Yuting and Liu, Thompson and Merlina, Andrea and Garrett, Thiago and Vitenberg, Roman and Rosa, Lorenzo and Awatramani, Aahil and Wang, Zheng and Birman, Ken},
	urldate = {2022-11-21},
	date = {2022-07},
	keywords = {cloud computing, edge intelligence, {IoT}, consistency, time-sensitive computing},
}

@inproceedings{zhou_online_2022,
	location = {New York, {NY}, {USA}},
	title = {Online incentive mechanism for task offloading with privacy-preserving in {UAV}-assisted mobile edge computing},
	isbn = {978-1-4503-9165-8},
	url = {https://doi.org/10.1145/3492866.3549715},
	doi = {10.1145/3492866.3549715},
	series = {{MobiHoc} '22},
	abstract = {Unmanned aerial vehicles ({UAVs}) have emerged as a promising technology to provide low-latency mobile edge computing ({MEC}) services. To fully utilize the potential of {UAV}-assisted {MEC} in practice, both technical and economic challenges need to be addressed: how to optimize {UAV} trajectory for online task offloading and incentivize the participation of {UAVs} without compromising the privacy of user equipment ({UE}). In this work, we consider unique features of {UAVs}, i.e., high mobility as well as limited energy and computing capacity, and propose a privacy-preserving auction framework, Ptero, to schedule offloading tasks on the fly and incentivize {UAVs}' participation. Specifically, Ptero first decomposes the online task offloading problem into a series of one-round problems by scaling the {UAV}'s energy constraint into the objective. To protect {UE}'s privacy, Ptero calculates {UAV}'s coverage based on subset-anonymity. At each round, Ptero schedules {UAVs} greedily, computes remuneration for working {UAVs}, and processes unserved tasks in the cloud to maximize the system's utility (i.e., minimize social cost). Theoretical analysis proves that Ptero achieves truthfulness, individual rationality, computational efficiency, privacy preserving and a non-trivial competitive ratio. Trace-driven evaluations further verify that Ptero can reduce the social cost by up to 116\% compared with four state-of-the-art algorithms.},
	pages = {211--220},
	booktitle = {Proceedings of the Twenty-Third International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Ruiting and Zhang, Renli and Wang, Yufeng and Tan, Haisheng and He, Kun},
	urldate = {2022-11-21},
	date = {2022-10},
	keywords = {task offloading, incentive mechanism, online algorithm, {UAV}-assisted {MEC}},
}

@inproceedings{bartolomeo_oakestra_2022,
	location = {New York, {NY}, {USA}},
	title = {Oakestra: an orchestration framework for edge computing},
	isbn = {978-1-4503-9434-5},
	url = {https://doi.org/10.1145/3546037.3546056},
	doi = {10.1145/3546037.3546056},
	series = {{SIGCOMM} '22},
	shorttitle = {Oakestra},
	abstract = {Edge computing enables developers to deploy their services on compute resources deployed closer to the users. The abstraction requires powerful orchestration capabilities and the resolution of complex optimization problems. While edge computing is a consistently growing trend, the community (research and industry) still largely embraces adaptations and extensions of existing cloud technologies that have been proven ineffective on edge (e.g. Kubernetes). In this work, we present Oakestra, a novel hierarchical orchestration framework specifically designed for supporting service operation over heterogeneous edge infrastructures. In this demonstration, we showcase the various features and operations of Oakestra using our latency-critical augmented reality ({AR}) application.},
	pages = {34--36},
	booktitle = {Proceedings of the {SIGCOMM} '22 Poster and Demo Sessions},
	publisher = {Association for Computing Machinery},
	author = {Bartolomeo, Giovanni and Bäurle, Simon and Mohan, Nitinder and Ott, Jörg},
	urldate = {2022-11-21},
	date = {2022-10},
	keywords = {edge computing, resource management, orchestration framework},
}

@inproceedings{belcastro_evaluation_2022,
	location = {Valencia, Spain},
	title = {Evaluation of large scale {RoI} mining applications in edge computing environments},
	isbn = {978-1-66543-326-6},
	url = {https://doi.org/10.1109/DS-RT52167.2021.9576131},
	doi = {10.1109/DS-RT52167.2021.9576131},
	series = {{DS}-{RT} '21},
	abstract = {Researchers and leading {IT} companies are increasingly proposing hybrid cloud/edge solutions, which allow to move part of the workload from the cloud to the edge nodes, by reducing the network traffic and energy consumption, but also getting low latency responses near to real time. This paper proposes a novel hybrid cloud/edge architecture for efficiently extracting Regions-of-Interest ({RoI}) in a large scale urban computing environment, where a huge amount of geotagged data are generated and collected through users's mobile devices. The proposal is organized in two parts: (i) a modeling part that defines the hybrid cloud/edge architecture capable of managing a large number of devices; (ii) a simulation part in which different design choices are evaluated to improve the performance of {RoI} mining algorithms in terms of processing time, network delay, task failure and computing resource utilization. Several experiments have been carried out to evaluate the performance of the proposed architecture starting from different configurations and orchestration policies. The achieved results showed that the proposed hybrid cloud/edge architecture, with the use of two novel orchestration policies (network- and utilization-based), permits to improve the exploitation of resources, also granting low network latency and task failure rate in comparison with other standard scenarios (only-edge or only-cloud).},
	pages = {1--8},
	booktitle = {Proceedings of the 2021 {IEEE}/{ACM} 25th International Symposium on Distributed Simulation and Real Time Applications},
	publisher = {{IEEE} Press},
	author = {Belcastro, Loris and Falcone, Alberto and Garro, Alfredo and Marozzo, Fabrizio},
	urldate = {2022-11-21},
	date = {2022-01},
	keywords = {cloud/edge architecture, {IoT} platforms, modeling and simulation, orchestration policies, {RoI} mining},
}

@inproceedings{sethi_mobicache_2022,
	location = {New York, {NY}, {USA}},
	title = {{MobiCache}: a mobility-aware caching technique in vehicular edge computing},
	isbn = {978-1-4503-9181-8},
	url = {https://doi.org/10.1145/3495243.3558266},
	doi = {10.1145/3495243.3558266},
	series = {{MobiCom} '22},
	shorttitle = {{MobiCache}},
	abstract = {Vehicular edge computing ({VEC}) brings computational resources at the edge of vehicular networks ({VANETs}). In {VEC}, the roadside unit ({RSU}) across the road segment acts as an edge server. The vehicle having less computational capability offloads high computation tasks to its nearby {RSU} for processing. There is a significant energy consumption occurs at the {RSU} in computing each high computation task. To minimize the energy consumption, a caching technique is used at {RSUs}. The greatest challenge of caching in {VEC} is the mobility of vehicles. In this poster, we propose a Mobility-Aware Caching technique ({MobiCache}) in {VEC}. {MobiCache} uses an actor-critic deep reinforcement learning framework to find the best routes for migrating the popular cache contents of {RSUs} according to the mobility pattern of vehicles. Simulation results show that our proposed caching strategy reduces the energy consumption by an average of 39.54\% as compared to other existing caching techniques.},
	pages = {868--870},
	booktitle = {Proceedings of the 28th Annual International Conference on Mobile Computing And Networking},
	publisher = {Association for Computing Machinery},
	author = {Sethi, Vivek and Pal, Sujata},
	urldate = {2022-11-21},
	date = {2022-10},
	keywords = {computation offloading, computational caching, energy optimization, vehicular edge computing},
}

@inproceedings{de_almeida_souza_poster_2022,
	location = {New York, {NY}, {USA}},
	title = {Poster: Safe Gate – {IoT} system to support sanitary measures to combat {COVID}-19},
	isbn = {978-1-4503-8566-4},
	url = {https://doi.org/10.1145/3494322.3494699},
	doi = {10.1145/3494322.3494699},
	series = {{IoT} '21},
	shorttitle = {Poster},
	abstract = {The {COVID}-19 pandemic crisis raised public health attention closer to our global society’s demands. The disease proliferation occurs typically by droplet transmission, by being close to an infected person. Social distancing, a natural solution, is not always applicable to everyday needs, such as in the public transportation system, which is a space highly susceptible to viral proliferation. A set of ways to reduce proliferation in these infrastructures is by reinforcing facial masks usage, restraining symptomatic users, and reducing physical contact with public devices. Safe Gate, an Internet of Things ({IoT}) solution to enforce containment measures for disease proliferation, is proposed in this paper. This {IoT} solution is based on a network of edge computing devices used to control access to the entrance gate of the stations. The edge devices service samples an user’s temperature and facial image to verify that body temperature is within normal bounds and the user is correctly wearing a face mask. The system is contact-free and does not require an active operator, with no personal data stored, preserving privacy. Additionally, it minimizes personnel involvement with passengers, ensuring staff protection. The research question is whether the solution with two levels of facial recognition using cognitive edge computing will meet the requirements of a real system. In addition to this question, a queuing model to verify the feasibility of the solution is presented and evaluates the operational impact on a real transportation system.},
	pages = {211--214},
	booktitle = {11th International Conference on the Internet of Things},
	publisher = {Association for Computing Machinery},
	author = {de Almeida Souza, Gabriel and de Carvalho Bertoli, Gustavo and Torres Ferreira, Guilherme and Leitao Albuquerque de Farias, Julio Cesar and A. C. Cesar, Cecilia},
	urldate = {2022-11-21},
	date = {2022-03},
	keywords = {{IoT}, Edge Computing, {COVID}-19, Queueing Model, Solution Design},
}

@inproceedings{ma_mobility-aware_2022,
	location = {New York, {NY}, {USA}},
	title = {Mobility-aware Task Splitting and Computation Resource Allocation for Distributed Multi-access Edge Computing Enabled Vehicular Network},
	isbn = {978-1-4503-8520-6},
	url = {https://doi.org/10.1145/3518781.3519206},
	doi = {10.1145/3518781.3519206},
	series = {{CMAAE} 2021},
	abstract = {When the computation capacity of connected vehicles cannot meet the ultra-low latency requirement of autonomous driving applications, the emergency of Multi-access Edge Computing ({MEC}) solves this problem effectively, where connected vehicles can offload its computation tasks to edge servers to reduce the latency. In this paper, we investigate the task splitting and computation resource allocation strategy considering the mobility of vehicles based on {MEC} enabled vehicular network to minimize the system delay. Within the computing framework of alternating direction method of multipliers ({ADMM}), we propose a computation resource allocation scheme by partially offloading vehicles’ computation tasks to an edge server to balance their computation loads. By analyzing the impact of the number of vehicles and the computation capacity on the average system delay through numerical simulation, we verify that the proposed scheme outperforms the baseline schemes.},
	pages = {164--170},
	booktitle = {2021 International Conference on Mechanical, Aerospace and Automotive Engineering},
	publisher = {Association for Computing Machinery},
	author = {Ma, Guifu and Li, Haoran and Wang, Xiaowei and Chen, Xiaolong and Bian, Yougang and Hu, Manjiang and Wang, Xuepeng and Zhang, Jin},
	urldate = {2022-11-21},
	date = {2022-06},
	keywords = {Resource allocation, Multi-access edge computing, Connected vehicles, Task splitting},
}

@inproceedings{zhou_nestfl_2022,
	location = {New York, {NY}, {USA}},
	title = {{NestFL}: efficient federated learning through progressive model pruning in heterogeneous edge computing},
	isbn = {978-1-4503-9181-8},
	url = {https://doi.org/10.1145/3495243.3558248},
	doi = {10.1145/3495243.3558248},
	series = {{MobiCom} '22},
	shorttitle = {{NestFL}},
	abstract = {In this paper, we present {NestFL}, a learning-efficient {FL} framework for edge computing, which can jointly improve the training efficiency and achieve personalization. Specifically, {NestFL} takes the runtime resources of the edge devices into consideration and assigns each device a sparse-structured subnetwork by progressively performing the structured pruning. During training, only the updates of these subnetworks are transmitted to the central server. Additionally, these generated subnetworks adopt a structure- and parameter-sharing mechanism, making themselves nested inside a multi-capacity global model. In doing so, the overall communication and computation costs can be significantly reduced, and each device can learn a personalized model without introducing extra parameters. Furthermore, a weighted aggregation mechanism is designed to improve the training performance and maximally preserve personalization.},
	pages = {817--819},
	booktitle = {Proceedings of the 28th Annual International Conference on Mobile Computing And Networking},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Xiaomao and Jia, Qingmin and Xie, Renchao},
	urldate = {2022-11-21},
	date = {2022-10},
	keywords = {federated learnings, model pruning, multi-capacity model, personalization},
}

@article{kizilkaya_effective_2022,
	title = {An Effective Forest Fire Detection Framework Using Heterogeneous Wireless Multimedia Sensor Networks},
	volume = {18},
	issn = {1551-6857},
	url = {https://doi.org/10.1145/3473037},
	doi = {10.1145/3473037},
	abstract = {With improvements in the area of Internet of Things ({IoT}), surveillance systems have recently become more accessible. At the same time, optimizing the energy requirements of smart sensors, especially for data transmission, has always been very important and the energy efficiency of {IoT} systems has been the subject of numerous studies. For environmental monitoring scenarios, it is possible to extract more accurate information using smart multimedia sensors. However, multimedia data transmission is an expensive operation. In this study, a novel hierarchical approach is presented for the detection of forest fires. The proposed framework introduces a new approach in which multimedia and scalar sensors are used hierarchically to minimize the transmission of visual data. A lightweight deep learning model is also developed for devices at the edge of the network to improve detection accuracy and reduce the traffic between the edge devices and the sink. The framework is evaluated using a real testbed, network simulations, and 10-fold cross-validation in terms of energy efficiency and detection accuracy. Based on the results of our experiments, the validation accuracy of the proposed system is 98.28\%, and the energy saving is 29.94\%. The proposed deep learning model’s validation accuracy is very close to the accuracy of the best performing architectures when the existing studies and lightweight architectures are considered. In terms of suitability for edge computing, the proposed approach is superior to the existing ones with reduced computational requirements and model size.},
	pages = {47:1--47:21},
	number = {2},
	journaltitle = {{ACM} Transactions on Multimedia Computing, Communications, and Applications},
	author = {Kizilkaya, Burak and Ever, Enver and Yatbaz, Hakan Yekta and Yazici, Adnan},
	urldate = {2022-11-21},
	date = {2022-02},
	keywords = {edge computing, energy efficiency, {IoT}, deep learning, heterogeneous {WMSN} architecture, {WMSNs}},
}

@inproceedings{ferreira_federated_2022,
	location = {New York, {NY}, {USA}},
	title = {A federated machine learning approach to detect international revenue share fraud on the 5G edge},
	isbn = {978-1-4503-8713-2},
	url = {https://doi.org/10.1145/3477314.3507322},
	doi = {10.1145/3477314.3507322},
	series = {{SAC} '22},
	abstract = {The fifth-generation (5G) of broadband cellular networks is giving rise to new paradigms of distributed computing, such as Edge Computing and Multi-access Edge Computing ({MEC}). The possibility of hosting Machine Learning ({ML}) applications close to the end-users presents advantages, such as better privacy (e.g., sensitive data is not shared to other systems), the reduction of communication latency, improvement of application performance, and more efficient energy consumption. However, the Edge Computing and {MEC} paradigms also pose challenges to {ML}. For instance, the data can be distributed among distinct edges and might not be shared (e.g., due to privacy issues). Also, the {ML} models might be trained on edge devices with limited computational resources. In this paper, we propose a Federated {ML} architecture to train {ML} models on the 5G Edge, using decentralized data and light {ML} training algorithms. Our architecture includes edge nodes to train models with local data and a centralized node to aggregate the resulting models. As a case study, we address an International Revenue Share Fraud ({IRSF}) task, assuming a real-world dataset collected from a leading provider of analytics solutions for the Telecom industry. We evaluate our architecture during two iterations of a Federated {ML} procedure and then we compare it with a centralized baseline {ML} model that is currently adopted by the software company. Overall, the experimental results show that the proposed Federated {ML} approach outperforms the baseline {ML} model, thus supporting its potential usage to detect {IRSF} on the 5G mobile network edge.},
	pages = {1432--1439},
	booktitle = {Proceedings of the 37th {ACM}/{SIGAPP} Symposium on Applied Computing},
	publisher = {Association for Computing Machinery},
	author = {Ferreira, Luís and Silva, Leopoldo and Pinho, Diana and Morais, Francisco and Martins, Carlos Manuel and Pires, Pedro Miguel and Fidalgo, Pedro and Rodrigues, Helena and Cortez, Paulo and Pilastri, André},
	urldate = {2022-11-21},
	date = {2022-05},
	keywords = {edge computing, multi-access edge computing, 5G networks, federated learning, machine learning},
}

@article{xavier_managing_2022,
	title = {Managing Heterogeneous and Time-Sensitive {IoT} Applications through Collaborative and Energy-Aware Resource Allocation},
	volume = {3},
	issn = {2691-1914},
	url = {https://doi.org/10.1145/3488248},
	doi = {10.1145/3488248},
	abstract = {In the Internet of Things ({IoT}) environment, the computing resources available in the cloud are often unable to meet the latency constraints of time critical applications due to the large distance between the cloud and data sources ({IoT} devices). The adoption of edge computing can help the cloud deliver services that meet time critical application requirements. However, it is challenging to meet the {IoT} application demands while using the resources smartly to reduce energy consumption at the edge of the network. In this context, we propose a fully distributed resource allocation algorithm for the {IoT}-edge-cloud environment, which (i) increases the infrastructure resource usage by promoting the collaboration between edge nodes, (ii) supports the heterogeneity and generic requirements of applications, and (iii) reduces the application latency and increases the energy efficiency of the edge. We compare our algorithm with a non-collaborative vertical offloading and with a horizontal approach based on edge collaboration. Results of simulations showed that the proposed algorithm is able to reduce 49.95\% of the {IoT} application request end-to-end latency, increase 95.35\% of the edge node utilization, and enhance the energy efficiency in terms of the edge node power consumption by 92.63\% in comparison to the best performances of vertical and collaboration approaches.},
	pages = {10:1--10:28},
	number = {2},
	journaltitle = {{ACM} Transactions on Internet of Things},
	author = {Xavier, Tiago C. S. and Delicato, Flavia C. and Pires, Paulo F. and Amorim, Claudio L. and Li, Wei and Zomaya, Albert},
	urldate = {2022-11-21},
	date = {2022-02},
	keywords = {Edge computing, Internet of Things, fog computing, resource allocation, latency, cloud, collaboration, distributed algorithm, edge, energy, energy aware, Iot, power, resource scheduling, stealing, utilization, work stealing},
}

@inproceedings{luu_vei_2022,
	location = {New York, {NY}, {USA}},
	title = {{VEI}: a multicloud edge gateway for computer vision in {IoT}},
	isbn = {978-1-4503-9930-2},
	url = {https://doi.org/10.1145/3565385.3565877},
	doi = {10.1145/3565385.3565877},
	series = {{MIDDLEWEDGE} '22},
	shorttitle = {{VEI}},
	abstract = {The large scale use of real-time computer vision for {IoT} applications faces challenges of big data streams, complex processing, low latency requirements, and data privacy concerns. Edge computing allows data to be processed close to the source, vastly reducing the data that needs to be sent to the cloud, thus reducing network bandwidth requirements, and lowering application latency. Additionally, sensitive video streams can be confined to the privacy perimeter of the end-user. However, current {IoT} edge middleware are designed for low data rate sensor applications, and do not satisfy the demanding needs of computer vision-based {IoT}. In this paper, we present the design and implementation of a novel edge gateway targeted specifically at emerging {IoT} computer vision applications. The proposed edge gateway enables realization of multiple vision algorithms at the edge from a single camera stream. Furthermore, unlike existing edge gateways available from public cloud service providers, the proposed gateway is vendor-neutral, and capable of connecting to multiple cloud providers. This allows for increased application resilience, lower costs, and avoids cloud vendor lock-in. We experimentally evaluate the performance of the proposed edge gateway for multiple computer vision applications, and multiple public clouds.},
	pages = {6--11},
	booktitle = {Proceedings of the 1st Workshop on Middleware for the Edge},
	publisher = {Association for Computing Machinery},
	author = {Luu, Samantha and Ravindran, Arun and Pazho, Armin Danesh and Tabkhi, Hamed},
	urldate = {2022-11-21},
	date = {2022-11},
	keywords = {edge computing, {IoT}, computer vision, multi-cloud},
}

@inproceedings{shaowang_sensor_2022,
	location = {New York, {NY}, {USA}},
	title = {Sensor fusion on the edge: initial experiments in the {EdgeServe} system},
	isbn = {978-1-4503-9346-1},
	url = {https://doi.org/10.1145/3530050.3532924},
	doi = {10.1145/3530050.3532924},
	series = {{BiDEDE} '22},
	shorttitle = {Sensor fusion on the edge},
	abstract = {Due to latency and privacy concerns, we are witnessing the rise of edge computing, where computation is placed close to the point of data collection to facilitate low-latency decision making. However, we believe that a very important class of sensor fusion applications, in which data generated in a disaggregated way has to be combined to make a decision, are not well understood in the context of edge computing. The necessary data needs to be in "the right place at the right time", making intra-edge communication a significant bottleneck. In prior work, we proposed an edge-based model serving system, called {EdgeServe}, that not only manages a machine learning inference service, but also orchestrates data movement between nodes on an edge network. In this paper, we evaluate trade-offs in temporal synchronization between data sources, and present initial experiments that study how different knobs can affect the performance of sensor fusion applications.},
	pages = {1--7},
	booktitle = {Proceedings of The International Workshop on Big Data in Emergent Distributed Environments},
	publisher = {Association for Computing Machinery},
	author = {Shaowang, Ted and Liang, Xi and Krishnan, Sanjay},
	urldate = {2022-11-21},
	date = {2022-06},
	keywords = {edge computing, federated inference},
}

@inproceedings{jin_distributed_2022,
	location = {New York, {NY}, {USA}},
	title = {Distributed inference for multiple {DNN} models in {IoT} environments: poster},
	isbn = {978-1-4503-9165-8},
	url = {https://doi.org/10.1145/3492866.3561254},
	doi = {10.1145/3492866.3561254},
	series = {{MobiHoc} '22},
	shorttitle = {Distributed inference for multiple {DNN} models in {IoT} environments},
	abstract = {Edge Computing ({EC}) has been promising in providing support for Deep Neural Network ({DNN}) applications in {IoT} environments. However, resources in each edge are limited as response time increases. To reduce the latency, we propose to distribute the computation of multiple {DNN} models to nearby {IoT} devices. In particular, we propose a piece-wise multilevel partitioning and scheduling algorithm to improve the completion time of {DNN} inference.},
	pages = {281--282},
	booktitle = {Proceedings of the Twenty-Third International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
	publisher = {Association for Computing Machinery},
	author = {Jin, {YoungHwan} and Park, {HyungBin} and Lee, {SuKyoung}},
	urldate = {2022-11-21},
	date = {2022-10},
	keywords = {{IoT}, offloading, multiple {DNNs}, piece-wise partitioning},
}

@article{ding_roadmap_2022,
	title = {Roadmap for edge {AI}: a Dagstuhl perspective},
	volume = {52},
	issn = {0146-4833},
	url = {https://doi.org/10.1145/3523230.3523235},
	doi = {10.1145/3523230.3523235},
	shorttitle = {Roadmap for edge {AI}},
	abstract = {Based on the collective input of Dagstuhl Seminar (21342), this paper presents a comprehensive discussion on {AI} methods and capabilities in the context of edge computing, referred as Edge {AI}. In a nutshell, we envision Edge {AI} to provide adaptation for data-driven applications, enhance network and radio access, and allow the creation, optimisation, and deployment of distributed {AI}/{ML} pipelines with given quality of experience, trust, security and privacy targets. The Edge {AI} community investigates novel {ML} methods for the edge computing environment, spanning multiple sub-fields of computer science, engineering and {ICT}. The goal is to share an envisioned roadmap that can bring together key actors and enablers to further advance the domain of Edge {AI}.},
	pages = {28--33},
	number = {1},
	journaltitle = {{ACM} {SIGCOMM} Computer Communication Review},
	author = {Ding, Aaron Yi and Peltonen, Ella and Meuser, Tobias and Aral, Atakan and Becker, Christian and Dustdar, Schahram and Hiessl, Thomas and Kranzlmüller, Dieter and Liyanage, Madhusanka and Maghsudi, Setareh and Mohan, Nitinder and Ott, Jörg and Rellermeyer, Jan S. and Schulte, Stefan and Schulzrinne, Henning and Solmaz, Gürkan and Tarkoma, Sasu and Varghese, Blesson and Wolf, Lars},
	urldate = {2022-11-21},
	date = {2022-03},
	keywords = {Edge Computing, 5G Beyond, Edge {AI}, Future Cloud, Roadmap},
}

@inproceedings{de_oliveira_knowledge_2022,
	location = {New York, {NY}, {USA}},
	title = {Knowledge graph stream processing at the edge},
	isbn = {978-1-4503-9308-9},
	url = {https://doi.org/10.1145/3524860.3539644},
	doi = {10.1145/3524860.3539644},
	series = {{DEBS} '22},
	abstract = {We present a knowledge graph management system designed to run on Edge computing devices that handles high-frequency data streams. During the design phase, we took into account the inherent limitations of the devices, i.e., limited computing power and storage space, as well as the expectations of applications, e.g., low latency, high throughput, and intelligent data management. This results in a compact, decompression-free, in-memory, streaming-enabled {RDF} store that supports continuous querying and some forms of reasoning. The system addresses efficient query processing of data continuously arriving at a fast pace and is well-adapted to event-driven applications such as anomaly and risk detection. We empirically emphasize its accuracy, robustness, latency, and throughput properties on a real-world {IoT} setting originating from the energy management domain.},
	pages = {115--125},
	booktitle = {Proceedings of the 16th {ACM} International Conference on Distributed and Event-Based Systems},
	publisher = {Association for Computing Machinery},
	author = {de Oliveira, Joffrey and Callé, Christophe and Xu, Weiqin and Calvez, Philippe and Curé, Olivier},
	urldate = {2022-11-21},
	date = {2022-07},
	keywords = {edge computing, knowledge graph, stream processing},
}

@article{fang_joint_2022,
	title = {Joint Architecture Design and Workload Partitioning for {DNN} Inference on Industrial {IoT} Clusters},
	issn = {1533-5399},
	url = {https://doi.org/10.1145/3551638},
	doi = {10.1145/3551638},
	abstract = {The advent of Deep Neural Networks ({DNNs}) has empowered numerous computer-vision applications. Due to the high computational intensity of {DNN} models, as well as the resource constrained nature of Industrial Internet-of-Things ({IIoT}) devices, it is generally very challenging to deploy and execute {DNNs} efficiently in the industrial scenarios. Substantial research has focused on model compression or edge-cloud offloading, which trades off accuracy for efficiency or depends on high-quality infrastructure support, respectively. In this article, we present {EdgeDI}, a framework for executing {DNN} inference in a partitioned, distributed manner on a cluster of {IIoT} devices. To improve the inference performance, {EdgeDI} exploits two key optimization knobs, including: (1) Model compression based on deep architecture design, which transforms the target {DNN} model into a compact one that reduces the resource requirements for {IIoT} devices without sacrificing accuracy; (2) Distributed inference based on adaptive workload partitioning, which achieves high parallelism by adaptively balancing the workload distribution among {IIoT} devices under heterogeneous resource conditions. We have implemented {EdgeDI} based on {PyTorch}, and evaluated its performance with the {NEU}-{CLS} defect classification task and two typical {DNN} models (i.e., {VGG} and {ResNet}) on a cluster of heterogeneous Raspberry Pi devices. The results indicate that the proposed two optimization approaches significantly outperform the existing solutions in their specific domains. When they are well combined, {EdgeDI} can provide scalable {DNN} inference speedups that are very close to or even much higher than the theoretical speedup bounds, while still maintaining the desired accuracy.},
	journaltitle = {{ACM} Transactions on Internet Technology},
	author = {Fang, Weiwei and Xu, Wenyuan and Yu, Chongchong and Xiong, Neal N.},
	urldate = {2022-11-21},
	date = {2022-07},
	keywords = {edge computing, deep learning, distributed inference, {DNN} architecture, Industrial Internet-of-Things ({IIoT})},
}

@inproceedings{zhou_iot_2022,
	location = {New York, {NY}, {USA}},
	title = {{IOT} Data Storage Solution Based on Hybrid Blockchain Edge Architecture},
	isbn = {978-1-4503-8408-7},
	url = {https://doi.org/10.1145/3488933.3489012},
	doi = {10.1145/3488933.3489012},
	series = {{AIPR} 2021},
	abstract = {In order to solve the problem of inefficient data storage and high latency in the case of a large number of {IoT} devices networked, for this purpose, this paper implements a data storage scheme for {IoT} devices based on blockchain and edge computing architecture, using an interstellar file system network formed by edge computing servers as nodes to achieve distributed localized storage of data and storing data hash addresses into the blockchain. Combined with smart contracts and an attribute-based access control framework, secure dynamic fine-grained access control of data and behavior tracking of visitors are achieved. Experiments show that the proposed scheme can effectively reduce data transmission latency, as well as lower latency request response and higher throughput, which also makes it more compatible with the current multi-user and multi-request access requirements in the {IoT} environment.},
	pages = {466--471},
	booktitle = {2021 4th International Conference on Artificial Intelligence and Pattern Recognition},
	publisher = {Association for Computing Machinery},
	author = {Zhou, Li and Liu, Jianhua},
	urldate = {2022-11-21},
	date = {2022-02},
	keywords = {Internet of Things, Access Control, Blockchain, Data Storage, Distributed},
}

@inproceedings{carlini_network_2022,
	location = {New York, {NY}, {USA}},
	title = {Network Measurements with Function-as-a-Service for Distributed Low-latency Edge Applications},
	isbn = {978-1-4503-9310-2},
	url = {https://doi.org/10.1145/3526059.3533622},
	doi = {10.1145/3526059.3533622},
	series = {{FRAME} '22},
	abstract = {Edge computing promises to bring computation and storage close to end-users, opening exciting new areas of improvement for applications with a high level of interactivity and requiring low latency. However, these improvements require careful scheduling of applications in the correct Edge resource. This decision is generally taken by considering multiple parameters, including the network capabilities. In this paper, we discuss an approach that measures latency and bandwidth between multiple clients and Edge servers. The approach is based on recent Serverless computing technologies, and it is meant as a support to take timely and correct scheduling decisions in the Edge. We also provide the description of a proof of concept implementation of the said approach.},
	pages = {25--28},
	booktitle = {Proceedings of the 2nd Workshop on Flexible Resource and Application Management on the Edge},
	publisher = {Association for Computing Machinery},
	author = {Carlini, Emanuele and Kavalionak, Hanna and Dazzi, Patrizio and Ferrucci, Luca and Coppola, Massimo and Mordacchini, Matteo},
	urldate = {2022-11-21},
	date = {2022-06},
	keywords = {edge computing, latency measurement, serverless computing},
}

@inproceedings{sun_gradient_2022,
	location = {New York, {NY}, {USA}},
	title = {Gradient Privacy-Preserving In Federated Learning via Proxy Re-Encryption},
	isbn = {978-1-4503-9683-7},
	url = {https://doi.org/10.1145/3561877.3561893},
	doi = {10.1145/3561877.3561893},
	series = {{ICISS} 2022},
	abstract = {For decentralized computing systems like cloud and edge computing, federated learning ({FL}) is an effective and safe machine learning technique. Its learning method involves frequent communication as participating local devices submit updates to a central server, which aggregates them and reassigns new weights to the devices. The updates may include gradients or model parameters. Private data is not sent outside of certain local devices in {FL}, offering a strong privacy protection solution. Since attackers can deduce the user's privacy from the local output, such as gradients, it still has some privacy problems. In order to effectively address this issue, we propose in this paper a proxy re-encryption scheme with a mask that, by incorporating a third-party proxy, effectively protects against server complicity attacks. Experiments demonstrate improved allowing the {FL} system to increase the acceptable communication cost while achieving more security features during model transmission. Moreover, our scheme is secure to honest-but-curious server setting even if the server colludes with multiple users. Overall, our system offers a safer and more precise system for {FL}.},
	pages = {100--106},
	booktitle = {2022 the 5th International Conference on Information Science and Systems},
	publisher = {Association for Computing Machinery},
	author = {Sun, Yipeng and Yang, Yuexiang},
	urldate = {2022-11-21},
	date = {2022-11},
	keywords = {arithmetic masks, Federated learning, privacy computing, proxy re-encryption},
}

@article{ren_towards_2022,
	title = {Towards Semantic Management of On-Device Applications in Industrial {IoT}},
	volume = {22},
	issn = {1533-5399},
	url = {https://doi.org/10.1145/3510820},
	doi = {10.1145/3510820},
	abstract = {The Internet of Things ({IoT}) is revolutionizing the industry. Powered by pervasive embedded devices, the Industrial {IoT} ({IIoT}) provides a unique solution for retrieving and analyzing data near the source in real-time. Many emerging techniques, such as Tiny Machine Learning ({TinyML}) and Complex Event Processing ({CEP}), are actively being developed to support decision making at the edge, shifting the paradigm from centralized processing to distributed computing. However, distributed computing presents management challenges, as {IoT} devices are diverse and constrained, and their number is growing exponentially. The situation is even more challenging when various on-device applications (so-called artifacts) are deployed across decentralized {IoT} networks. Questions to be addressed include how to discover an appropriate function, whether that function can be executed on a certain device, and how to orchestrate a cross-platform service. To tackle these challenges, we propose an approach for the scalable management of on-device applications among distributed {IoT} devices. By leveraging the W3C Web of Things ({WoT}), the capabilities of each {IoT} device, or more precisely, its interaction patterns, can be semantically expressed in a Thing Description ({TD}). In addition, we introduce semantic modeling of on-device applications to supplement an {TD} with additional information regarding applications on the device. Specifically, we demonstrate two examples of semantic modeling: neural networks ({NN}) and {CEP} rules. The ontologies are evaluated by answering a set of competency questions. By hosting the enriched semantic knowledge of the entire {IoT} system in a Knowledge Graph ({KG}), we can discover and interoperate edge devices and artifacts across the decentralized network. This can reduce fragmentation and increase the reusability of {IoT} components. We demonstrate the feasibility of our concept on an industrial workstation consisting of a conveyor belt and several {IoT} devices. Finally, the requirements for constructing an {IoT} semantic management system are discussed.},
	pages = {102:1--102:30},
	number = {4},
	journaltitle = {{ACM} Transactions on Internet Technology},
	author = {Ren, Haoyu and Anicic, Darko and Runkler, Thomas A.},
	urldate = {2022-11-21},
	date = {2022-11},
	keywords = {complex event processing, Industrial {IoT}, neural network, semantic management, semantic modeling, Tiny machine learning},
}

@inproceedings{chabi_sika_boni_task_2022,
	location = {New York, {NY}, {USA}},
	title = {Task Offloading in Autonomous {IoT} Systems using Deep Reinforcement Learning and ns3-gym},
	isbn = {978-1-4503-8566-4},
	url = {https://doi.org/10.1145/3494322.3494325},
	doi = {10.1145/3494322.3494325},
	series = {{IoT} '21},
	abstract = {{IoT} systems grow quickly and are massively present in urban areas. Their successful deployment requires autonomy that can be built on automated learning technologies such as Deep Learning. The {IoT} applications require important computational resources, rarely available on devices. Autonomous {IoT} systems require the computation power available on the edge and cloud servers in order to offload some tasks related to the supported applications and the underlying platforms. Task offloading constitutes a big challenge in autonomous {IoT} systems due to the huge number of {IoT} devices for scenarios of the family of smart cities. Managing task offloading in such contexts requires adaptive strategies capable of taking into consideration the rapid evolution of available resources and proposing efficient offloading solutions to all received requests. In this paper we use a Deep Reinforcement Learning ({DRL}) approach capable of handling large state spaces, and resolve the optimization problem in this context, where other techniques can not scale efficiently. Our solution is based on a {DRL} agent that was developed in the ns3-gym framework and was tested on {IoT} system scenario implemented in the {NS}3 simulator. The results obtained show that the {DRL} agent can adapt quickly to resource evolution in the {IoT} system and can handle big number of demands fulfilling scalabilty requirements of autonomous {IoT} systems.},
	pages = {17--24},
	booktitle = {11th International Conference on the Internet of Things},
	publisher = {Association for Computing Machinery},
	author = {Chabi Sika Boni, Abdel Kader and Hassan, Hassan and Drira, Khalil},
	urldate = {2022-11-21},
	date = {2022-03},
	keywords = {Autonomous {IoT} systems, Deep Reinforcement Learning, Task offloading},
}

@inproceedings{garcia_santaclara_prototype_2022,
	location = {New York, {NY}, {USA}},
	title = {Prototype of deployment of Federated Learning with {IoT} devices},
	isbn = {978-1-4503-9483-3},
	url = {https://doi.org/10.1145/3551663.3558681},
	doi = {10.1145/3551663.3558681},
	series = {{PE}-{WASUN} '22},
	abstract = {In the age of technology, data is an increasingly important resource. This importance is growing in the field of Artificial Intelligence ({AI}), where sub fields such as Machine Learning ({ML}) need more and more data to achieve better results. Internet of Things ({IoT}) is the connection of sensors and smart objects to collect and exchange data, in addition to achieving many other tasks. A huge amount of the resource desired, data, is stored in mobile devices, sensors and other Internet of Things ({IoT}) devices, but remains there due to data protection restrictions. At the same time these devices do not have enough data or computational capacity to train good models. Moreover, transmitting, storing and processing all this data on a centralised server is problematic. Federated Learning ({FL}) provides an innovative solution that allows devices to learn in a collaborative way. More importantly, it accomplishes this without violating data protection laws. {FL} is currently growing, and there are several solutions that implement it. This article presents a prototype of a {FL} solution where the {IoT} devices used were raspberry pi boards. The results compare the performance of a solution of this type with those obtained in traditional approaches. In addition, the {FL} solution performance was tested in a hostile environment. A convolutional neural network ({CNN}) and a image data set were used. The results show the feasibility and usability of these techniques, although in many cases they do not reach the performance of traditional approaches.},
	pages = {9--16},
	booktitle = {Proceedings of the 19th {ACM} International Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, \& Ubiquitous Networks},
	publisher = {Association for Computing Machinery},
	author = {García Santaclara, Pablo and Fernández Vilas, Ana and Díaz Redondo, Rebeca P.},
	urldate = {2022-11-21},
	date = {2022-10},
	keywords = {privacy, deep learning, federated learning, machine learning, distributed learning, internet of things, {MQTT}, raspberry pi},
}

@inproceedings{chen_modelling_2022,
	location = {New York, {NY}, {USA}},
	title = {Modelling Task Offloading Mobile Edge Computing},
	isbn = {978-1-4503-9571-7},
	url = {https://doi.org/10.1145/3512850.3512859},
	doi = {10.1145/3512850.3512859},
	series = {{ICCDE} 2022},
	abstract = {With the rapid growth of mobile devices (such as smart phones and {IoT} devices) and the upcoming 5G era, it has been considered that edge computing will play a significant role, which together with the Cloud server forms the Mobile Edge Computing ({MEC}) platform. In {MEC}, it is desired that the tasks originated from the mobile devices can be offloaded to run on the edge devices or on the cloud. Namely, when a mobile device deems that it can benefit from not running its task locally (in terms of reducing the execution time), it will make the offloading decision to run the task on the edge. But when the total number of tasks offloaded from the mobile devices to the edge exceeds the capacity of the edge, some tasks may be further offloaded from the edge to the cloud server. In this paper, we aim to model the task offloading behavior in {MEC}. The game theory is utilized to establish the model. The mixed strategy for each mobile device (i.e., the probability that a mobile device offloads its task) at the Nash Equilibrium is derived. Further, the makespan of all the tasks running on the {MEC} platform is modelled. The extensive experiments have been conducted and the results show that the offload game modelled in this paper works effectively.},
	pages = {15--21},
	booktitle = {2022 The 8th International Conference on Computing and Data Engineering},
	publisher = {Association for Computing Machinery},
	author = {Chen, Zhiyan and He, Ligang},
	urldate = {2022-11-21},
	date = {2022-04},
	keywords = {task offloading, mobile edge computing, game theory},
}

@inproceedings{serena_simulation_2022,
	location = {Valencia, Spain},
	title = {Simulation of hybrid edge computing architectures},
	isbn = {978-1-66543-326-6},
	url = {https://doi.org/10.1109/DS-RT52167.2021.9576121},
	doi = {10.1109/DS-RT52167.2021.9576121},
	series = {{DS}-{RT} '21},
	abstract = {Dealing with a growing amount of data is a crucial challenge for the future of information and communication technologies. More and more devices are expected to transfer data through the Internet, therefore new solutions have to be designed in order to guarantee low latency and efficient traffic management. In this paper, we propose a solution that combines the edge computing paradigm with a decentralized communication approach based on Peer-to-Peer (P2P). According to the proposed scheme, participants to the system are employed to relay messages of other devices, so as to reach a destination (usually a server at the edge of the network) even in absence of an Internet connection. This approach can be useful in dynamic and crowded environments, allowing the system to outsource part of the traffic management from the Cloud servers to end-devices. To evaluate our proposal, we carry out some experiments with the help of {LUNES}, an open source discrete events simulator specifically designed for distributed environments. In our simulations, we tested several system configurations in order to understand the impact of the algorithms involved in the data dissemination and some possible network arrangements.},
	pages = {1--8},
	booktitle = {Proceedings of the 2021 {IEEE}/{ACM} 25th International Symposium on Distributed Simulation and Real Time Applications},
	publisher = {{IEEE} Press},
	author = {Serena, Luca and Zichichi, Mirko and D'Angelo, Gabriele and Ferretti, Stefano},
	urldate = {2022-11-21},
	date = {2022-01},
	keywords = {edge computing, communication, peer-to-peer, performance evaluation, simulation},
}

@article{shin_secure_2022,
	title = {Secure and Efficient Hybrid Data Deduplication in Edge Computing},
	volume = {22},
	issn = {1533-5399},
	url = {https://doi.org/10.1145/3537675},
	doi = {10.1145/3537675},
	abstract = {As an extension of cloud computing, edge computing introduces additional intermediate devices, called edge nodes near clients, providing computing services on behalf of the central cloud more efficiently. Although edge computing brings several benefits such as low latency and bandwidth savings on the edge side, rapid increase in the amount of data transmitted to the central cloud hinders efficient utilization of the storage system on the central cloud side especially when the data from edge devices are encrypted. To mitigate this issue in a privacy-preserving manner, data deduplication techniques for encrypted data have been extensively studied to enhance both the security and efficiency in the conventional cloud system with two different approaches. A server-side secure deduplication approach protects data privacy but impairs network efficiency by allowing duplicate uploads, while a client-side one improves network efficiency but suffers from potential information leakage due to its vulnerability to the side-channel attack. In this article, we propose a hybrid secure deduplication scheme for edge computing, which guarantees both advantages of the aforementioned two approaches. Specifically, our scheme guarantees data privacy by applying the server-side deduplication technique between the client and the edge nodes and maximizes network efficiency through the client-side deduplication technique between the edge nodes and the cloud. In addition, we devise a novel additively homomorphic encryption for efficient deduplication operations in the resource-limited edge nodes. Based on our experimental results, the proposed scheme reduces the communication costs by approximately 2.5 times for a storage server when the duplicate ratio is 50\%, and the response time is reduced by about 2 times when the data size is 16 {MB}.},
	pages = {80:1--80:25},
	number = {3},
	journaltitle = {{ACM} Transactions on Internet Technology},
	author = {Shin, Hyungjune and Koo, Dongyoung and Hur, Junbeom},
	urldate = {2022-11-21},
	date = {2022-07},
	keywords = {cloud computing, edge computing, key sharing protocol, Secure data deduplication},
}

@inproceedings{qian_performance_2022,
	location = {New York, {NY}, {USA}},
	title = {Performance Evaluation of Edge Computing-Aided {IoT} Augmented Reality Systems},
	isbn = {978-1-4503-9481-9},
	url = {https://doi.org/10.1145/3551661.3561371},
	doi = {10.1145/3551661.3561371},
	series = {Q2SWinet '22},
	abstract = {Envisioned mobile augmented reality ({MAR}) ushers a new plethora of smart applications. However, the resource-constrained nature of head-mounted devices ({HMDs}) has limited the development of {MAR} systems. In this regard, edge computing has emerged as a promising solution for the processing of {MAR} computer-intensive tasks. In edge-aided {MAR} systems, {HMDs} will offload to edge nodes part of the acquired video frames, which reduces the latency and energy cost for video analytics in {MAR} systems. In this paper, we devise a queuing theory-based mathematical framework for guiding the design of {MAR} systems. The proposed mathematical framework models the characteristics of {HMDs} and edge devices, and the different network conditions. It serves as a tool for directing the decision-making in the design of {MAR} systems under different conditions and applications. Extensive numerical evaluations show that offloading frames to edge servers at a proper rate can significantly reduce the total average latency while a higher offloading rate incurs lower energy costs at {MAR} devices.},
	pages = {79--86},
	booktitle = {Proceedings of the 18th {ACM} International Symposium on {QoS} and Security for Wireless and Mobile Networks},
	publisher = {Association for Computing Machinery},
	author = {Qian, Weiyang and Coutinho, Rodolfo W. L.},
	urldate = {2022-11-21},
	date = {2022-10},
	keywords = {edge computing, internet of things, wireless augmented reality},
}

@inproceedings{he_pyramid_2022,
	location = {New York, {NY}, {USA}},
	title = {Pyramid: Enabling Hierarchical Neural Networks with Edge Computing},
	isbn = {978-1-4503-9096-5},
	url = {https://doi.org/10.1145/3485447.3511990},
	doi = {10.1145/3485447.3511990},
	series = {{WWW} '22},
	shorttitle = {Pyramid},
	abstract = {Machine learning ({ML}) is powering a rapidly-increasing number of web applications. As a crucial part of 5G, edge computing facilitates edge artificial intelligence ({AI}) by {ML} model training and inference at the network edge on edge servers. Compared with centralized cloud {AI}, edge {AI} enables low-latency {ML} inference which is critical to many delay-sensitive web applications, e.g., web {AR}/{VR}, web gaming and Web-of-Things applications. Existing studies of edge {AI} focused on resource and performance optimization in training and inference, leveraging edge computing merely as a tool to accelerate training and inference processes. However, the unique ability of edge computing to process data with context awareness, a powerful feature for building the web-of-things for smart cities, has not been properly explored. In this paper, we propose a novel framework named Pyramid that unleashes the potential of edge {AI} by facilitating homogeneous and heterogeneous hierarchical {ML} inferences. We motivate and present Pyramid with traffic prediction as an illustrative example, and evaluate it through extensive experiments conducted on two real-world datasets. The results demonstrate the superior performance of Pyramid neural networks in hierarchical traffic prediction and weather analysis.},
	pages = {1860--1870},
	booktitle = {Proceedings of the {ACM} Web Conference 2022},
	publisher = {Association for Computing Machinery},
	author = {He, Qiang and Dong, Zeqian and Chen, Feifei and Deng, Shuiguang and Liang, Weifa and Yang, Yun},
	urldate = {2022-11-21},
	date = {2022-04},
	keywords = {edge computing, machine learning, edge {AI}, Web of Things},
}

@article{xu_psdf_2022,
	title = {{PSDF}: Privacy-aware {IoV} Service Deployment with Federated Learning in Cloud-Edge Computing},
	volume = {13},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3501810},
	doi = {10.1145/3501810},
	shorttitle = {{PSDF}},
	abstract = {Through the collaboration of cloud and edge, cloud-edge computing allows the edge that approximates end-users undertakes those non-computationally intensive service processing of the cloud, reducing the communication overhead and satisfying the low latency requirement of Internet of Vehicle ({IoV}). With cloud-edge computing, the computing tasks in {IoV} is able to be delivered to the edge servers ({ESs}) instead of the cloud and rely on the deployed services of {ESs} for a series of processing. Due to the storage and computing resource limits of {ESs}, how to dynamically deploy partial services to the edge is still a puzzle. Moreover, the decision of service deployment often requires the transmission of local service requests from {ESs} to the cloud, which increases the risk of privacy leakage. In this article, a method for privacy-aware {IoV} service deployment with federated learning in cloud-edge computing, named {PSDF}, is proposed. Technically, federated learning secures the distributed training of deployment decision network on each {ES} by the exchange and aggregation of model weights, avoiding the original data transmission. Meanwhile, homomorphic encryption is adopted for the uploaded weights before the model aggregation on the cloud. Besides, a service deployment scheme based on deep deterministic policy gradient is proposed. Eventually, the performance of {PSDF} is evaluated by massive experiments.},
	pages = {70:1--70:22},
	number = {5},
	journaltitle = {{ACM} Transactions on Intelligent Systems and Technology},
	author = {Xu, Xiaolong and Liu, Wentao and Zhang, Yulan and Zhang, Xuyun and Dou, Wanchun and Qi, Lianyong and Bhuiyan, Md Zakirul Alam},
	urldate = {2022-11-21},
	date = {2022-10},
	keywords = {privacy preservation, federated learning, Cloud-edge computing, {IoV}},
}

@inproceedings{ju_proactive_2022,
	location = {New York, {NY}, {USA}},
	title = {Proactive autoscaling for edge computing systems with kubernetes},
	isbn = {978-1-4503-9163-4},
	url = {https://doi.org/10.1145/3492323.3495588},
	doi = {10.1145/3492323.3495588},
	series = {{UCC} '21},
	abstract = {With the emergence of the Internet of Things and 5G technologies, the edge computing paradigm is playing increasingly important roles with better availability, latency-control and performance. However, existing autoscaling tools for edge computing applications do not utilize heterogeneous resources of edge systems efficiently, leaving scope for performance improvement. In this work, we propose a Proactive Pod Autoscaler ({PPA}) for edge computing applications on Kubernetes. The proposed {PPA} is able to forecast workloads in advance with multiple user-defined/customized metrics and to scale edge computing applications up and down correspondingly. The {PPA} is optimized and evaluated on an example {CPU}-intensive edge computing application further. It can be concluded that the proposed {PPA} outperforms the default pod autoscaler of Kubernetes on both efficiency of resource utilization and application performance. The article also highlights future possible improvements on the proposed {PPA}.},
	pages = {1--8},
	booktitle = {Proceedings of the 14th {IEEE}/{ACM} International Conference on Utility and Cloud Computing Companion},
	publisher = {Association for Computing Machinery},
	author = {Ju, Li and Singh, Prashant and Toor, Salman},
	urldate = {2022-11-21},
	date = {2022-02},
	keywords = {edge computing, autoscaling, kubernetes, proactive autoscaling},
}

@inproceedings{makris_towards_2022,
	location = {New York, {NY}, {USA}},
	title = {Towards a Distributed Storage Framework for Edge Computing Infrastructures},
	isbn = {978-1-4503-9310-2},
	url = {https://doi.org/10.1145/3526059.3533617},
	doi = {10.1145/3526059.3533617},
	series = {{FRAME} '22},
	abstract = {Due to the continuous development of Internet of Things ({IoT}), the volume of the data these devices generate are expected to grow dramatically in the future. As a result, managing and processing such massive data amounts at the edge becomes a vital issue. Edge computing moves data and computation closer to the client enabling latency- and bandwidth-sensitive applications, that would not be feasible using cloud and remote processing alone. Nevertheless, implementing an efficient edge-enabled storage system is challenging due to the distributed and heterogeneous nature of the edge and its limited resource capabilities. To this end, we propose a lightweight hybrid distributed edge/cloud storage framework which aims to improve the Quality of Experience ({QoE}) of the end-users by migrating data close to them, thus reducing data transfers delays and network utilization. The proposed edge storage component ({ESC}) exploits the Dynamic Lifecycle Framework, in order to enable transparent and automated access for containerized applications to remote workloads. The effectiveness of the {ESC} is evaluated by employing a number of resource utilization and Quality of Service ({QoS}) metrics.},
	pages = {9--14},
	booktitle = {Proceedings of the 2nd Workshop on Flexible Resource and Application Management on the Edge},
	publisher = {Association for Computing Machinery},
	author = {Makris, Antonios and Psomakelis, Evangelos and Theodoropoulos, Theodoros and Tserpes, Konstantinos},
	urldate = {2022-11-21},
	date = {2022-06},
	keywords = {cloud computing, edge computing, internet of things, kubernetes, container-based, edge storage, minio, virtualization},
}

@article{zhou_providing_2022,
	title = {Providing Reliable Service for Parked-vehicle-assisted Mobile Edge Computing},
	volume = {22},
	issn = {1533-5399},
	url = {https://doi.org/10.1145/3514242},
	doi = {10.1145/3514242},
	abstract = {Nowadays, a growing number of computation-intensive applications appear in our daily life. Those applications make the loads of both the core network and the mobile devices, in terms of energy and bandwidth, hugely increase. Offloading computation-intensive tasks to edge cloud is proposed to address this issue. Since edge clouds have limited computation resources compared with the remote cloud, they would get over-loaded because of the heavy computation burden. Parked-vehicle-assisted mobile edge computing becomes one of the promising solutions for this problem. However, several critical issues in parked-vehicle-assisted mobile edge computing would result in low reliable edge service. The open environment would bring about uncertainty, and the data privacy is hard to ensure. In addition, different from edge cloud, each parked vehicle only has limited parking duration and can leave unexpectedly for personal reasons. Moreover, edge cloud and vehicle adopt different execution models of computation and communication. The heterogeneous environment may result in negative effect on cooperativeness. Ignoring those issues can result in substantial performance degradation. To tackle this challenge and explore the benefits of parked-vehicle-assisted offloading, we study the task offloading and resource-allocation problem by fully considering the above issues. First, we propose a resource-management scheme to address the privacy issue. Second, we review the execution model of computation and communication in parked-vehicle-assisted computation offloading. Then, we formulate the problem into a mixed-integer nonlinear programming. The problem is hard to tackle due to its non-convex nature, which means that the time complexity of finding global optimal solution is unaffordable. Finally, we decompose the original problem into two sub-problems with lower complexity, and related algorithms are given to deal with the sub-problems. Simulation results demonstrate the effectiveness of the proposed solution.},
	pages = {91:1--91:24},
	number = {4},
	journaltitle = {{ACM} Transactions on Internet Technology},
	author = {Zhou, Ao and Ma, Xiao and Gao, Siyi and Wang, Shangguang},
	urldate = {2022-11-21},
	date = {2022-11},
	keywords = {task offloading, Mobile edge computing, resource allocation, parked vehicle, reliable service},
}

@article{yao_differential_2023,
	title = {Differential privacy in edge computing-based smart city Applications:Security issues, solutions and future directions},
	volume = {19},
	issn = {2590-0056},
	url = {https://www.sciencedirect.com/science/article/pii/S2590005623000188},
	doi = {10.1016/j.array.2023.100293},
	shorttitle = {Differential privacy in edge computing-based smart city Applications},
	abstract = {Fast-growing smart city applications, such as smart delivery, smart community, and smart health, are generating big data that are widely distributed on the internet. {IoT} (Internet of Things) systems are at the centre of smart city applications, as traditional cloud computing is insufficient for satisfying the critical requirements of smart {IoT} systems. Due to the nature of smart city applications, massive {IoT} data may contain sensitive information; hence, various privacy-preserving methods, such as anonymity, federated learning, and homomorphic encryption, have been utilised over the years. Furthermore, limited concern has been given to the resource consumption for data privacy-preserving in edge computing environments, which are resource-constrained when compared with cloud data centres. In particular, differential privacy ({DP}) has been an effective privacy-preserving method in the edge computing environment. However, there is no dedicated study on {DP} technology with a focus on smart city applications in the edge computing environment. To fill this gap, this paper provides a comprehensive study on {DP} in edge computing-based smart city applications, covering various aspects, such as privacy models, research methods, mechanisms, and applications. Our study focuses on five areas of data privacy, including data transmitting privacy, data processing privacy, data model training privacy, data publishing privacy, and location privacy. In addition, we investigate many potential applications of {DP} in smart city application scenarios. Finally, future directions of {DP} in edge computing are envisaged. We hope this study can be a useful roadmap for researchers and practitioners in edge computing enable smart city applications.},
	pages = {100293},
	journaltitle = {Array},
	shortjournal = {Array},
	author = {Yao, Aiting and Li, Gang and Li, Xuejun and Jiang, Frank and Xu, Jia and Liu, Xiao},
	urldate = {2024-01-29},
	date = {2023-09-01},
	keywords = {Edge computing, Differential privacy, Privacy-preserving, Smart city, Smart {IoT} systems},
	file = {ScienceDirect Snapshot:C\:\\Users\\Emanuele\\Zotero\\storage\\E3CQZ9ET\\S2590005623000188.html:text/html;Yao et al. - 2023 - Differential privacy in edge computing-based smart.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\BC6B5BCV\\Yao et al. - 2023 - Differential privacy in edge computing-based smart.pdf:application/pdf},
}

@article{huso_privacy-preserving_2023,
	title = {Privacy-preserving data dissemination scheme based on Searchable Encryption, publish–subscribe model, and edge computing},
	volume = {203},
	issn = {0140-3664},
	url = {https://www.sciencedirect.com/science/article/pii/S0140366423000865},
	doi = {10.1016/j.comcom.2023.03.006},
	abstract = {Attribute-based Searchable Encryption is emerging as a promising cryptographic technique supporting data protection, flexible access control, and keyword search over encrypted data. The current scientific literature already investigated its adoption in cloud-based services and additionally explored the usage of edge computing to implement some of the cryptographic tasks in scenarios with limited computational capabilities (such as Internet of Things). In the majority of the available solutions, however, the remote cloud is still responsible for data storage, keyword search over encrypted data, and delivery tasks. Indeed, the heavy computational load generated in scenarios with multiple data producers and data consumers (never studied yet) and large communication latencies can inevitably compromise the overall system performance. To bridge this gap, this work proposes a decentralized service architecture offering privacy-preserving data dissemination, by jointly leveraging attribute-based Searchable Encryption techniques, publish–subscribe communication model, and edge computing capabilities. Here, customized Edge Servers are deployed at the network edge to (i) collect subscription requests encoded via Searchable Encryption Trapdoors, (ii) receive data publications, encrypted via Attribute-based Searchable Encryption scheme, (iii) implement keyword search over encrypted data, and (iv) deliver encrypted data only to authorized requesters. Experimental tests explored the impact of network configuration and traffic load on both communication latency and energy consumption. Obtained results demonstrated the unique ability of the proposed solution to achieve shorter data delivery delays as well as less energy consumption with respect to cloud-based alternatives.},
	pages = {262--275},
	journaltitle = {Computer Communications},
	shortjournal = {Computer Communications},
	author = {Huso, Ingrid and Sparapano, Daniele and Piro, Giuseppe and Boggia, Gennaro},
	urldate = {2024-01-29},
	date = {2023-04-01},
	keywords = {Internet of Things, Experimental evaluations, Searchable Encryption, Secure data dissemination},
	file = {Huso et al. - 2023 - Privacy-preserving data dissemination scheme based.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\V3UXNS3P\\Huso et al. - 2023 - Privacy-preserving data dissemination scheme based.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Emanuele\\Zotero\\storage\\IFALDF3K\\S0140366423000865.html:text/html},
}


@article{tan_efficient_2023,
	title = {An efficient {IoT} group association and data sharing mechanism in edge computing paradigm},
	volume = {1},
	issn = {2772-9184},
	url = {https://www.sciencedirect.com/science/article/pii/S2772918422000030},
	doi = {10.1016/j.csa.2022.100003},
	abstract = {Despite its benefits and promising future, security and privacy challenges for the {IoT} wireless communication of edge computing environment remain unaddressed. As a result, proper authentication mechanisms are critical, especially in the extreme scenario where some edge facilities are not functional. For the above consideration, in this paper we develop an efficient {IoT} group association and updating mechanism in edge computing paradigm. The proposed scheme can provide data transmission and communication guarantees for special practical scenarios. The group key updating process in our architecture only necessitates minor changes on the {EI} side, whereas the decryption information of some {IoT} devices remains constant if the devices have not been revoked. The proposed strategy can accomplish the desired security features, according to the security analysis.},
	pages = {100003},
	journaltitle = {Cyber Security and Applications},
	shortjournal = {Cyber Security and Applications},
	author = {Tan, Haowen},
	urldate = {2024-01-29},
	date = {2023-12-01},
	keywords = {{IoT}, Edge Computing, Security, Privacy-Preserving, Wireless Communication},
	file = {ScienceDirect Snapshot:C\:\\Users\\Emanuele\\Zotero\\storage\\D5PAGWII\\S2772918422000030.html:text/html;Tan - 2023 - An efficient IoT group association and data sharin.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\V3DG2XDV\\Tan - 2023 - An efficient IoT group association and data sharin.pdf:application/pdf},
}

@article{gupta_security_2023,
	title = {Security paradigm for remote health monitoring edge devices in internet of things},
	volume = {35},
	issn = {1319-1578},
	url = {https://www.sciencedirect.com/science/article/pii/S1319157822004384},
	doi = {10.1016/j.jksuci.2022.12.020},
	abstract = {The tremendous growth in the internet of things ({IoT}) technology has provided great support for e-healthcare applications. The remote health monitoring of patients at home is gaining popularity with the increase in design of number of {IoT} enabled wearable devices. The secure and efficient health data retrieval during continuous uploading of huge data on network is a challenge. In addition, another challenge exists due to limited resources available with {IoT} device to proceed efficient data retrieval. On the other hand, the edge cloud in edge computing technology provide abundant resources to its devices for various computations, storage and processing. The integration of {IoT} with edge would solve the resource constraint issue. However, efficient retrieval of health data from large pool of data would still be an issue due to {IP} based solutions offered by {IoT}. The Named Data Networking ({NDN}) is a promising solution for efficient delivery of data based on its name based content searching. This paper proposed {NDN} communication based secure remote healthcare monitoring framework by integrating {IoT} with edge computing where security to the each individual content is provided through hashing and encryption mechanism. The performance of the proposed framework is evaluated against its companion in Icarus simulator. The results proved the efficiency of our framework for content retrieval delay and cost associated in accessing the required data.},
	pages = {101478},
	number = {6},
	journaltitle = {Journal of King Saud University - Computer and Information Sciences},
	shortjournal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Gupta, Divya and Rani, Shalli and Raza, Saleem and Faseeh Qureshi, Nawab Muhammad and Mansour, Romany F. and Ragab, Mahmoud},
	urldate = {2024-01-29},
	date = {2023-06-01},
	keywords = {{IoT}, Security, Caching, Edge device, {NDN}, Remote health monitoring},
	file = {Gupta et al. - 2023 - Security paradigm for remote health monitoring edg.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\5KGASEXR\\Gupta et al. - 2023 - Security paradigm for remote health monitoring edg.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Emanuele\\Zotero\\storage\\N6H7EF3F\\S1319157822004384.html:text/html},
}

@article{le_brainyedge_2023,
	title = {{BrainyEdge}: An {AI}-enabled framework for {IoT} edge computing},
	volume = {9},
	issn = {2405-9595},
	url = {https://www.sciencedirect.com/science/article/pii/S2405959521001727},
	doi = {10.1016/j.icte.2021.12.007},
	shorttitle = {{BrainyEdge}},
	abstract = {Along with the proliferation of the Internet of Things ({IoT}) and the surge in the use of artificial intelligence ({AI}), Edge Computing has proved considerable success in reducing latency, network traffic consumption, and security risks. The convergence of {AI} and Edge Computing, emerging a brand-new paradigm called edge intelligence, has been expected to unleash the full potential of intelligent {IoT} services. Unfortunately, integrating {AI} and Edge Computing into {IoT} is highly challenging due to the concerns over {IoT} device performance, energy efficiency, and privacy. In this paper, we present {brainyEdge}, an {AI}-enabled framework for edge devices able to jointly satisfy the Quality of Experience ({QoE}) criteria of {IoT} applications. We enhanced the intelligence of {AI} models operating at edges by designing a learning procedure consisting of transfer learning and incremental learning to dynamically retrain the models with personalized and incremental data locally stored. These data are classified into private data permanently stored in edges and public data shared in the cloud. This increases the edge-cloud collaboration level while preserving data privacy. To minimize the network cost of deploying the models to edge devices, we developed a lightweight deployment paradigm supporting cloud-compression and edge-decompression based on a user-desired compression ratio. Our prototype-based evaluation results indicate the superiority of {brainyEdge} over a typical edge-cloud paradigm.},
	pages = {211--221},
	number = {2},
	journaltitle = {{ICT} Express},
	shortjournal = {{ICT} Express},
	author = {Le, Kim-Hung and Le-Minh, Khanh-Hoi and Thai, Huy-Tan},
	urldate = {2024-01-29},
	date = {2023-04-01},
	keywords = {Edge computing, {AI}-enabled framework, Artificial Intelligence, Smart {IoT}},
	file = {Le et al. - 2023 - BrainyEdge An AI-enabled framework for IoT edge c.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\65ADCNAM\\Le et al. - 2023 - BrainyEdge An AI-enabled framework for IoT edge c.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Emanuele\\Zotero\\storage\\3QXJIAEZ\\S2405959521001727.html:text/html},
}

@article{gupta_prediction_2023,
	title = {Prediction of health monitoring with deep learning using edge computing},
	volume = {25},
	issn = {2665-9174},
	url = {https://www.sciencedirect.com/science/article/pii/S2665917422002380},
	doi = {10.1016/j.measen.2022.100604},
	abstract = {Today's modern computing environment provides a smart healthcare monitoring system for early prediction of fall detection. The Internet of Things-based health model plays a significant role in the health care service area and helps to improve the processing of data and its prediction. Transferring reports or data from one place to another takes too much time and energy, and it will cause high latency and energy issues. To handle these kinds of hazards, edge computing provides solutions. In this paper w presents smart healthcare system issues, services, and applications. Furthermore, propose a {CNN}-based prediction model with the use of edge computing and {IoT} paradigms. Edge computing is a distributed environment framework that enables rapid resource availability and response time through local edge servers computed at the end of {IoT} devices. The {CNN} model is used to analyse the health data collected by {IoT} devices. Furthermore, the role of edge devices is to provide doctors and patients with timely health-prediction reports via edge servers. The proposed mechanism can be analysed using accuracy and error rate performance parameters. In the proposed mechanism, the accuracy is 99.23\% in comparison with other techniques.},
	pages = {100604},
	journaltitle = {Measurement: Sensors},
	shortjournal = {Measurement: Sensors},
	author = {Gupta, Piyush and Chouhan, Ajay Veer and Wajeed, Mohammed Abdul and Tiwari, Shivam and Bist, Ankur Singh and Puri, Shiv Charan},
	urldate = {2024-01-29},
	date = {2023-02-01},
	keywords = {Edge computing, Healthcare, Health monitoring, {IoT} and {CNN}},
	file = {Gupta et al. - 2023 - Prediction of health monitoring with deep learning.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\XMG32SVW\\Gupta et al. - 2023 - Prediction of health monitoring with deep learning.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Emanuele\\Zotero\\storage\\44S94Z8B\\S2665917422002380.html:text/html},
}

@article{ajao_secure_2023,
	title = {Secure edge computing vulnerabilities in smart cities sustainability using petri net and genetic algorithm-based reinforcement learning},
	volume = {18},
	issn = {2667-3053},
	url = {https://www.sciencedirect.com/science/article/pii/S2667305323000418},
	doi = {10.1016/j.iswa.2023.200216},
	abstract = {The Industrial Internet of Things ({IIoT}) revolution has emerged as a promising network that enhanced information dissemination about the city's resources. This city's resources are wirelessly connected to different constrained devices (such as sensors, robotics, and actuators). However, the communication of this wireless information is threatened by several malicious attacks, cyber-attacks, and hackers. This is due to unsecured {IIoT} networks that were exposed as a potential back door entry point for the attacks. Consequently, this study aims to develop a security framework for the smart cities’ sustainability edge computing vulnerabilities using Petri Net and Genetic Algorithm-Based Reinforcement Learning ({GARL}). First, a common trust model for addressing information outflows in the network using a distributed authorization algorithm is proposed. This algorithm is implemented on a secure framework modeling in Petri Net called secure trust-aware philosopher privacy and authentication ({STAPPA}) for mitigation of the privacy breach in the networks. Genetic Algorithm-based Reinforcement Learning ({GARL}) is used to optimize the search, detect anomalies, and shortest route during the agent learning in the environment. The detection and accuracy rate results obtained over a secure framework using reinforcement learning are 98.75, 99, 99.50, 99.75, and 100\% during simulation in the network environment. The average sensitivity of the detection rate is 1.000, while the average specificity outcome is 0.868. The result of the {GARL} simulation model obtained shows the best distance of 238.84 * 10−3 fitness when the search space is optimized by reducing the number of chromosomes to 10 in the model. These approaches help to detect anomalies and prevent unauthorized users from accessing edge computing components in the city architecture.},
	pages = {200216},
	journaltitle = {Intelligent Systems with Applications},
	shortjournal = {Intelligent Systems with Applications},
	author = {Ajao, Lukman Adewale and Apeh, Simon Tooswem},
	urldate = {2024-01-29},
	date = {2023-05-01},
	keywords = {Edge computing, Smart cities, Reinforcement learning, Fog computing, Industrial internet of things},
	file = {Ajao e Apeh - 2023 - Secure edge computing vulnerabilities in smart cit.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\U473SGP2\\Ajao e Apeh - 2023 - Secure edge computing vulnerabilities in smart cit.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Emanuele\\Zotero\\storage\\PPXWUJCY\\S2667305323000418.html:text/html},
}

@article{foko_sindjoung_data_2023,
	title = {A data security and privacy scheme for user quality of experience in a Mobile Edge Computing-based network},
	volume = {19},
	issn = {2590-0056},
	url = {https://www.sciencedirect.com/science/article/pii/S2590005623000292},
	doi = {10.1016/j.array.2023.100304},
	abstract = {Cloud computing has widely been used for applications that require huge computational and data storage resources. Unfortunately, with the advent of new technologies such as fifth generation of cellular networks that provide new applications like {IoT}, cloud computing presents many limits among which the End-To-End (E2E) latency is the main challenge. These applications generally degrade scenarios that require low latency. Mobile Edge Computing ({MEC}) has been proposed to solve this issue. {MEC} brings computing and storage resources from cloud data center to edge data center, closer to end-user equipment to reduce the E2E latency for request processing. However, {MEC} is vulnerable to security, data privacy, and authentication that affect the end-user Quality of Experience ({QoE}). It is therefore fundamental that these challenges are addressed to avoid poor user experience due to the lack of security or data privacy. In this paper, we propose a hybrid cryptographic system that uses the symmetric and asymmetric cryptographic systems, to improve data security, privacy, and user authentication in a {MEC}-based network. We show that our proposed scheme is secured by validating it with the Automated Validation of Internet Security Protocol and Application tool. Simulation results show that our solution consumes less computing resources.},
	pages = {100304},
	journaltitle = {Array},
	shortjournal = {Array},
	author = {Foko Sindjoung, Miguel Landry and Velempini, Mthulisi and Tayou Djamegni, Clémentin},
	urldate = {2024-01-29},
	date = {2023-09-01},
	keywords = {Quality of service, Mobile edge computing, Autonomous vehicular network, Data security and privacy, User authentication, User quality of experience},
	file = {Foko Sindjoung et al. - 2023 - A data security and privacy scheme for user qualit.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\M62XE2B8\\Foko Sindjoung et al. - 2023 - A data security and privacy scheme for user qualit.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Emanuele\\Zotero\\storage\\XKFL29DW\\S2590005623000292.html:text/html},
}

@article{garro_maritime_2023,
	title = {Maritime terminals’ cargo handling equipment cooperation leveraging {IoT} and edge computing: The {ASSIST}-{IoT} approach},
	volume = {72},
	issn = {2352-1465},
	url = {https://www.sciencedirect.com/science/article/pii/S2352146523011298},
	doi = {10.1016/j.trpro.2023.11.831},
	series = {{TRA} Lisbon 2022 Conference Proceedings Transport Research Arena ({TRA} Lisbon 2022),14th-17th November 2022, Lisboa, Portugal},
	shorttitle = {Maritime terminals’ cargo handling equipment cooperation leveraging {IoT} and edge computing},
	abstract = {Port container terminals with their logistic infrastructure are essential nodes for a functional economic activity in the developed world. Hence, innovation in efficiency of the port-container industry is a fundamental issue. This paper presents a Next Generation {IoT} architecture inspired by the merging of commercial terminal-oriented {ICT} solutions with the results of H2020 research. The architecture is designed to overcome the constraints and meet requirements of a real scenario in maritime ports where different Container Handling Equipment must share heterogeneous data in a decentralized way, leveraging edge computing. This allows for their easier cooperation and avoiding unproductive movements and central communication, while reducing communication latency related to terminal operations. The paper describes a usage example, accompanied with evidence of the first stages of deployment.},
	pages = {2864--2871},
	journaltitle = {Transportation Research Procedia},
	shortjournal = {Transportation Research Procedia},
	author = {Garro, Eduardo and Lacalle, Ignacio and Blanquer, Francisco and Ramos, Adrian and Martinez, Angel and Sowiński, Piotr and Llorente, Miguel Angel and Palau, Carlos},
	urldate = {2024-01-29},
	date = {2023-01-01},
	keywords = {{IoT}, edge, {ASSIST}-{IoT}, automation, container terminals, port},
	file = {Garro et al. - 2023 - Maritime terminals’ cargo handling equipment coope.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\92WDH4JK\\Garro et al. - 2023 - Maritime terminals’ cargo handling equipment coope.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Emanuele\\Zotero\\storage\\WC5UVD34\\S2352146523011298.html:text/html},
}

@article{shen_evolutionary_2023,
	title = {Evolutionary privacy-preserving learning strategies for edge-based {IoT} data sharing schemes},
	volume = {9},
	issn = {2352-8648},
	url = {https://www.sciencedirect.com/science/article/pii/S2352864822000955},
	doi = {10.1016/j.dcan.2022.05.004},
	abstract = {The fast proliferation of edge devices for the Internet of Things ({IoT}) has led to massive volumes of data explosion. The generated data is collected and shared using edge-based {IoT} structures at a considerably high frequency. Thus, the data-sharing privacy exposure issue is increasingly intimidating when {IoT} devices make malicious requests for filching sensitive information from a cloud storage system through edge nodes. To address the identified issue, we present evolutionary privacy preservation learning strategies for an edge computing-based {IoT} data sharing scheme. In particular, we introduce evolutionary game theory and construct a payoff matrix to symbolize intercommunication between {IoT} devices and edge nodes, where {IoT} devices and edge nodes are two parties of the game. {IoT} devices may make malicious requests to achieve their goals of stealing privacy. Accordingly, edge nodes should deny malicious {IoT} device requests to prevent {IoT} data from being disclosed. They dynamically adjust their own strategies according to the opponent's strategy and finally maximize the payoffs. Built upon a developed application framework to illustrate the concrete data sharing architecture, a novel algorithm is proposed that can derive the optimal evolutionary learning strategy. Furthermore, we numerically simulate evolutionarily stable strategies, and the final results experimentally verify the correctness of the {IoT} data sharing privacy preservation scheme. Therefore, the proposed model can effectively defeat malicious invasion and protect sensitive information from leaking when {IoT} data is shared.},
	pages = {906--919},
	number = {4},
	journaltitle = {Digital Communications and Networks},
	shortjournal = {Digital Communications and Networks},
	author = {Shen, Yizhou and Shen, Shigen and Li, Qi and Zhou, Haiping and Wu, Zongda and Qu, Youyang},
	urldate = {2024-01-29},
	date = {2023-08-01},
	keywords = {Edge computing, Internet of things, Privacy preservation, Data sharing, Evolutionary game},
	file = {Shen et al. - 2023 - Evolutionary privacy-preserving learning strategie.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\EJ5UQJVS\\Shen et al. - 2023 - Evolutionary privacy-preserving learning strategie.pdf:application/pdf},
}

@article{ahmed_joint_2023,
	title = {Joint optimization of {UAV}-{IRS} placement and resource allocation for wireless powered mobile edge computing networks},
	volume = {35},
	issn = {1319-1578},
	url = {https://www.sciencedirect.com/science/article/pii/S1319157823002008},
	doi = {10.1016/j.jksuci.2023.101646},
	abstract = {The rapid evolution of communication systems towards the next generation has led to an increased deployment of Internet of Things ({IoT}) devices for various real-time applications. However, these devices often face limitations in terms of processing power and battery life, which can hinder overall system performance. Additionally, applications such as augmented reality and surveillance require intensive computations within tight timeframes. This research focuses on investigating a mobile edge computing ({MEC}) network empowered by unmanned aerial vehicle intelligent reflecting surfaces ({UAV}-{IRS}) to enhance the computational energy efficiency of the system through optimized resource allocation. The {MEC} infrastructure incorporates the energy transfer circuit ({ETC}) and edge server ({ES}), co-located with the intelligent access point ({AP}). To eliminate interference between energy transfer and data transmission, a time-division multiple access method is utilized. In the first phase, the {ETC} wirelessly transfers power to low-power {IoT} devices, which efficiently harvest and store the received energy in their batteries. In the second phase, {IoT} devices employ the stored energy for local computing or offloading tasks. Furthermore, the presence of tall buildings may obstruct communication routes, impacting system functionality. To address these challenges, we propose an optimization framework that simultaneously considers time, power, phase shift design, and local computational resources. This joint optimization problem is non-convex and non-linear, making it {NP}-hard. To tackle this complexity, we decompose the problem into subproblems and solve them iteratively using a convex optimization toolbox like {CVX}. Through simulations, we demonstrate that our proposed optimization framework significantly improves 40.7\% system performance compared to alternative approaches.},
	pages = {101646},
	number = {8},
	journaltitle = {Journal of King Saud University - Computer and Information Sciences},
	shortjournal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Ahmed, Manzoor and Alshahrani, Haya Mesfer and Alruwais, Nuha and Asiri, Mashael M. and Duhayyim, Mesfer Al and Khan, Wali Ullah and khurshaid, Tahir and Nauman, Ali},
	urldate = {2024-01-29},
	date = {2023-09-01},
	keywords = {Resource allocation, Mobile edge computing, Latency, Energy consumption minimization, Intelligent reflecting surfaces, Mathematical optimization},
	file = {Ahmed et al. - 2023 - Joint optimization of UAV-IRS placement and resour.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\Q5KUIIEQ\\Ahmed et al. - 2023 - Joint optimization of UAV-IRS placement and resour.pdf:application/pdf},
}

@article{zhang_vpfl_2023,
	title = {{VPFL}: A verifiable privacy-preserving federated learning scheme for edge computing systems},
	volume = {9},
	issn = {2352-8648},
	url = {https://www.sciencedirect.com/science/article/pii/S2352864822001018},
	doi = {10.1016/j.dcan.2022.05.010},
	shorttitle = {{VPFL}},
	abstract = {Federated learning for edge computing is a promising solution in the data booming era, which leverages the computation ability of each edge device to train local models and only shares the model gradients to the central server. However, the frequently transmitted local gradients could also leak the participants’ private data. To protect the privacy of local training data, lots of cryptographic-based Privacy-Preserving Federated Learning ({PPFL}) schemes have been proposed. However, due to the constrained resource nature of mobile devices and complex cryptographic operations, traditional {PPFL} schemes fail to provide efficient data confidentiality and lightweight integrity verification simultaneously. To tackle this problem, we propose a Verifiable Privacy-preserving Federated Learning scheme ({VPFL}) for edge computing systems to prevent local gradients from leaking over the transmission stage. Firstly, we combine the Distributed Selective Stochastic Gradient Descent ({DSSGD}) method with Paillier homomorphic cryptosystem to achieve the distributed encryption functionality, so as to reduce the computation cost of the complex cryptosystem. Secondly, we further present an online/offline signature method to realize the lightweight gradients integrity verification, where the offline part can be securely outsourced to the edge server. Comprehensive security analysis demonstrates the proposed {VPFL} can achieve data confidentiality, authentication, and integrity. At last, we evaluate both communication overhead and computation cost of the proposed {VPFL} scheme, the experimental results have shown {VPFL} has low computation costs and communication overheads while maintaining high training accuracy.},
	pages = {981--989},
	number = {4},
	journaltitle = {Digital Communications and Networks},
	shortjournal = {Digital Communications and Networks},
	author = {Zhang, Jiale and Liu, Yue and Wu, Di and Lou, Shuai and Chen, Bing and Yu, Shui},
	urldate = {2024-01-29},
	date = {2023-08-01},
	keywords = {Edge computing, Federated learning, Privacy-preserving, Homomorphic cryptosystem, Verifiable aggregation},
	file = {Zhang et al. - 2023 - VPFL A verifiable privacy-preserving federated le.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\UQKDBSSV\\Zhang et al. - 2023 - VPFL A verifiable privacy-preserving federated le.pdf:application/pdf},
}

@article{truong_performance_2023,
	title = {Performance analysis and optimization of multiple {IIoT} devices radio frequency energy harvesting {NOMA} mobile edge computing networks},
	volume = {79},
	issn = {1110-0168},
	url = {https://www.sciencedirect.com/science/article/pii/S1110016823006075},
	doi = {10.1016/j.aej.2023.07.025},
	abstract = {In this day and age, the Industrial Internet of Things ({IIoT}) has been considered to revolutionize industrial manufacturing by capturing and accessing massive data sources with incredible speed and efficiency than before. Combined with it, Mobile Edge Computing ({MEC}) is a comprehensive Digital Transformation tendency to solve the problems Cloud computing faces. However, the fundamental challenges of energy and latency make deploying {IIoT} {MEC} networks difficult. Accordingly, this paper considers the efficient design of time allocation for successful computation probability ({SCP}) maximization for multiple energy-constrained mobile devices ({MD}) and multiple antennas access point ({AP}) in uplink radio frequency energy harvesting ({RF} {EH}) non-orthogonal multiple access ({NOMA}) {IIoT} network. Specifically, multiple {MDs} need to receive the energy and compute support of a {MEC} server placed in a multiple antenna wireless {AP} to complete the task immediately. Accordingly, a four-phase communication protocol is proposed to ensure system performance. The system follows the cluster head ({CH}) scheme based on the channel state information ({CSI}) to harvest {RF} energy from the {AP}. To ensure the highest system performance, we propose two algorithms for determining the optimal {EH} time for two {CHs}: {SCPM}-{GSS} and {SCPM}-{GA}. In addition, we derive the closed-form expressions for the {SCP} of the system and each {CH}. Monte Carlo simulations are used to verify the results of the analysis. The numerical results demonstrate the effects of crucial system parameters of our proposed {NOMA} scheme with those of conventional orthogonal multiple access ({OMA}) schemes. Furthermore, the proposed optimization algorithms allow the system to avoid outages like the random parameters setting approach and improve the {SCP} by 3 to 30\% compared to the fixed parameters set when the transmit power is low and medium.},
	pages = {1--20},
	journaltitle = {Alexandria Engineering Journal},
	shortjournal = {Alexandria Engineering Journal},
	author = {Truong, Van-Truong and Ha, Dac-Binh and Nayyar, Anand and Bilal, Muhammad and Kwak, Daehan},
	urldate = {2024-01-29},
	date = {2023-09-15},
	keywords = {Optimization, Mobile edge computing, {IIoT}, Multiple users, Non-orthogonal multiple access, Radio frequency energy harvesting},
	file = {Truong et al. - 2023 - Performance analysis and optimization of multiple .pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\XRNL8CR8\\Truong et al. - 2023 - Performance analysis and optimization of multiple .pdf:application/pdf},
}

@article{liu_secure_2023,
	title = {Secure distributed data integrity auditing with high efficiency in 5G-enabled software-defined edge computing},
	volume = {1},
	issn = {2772-9184},
	url = {https://www.sciencedirect.com/science/article/pii/S2772918422000042},
	doi = {10.1016/j.csa.2022.100004},
	abstract = {In edge computing, the idle resources of the devices in the network can be virtualized into a platform that provides clients with storage resource and computing capability. Note that the service response of edge computing is faster than that of cloud computing. The service provision speed and the distributed resources utilization rate of edge computing will be further improved when integrated with 5 G and software definition paradigm in the design of the network system. However, the issues of data storage security and edge devices’ trustworthiness seriously restrict the development of edge computing. To enhance the security of the data storage in edge computing, a secure distributed data integrity auditing is proposed. The proposed auditing scheme in this paper can be used to guarantee the correctness and the completeness of the stored data in 5G-enabled software-defined edge computing. The auditing results of the distributed data in the proposed scheme can be used as an important basis for evaluating the trustworthiness of the edge devices. Due to the utilization of certificateless cryptography in the design of the proposed scheme, the computational cost of the terminal side can be highly reduced. Security analysis of the proposed scheme demonstrates that the properties of key exposure resistance and privacy-preserving are provided in data auditing. Simulation results of the time cost of the server side and the terminal side show that the proposed scheme is highly efficient compared to previous schemes.},
	pages = {100004},
	journaltitle = {Cyber Security and Applications},
	shortjournal = {Cyber Security and Applications},
	author = {Liu, Dengzhi and Li, Zhimin and Jia, Dongbao},
	urldate = {2024-01-29},
	date = {2023-12-01},
	keywords = {Edge computing, Privacy-preserving, 5G and software definition, Certificateless cryptography, Distributed data integrity auditing, Key exposure resistance},
	file = {Liu et al. - 2023 - Secure distributed data integrity auditing with hi.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\XEKWUENW\\Liu et al. - 2023 - Secure distributed data integrity auditing with hi.pdf:application/pdf},
}

@article{rajagopal_fedsdm_2023,
	title = {{FedSDM}: Federated learning based smart decision making module for {ECG} data in {IoT} integrated Edge–Fog–Cloud computing environments},
	volume = {22},
	issn = {2542-6605},
	url = {https://www.sciencedirect.com/science/article/pii/S2542660523001075},
	doi = {10.1016/j.iot.2023.100784},
	shorttitle = {{FedSDM}},
	abstract = {Massive data collection in modern systems has paved the way for data-driven machine learning, a promising technique for creating reliable and robust statistical models. By combining the data into centralized storage to develop a reliable learning model, there are concerns with privacy, ownership, and strict rules. It is self-evident that the samples in the typical machine learning centralized server paradigm have vastly different probability distributions of data supplied by each user. As a result, the typical model needs to be personalized for critical medical applications, and the deployment needs an efficient mechanism that can adapt to varying user inputs. Due to the heterogeneous and dynamic nature of critical medical {IoT} applications in such Edge/Fog scenarios, the privacy of patients become a crucial problem. Federated Learning, the model trained on diversity helps in addressing these concerns when used. This paper proposes the integration of Federated Learning for distributed Edge–Fog–Cloud architecture in the {IoT} smart healthcare sector. This paper presents {FedSDM}, the Federated Learning-based Smart Decision Making framework for the {ECG} data in microservice-based {IoT} medical applications. This proposal makes use of the advantages of Edge/Fog computing for real-time critical applications. It deploys the Federated Learning model at the Edge, Fog, and Cloud layers for performance comparison. The parameters considered for performance evaluation are energy consumption, network usage, cost, execution time, and latency. The proposed method shows that Edge-based deployment outperforms Fog and Cloud in terms of energy consumption, network usage, cost, execution time, and latency (i.e.) 0.3\%, 2\%, 15\%, 11\%, and 3\% when compared with Fog and 1.6\%, 31\%, 41\%, 24 \% and 85\% against Cloud respectively.},
	pages = {100784},
	journaltitle = {Internet of Things},
	shortjournal = {Internet of Things},
	author = {Rajagopal, Shinu M. and M., Supriya and Buyya, Rajkumar},
	urldate = {2024-01-29},
	date = {2023-07-01},
	keywords = {Edge computing, Cloud computing, Internet of things, Real-time systems, Resource management, Federated learning, Fog computing, Public healthcare},
	file = {Rajagopal et al. - 2023 - FedSDM Federated learning based smart decision ma.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\9H5UKT9V\\Rajagopal et al. - 2023 - FedSDM Federated learning based smart decision ma.pdf:application/pdf},
}

@article{carro-lagoa_multicamera_2023,
	title = {Multicamera edge-computing system for persons indoor location and tracking},
	volume = {24},
	issn = {2542-6605},
	url = {https://www.sciencedirect.com/science/article/pii/S2542660523002639},
	doi = {10.1016/j.iot.2023.100940},
	abstract = {This paper presents an indoor person localization and tracking system that uses multiple smart cameras equipped with artificial intelligence ({AI}) accelerators serving as edge-computing nodes. Our main contributions are as follows: (a) the development of a new multicamera tracking system for indoor scenarios; (b) the release of a multitarget multicamera tracking dataset; and (c) the development of an annotation mechanism based on waypoints. The system can simultaneously track several individuals while preserving their privacy and anonymity, because no images or sensitive data are transmitted outside the edge nodes. Only the position and appearance of each person were transmitted to the central server. In addition, a multitarget multicamera tracking dataset was released. The dataset contains recordings from five cameras in an indoor scenario and is annotated with the real-world coordinates of individuals. Ground-truth annotations were semiautomatically generated using a mechanism in which people equipped with mobile phones followed specific paths with predefined waypoints. Software related to the ground-truth annotation mechanism has also been released as open source.},
	pages = {100940},
	journaltitle = {Internet of Things},
	shortjournal = {Internet of Things},
	author = {Carro-Lagoa, Ángel and Barral, Valentín and González-López, Miguel and Escudero, Carlos J. and Castedo, Luis},
	urldate = {2024-01-29},
	date = {2023-12-01},
	keywords = {Privacy, Edge computing, Computer vision, Data sets, Indoor localization, Tracking, Video annotation},
	file = {Carro-Lagoa et al. - 2023 - Multicamera edge-computing system for persons indo.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\6VSN3SXF\\Carro-Lagoa et al. - 2023 - Multicamera edge-computing system for persons indo.pdf:application/pdf},
}

@article{ait_abdelmoula_towards_2023,
	title = {Towards a sustainable edge computing framework for condition monitoring in decentralized photovoltaic systems},
	volume = {9},
	issn = {2405-8440},
	url = {https://www.sciencedirect.com/science/article/pii/S2405844023086838},
	doi = {10.1016/j.heliyon.2023.e21475},
	abstract = {In recent times, the rapid advancements in technology have led to a digital revolution in urban areas, and new computing frameworks are emerging to address the current issues in monitoring and fault detection, particularly in the context of the growing renewable decentralized energy systems. This research proposes a novel framework for monitoring the condition of decentralized photovoltaic systems within a smart city infrastructure. The approach uses edge computing to overcome the challenges associated with costly processing through remote cloud servers. By processing data at the edge of the network, this concept allows for significant gains in speed and bandwidth consumption, making it suitable for a sustainable city environment. In the proposed edge-learning scheme, several machine learning models are compared to find the best suitable model achieving both high accuracy and low latency in detecting photovoltaic faults. Four light and rapid machine learning models, namely, {CBLOF}, {LOF}, {KNN}, {ANN}, are selected as best performers and trained locally in decentralized edge nodes. The overall approach is deployed in a smart solar campus with multiple distributed {PV} units located in the R\&D platform Green \& Smart Building Park. Several experiments were conducted on different anomaly scenarios, and the models were evaluated based on their supervision method, f1-score, inference time, {RAM} usage, and model size. The paper also investigates the impact of the type of supervision and the class of the model on the anomaly detection performance. The findings indicated that the supervised artificial neural network ({ANN}) had superior performance compared to other models, obtaining an f1-score of 80 \% even in the most unfavorable conditions. The findings also showed that {KNN} was the most suitable unsupervised model for the investigated experiments achieving good f1-scores (100 \%, 95 \% and 92 \%) in 3 out of 4 scenarios making it a good candidate for similar anomaly detection tasks.},
	pages = {e21475},
	number = {11},
	journaltitle = {Heliyon},
	shortjournal = {Heliyon},
	author = {Ait Abdelmoula, Ibtihal and Idrissi Kaitouni, Samir and Lamrini, Nassim and Jbene, Mourad and Ghennioui, Abdellatif and Mehdary, Adil and El Aroussi, Mohamed},
	urldate = {2024-01-29},
	date = {2023-11-01},
	keywords = {Anomaly detection, Digitalization, Edge-computing, Embedded, Online monitoring, Smart grids},
	file = {Ait Abdelmoula et al. - 2023 - Towards a sustainable edge computing framework for.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\XRL4CRP6\\Ait Abdelmoula et al. - 2023 - Towards a sustainable edge computing framework for.pdf:application/pdf},
}

@article{sharif_priority-based_2023,
	title = {Priority-based task scheduling and resource allocation in edge computing for health monitoring system},
	volume = {35},
	issn = {1319-1578},
	url = {https://www.sciencedirect.com/science/article/pii/S1319157823000010},
	doi = {10.1016/j.jksuci.2023.01.001},
	abstract = {New and innovative wearable {IoT} devices for health monitoring systems ({HMS}) have been invented one after another. However, most of these devices are resource-constrained with restricted energy and computation power. The {HMS} data need to be processed via mobile edge computing ({MEC}) to improve the response time to fulfill the latency-sensitive and computation-intensive applications and to reduce bandwidth consumption. This paper presents an efficient task scheduling and resource allocation mechanism in {MEC} to meet these demands in contemplating emergency conditions under {HMS}. We propose a priority-based task-scheduling and resource-allocation ({PTS}-{RA}) mechanism that can assign different priorities to different tasks by considering the tasks' emergency levels computed with respect to the data aggregated from a patient's smart wearable devices. The mechanism can optimally determine whether a task should be processed locally at the hospital workstations ({HW}) or in the cloud. This is aimed to reduce the total task processing time and the bandwidth cost as much as possible. The proposed approach is to ensure that tasks related to the emergency are given higher priorities and to run first. After the tasks’ computations, results are sent to the doctor to response promptly with quick decisions. The proposed {PTS}-{RA} was benchmarked against state-of-the-art algorithms concerning average latency, task scheduling efficiency, task execution time, network usage, {CPU} utilization, and energy consumption. The benchmarking results are promising as {PTS}-{RA} is capable to manage the emergency conditions and is meeting the latency-sensitive tasks' requirements with reduced bandwidth cost.},
	pages = {544--559},
	number = {2},
	journaltitle = {Journal of King Saud University - Computer and Information Sciences},
	shortjournal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Sharif, Zubair and Tang Jung, Low and Ayaz, Muhammad and Yahya, Mazlaini and Pitafi, Shahneela},
	urldate = {2024-01-29},
	date = {2023-02-01},
	keywords = {Cloud computing, Resource allocation, Mobile edge computing, Healthcare monitoring system, Priority-based task scheduling, Smart hospitals},
	file = {Sharif et al. - 2023 - Priority-based task scheduling and resource alloca.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\F7JCLEZZ\\Sharif et al. - 2023 - Priority-based task scheduling and resource alloca.pdf:application/pdf},
}

@article{sahoo_learning_2023,
	title = {A learning automata based edge resource allocation approach for {IoT}-enabled smart cities},
	issn = {2352-8648},
	url = {https://www.sciencedirect.com/science/article/pii/S2352864823001736},
	doi = {10.1016/j.dcan.2023.11.009},
	abstract = {The development of the Internet of Things ({IoT}) technology leading to a new era of smart applications such as smart transportation, buildings, and smart homes. Moreover, these applications act as the building blocks of {IoT}-enabled smart cities. The high volume and high velocity of data generated by various smart city applications are sent to flexible and efficient cloud computing resources for processing. However, there is a high computation latency due to the presence of a remote cloud server. Edge computing, which brings the computation close to the data source is introduced to overcome this problem. In an {IoT}-enabled smart city environment, one of the main concerns is to consume the least amount of energy while executing tasks that satisfy the delay constraint. An efficient resource allocation at the edge is helpful to address this issue. In this paper, an energy and delay minimization problem in a smart city environment is formulated as a bi-objective edge resource allocation problem. First, we presented a three-layer network architecture for {IoT}-enabled smart cities. Then, we designed a learning automata-based edge resource allocation approach considering the three-layer network architecture to solve the said bi-objective minimization problem. Learning Automata ({LA}) is a reinforcement-based adaptive decision-maker that helps to find the best task and edge resource mapping. An extensive set of simulations is performed to demonstrate the applicability and effectiveness of the {LA}-based approach in the {IoT}-enabled smart city environment.},
	journaltitle = {Digital Communications and Networks},
	shortjournal = {Digital Communications and Networks},
	author = {Sahoo, Sampa and Sahoo, Kshira Sagar and Sahoo, Bibhudatta and Gandomi, Amir H.},
	urldate = {2024-01-29},
	date = {2023-12-15},
	keywords = {Edge computing, Resource allocation, {IoT}, Smart city, Learning automata},
	file = {Sahoo et al. - 2023 - A learning automata based edge resource allocation.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\UFIXIFGS\\Sahoo et al. - 2023 - A learning automata based edge resource allocation.pdf:application/pdf},
}


@article{tang_energy-optimal_2023,
	title = {Energy-optimal {DNN} model placement in {UAV}-enabled edge computing networks},
	issn = {2352-8648},
	url = {https://www.sciencedirect.com/science/article/pii/S235286482300038X},
	doi = {10.1016/j.dcan.2023.02.003},
	abstract = {Unmanned aerial vehicle ({UAV})-enabled edge computing is emerging as a potential enabler for Artificial Intelligence of Things ({AIoT}) in the forthcoming sixth-generation (6G) communication networks. With the use of flexible {UAVs}, massive sensing data is gathered and processed promptly without considering geographical locations. Deep neural networks ({DNNs}) are becoming a driving force to extract valuable information from sensing data. However, the lightweight servers installed on {UAVs} are not able to meet the extremely high requirements of inference tasks due to the limited battery capacities of {UAVs}. In this work, we investigate a {DNN} model placement problem for {AIoT} applications, where the trained {DNN} models are selected and placed on {UAVs} to execute inference tasks locally. It is impractical to obtain future {DNN} model request profiles and system operation states in {UAV}-enabled edge computing. The Lyapunov optimization technique is leveraged for the proposed {DNN} model placement problem. Based on the observed system overview, an advanced online placement ({AOP}) algorithm is developed to solve the transformed problem in each time slot, which can reduce {DNN} model transmission delay and disk I/O energy cost simultaneously while keeping the input data queues stable. Finally, extensive simulations are provided to depict the effectiveness of the {AOP} algorithm. The numerical results demonstrate that the {AOP} algorithm can reduce 18.14\% of the model placement cost and 29.89\% of the input data queue backlog on average by comparing it with benchmark algorithms.},
	journaltitle = {Digital Communications and Networks},
	shortjournal = {Digital Communications and Networks},
	author = {Tang, Jianhang and Wu, Guoquan and Jalalzai, Mohammad Mussadiq and Wang, Lin and Zhang, Bing and Zhou, Yi},
	urldate = {2024-01-29},
	date = {2023-03-05},
	keywords = {6G networks, {DNN} model Placement, Inference tasks, {UAV}-Enabled edge computing},
	file = {Tang et al. - 2023 - Energy-optimal DNN model placement in UAV-enabled .pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\WLHFSE34\\Tang et al. - 2023 - Energy-optimal DNN model placement in UAV-enabled .pdf:application/pdf},
}

@article{badidi_workflow_2023,
	title = {On workflow scheduling for latency-sensitive edge computing applications},
	volume = {220},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050923006671},
	doi = {10.1016/j.procs.2023.03.132},
	series = {The 14th International Conference on Ambient Systems, Networks and Technologies Networks ({ANT}) and The 6th International Conference on Emerging Data and Industry 4.0 ({EDI}40)},
	abstract = {With the rapid proliferation of edge computing-based solutions, many edge computing applications use the cloud for data processing and analysis. However, latency-sensitive applications have low latency requirements and can be very bandwidth hungry, so processing their collected data through cloud servers is not efficient and cost-effective. For example, traffic management and health condition monitoring applications, require real-time data processing at the network edge to respond immediately to unexpected events. These applications are typically executed as workflows with dependent tasks that require careful scheduling to allocate the appropriate resources to the tasks so that the execution is done in a way that satisfies the users’ target functions. In this work, we evaluate some traditional scheduling heuristics for the execution of workflow tasks in an edge-computing scenario. Our goal is to compare their performance in terms of execution time and cost and show that these heuristics, previously used in scheduling in the context of cloud environments, can also be used in edge computing scenarios. The results show that the {MinMin} and {PSO} scheduling algorithms offer the best results with regard to execution time and cost.},
	pages = {958--963},
	journaltitle = {Procedia Computer Science},
	shortjournal = {Procedia Computer Science},
	author = {Badidi, Elarbi},
	urldate = {2024-01-29},
	date = {2023-01-01},
	keywords = {Edge computing, cloud computing, latency, scheduling},
	file = {Badidi - 2023 - On workflow scheduling for latency-sensitive edge .pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\R9M3JPI3\\Badidi - 2023 - On workflow scheduling for latency-sensitive edge .pdf:application/pdf},
}

@article{feng_innovative_2023,
	title = {Innovative soft computing-enabled cloud optimization for next-generation {IoT} in digital twins},
	volume = {136},
	issn = {1568-4946},
	url = {https://www.sciencedirect.com/science/article/pii/S156849462300100X},
	doi = {10.1016/j.asoc.2023.110082},
	abstract = {The research aims to reduce the network resource pressure on cloud centers ({CC}) and edge nodes, to improve the service quality and to optimize the network performance. In addition, it studies and designs a kind of edge–cloud collaboration framework based on the Internet of Things ({IoT}). First, raspberry pi ({RP}) card working machines are utilized as the working nodes, and a kind of edge–cloud collaboration framework is designed for edge computing. The framework consists mainly of three layers, including edge {RP} ({ERP}), monitoring \& scheduling {RP} ({MSRP}), and {CC}. Among the three layers, collaborative communication can be realized between {RPs} and between {RPs} and {CCs}. Second, a kind of edge–cloud​ matching algorithm is proposed in the time delay constraint scenario. The research results obtained by actual task assignments demonstrate that the task time delay in face recognition on edge–cloud collaboration mode is the least among the three working modes, including edge only, {CC} only, and edge–{CC} collaboration modes, reaching only 12 s. Compared with that of {CC} running alone, the identification results of the framework rates on edge–cloud collaboration and {CC} modes are both more fluent than those on edge mode only, and real-time object detection can be realized. The total energy consumption of the unloading execution by system users continuously decreases with the increase in the number of users. It is assumed that the number of pieces of equipment in systems is 150, and the energy-saving rate of systems is affected by the frequency of task generation. The frequency of task generation increases with the corresponding reduction in the energy-saving rate of systems. Based on object detection as an example, the system energy consumption is decreased from 18 W to 16 W after the assignment of algorithms. The included framework improves the resource utility rate and reduces system energy consumption. In addition, it provides theoretical and practical references for the implementation of the edge–cloud collaboration framework.},
	pages = {110082},
	journaltitle = {Applied Soft Computing},
	shortjournal = {Applied Soft Computing},
	author = {Feng, Hailin and Qiao, Liang and Lv, Zhihan},
	urldate = {2024-01-29},
	date = {2023-03-01},
	keywords = {Edge computing, Internet of things, Cloud optimization, Edge–cloud collaboration},
	file = {Feng et al. - 2023 - Innovative soft computing-enabled cloud optimizati.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\VLQFQ77V\\Feng et al. - 2023 - Innovative soft computing-enabled cloud optimizati.pdf:application/pdf},
}

@article{moparthi_improved_2023,
	title = {An improved energy-efficient cloud-optimized load-balancing for {IoT} frameworks},
	volume = {9},
	issn = {2405-8440},
	url = {https://www.sciencedirect.com/science/article/pii/S2405844023091557},
	doi = {10.1016/j.heliyon.2023.e21947},
	abstract = {As wireless communication grows, so does the need for smart, simple, affordable solutions. The need prompted academics to develop appropriate network solutions ranging from wireless sensor networks ({WSNs}) to the Internet of Things ({IoT}). With the innovations of researchers, the necessity for enhancements in existing researchers has increased. Initially, network protocols were the focus of study and development. Regardless, {IoT} devices are already being employed in different industries and collecting massive amounts of data through complicated applications. This necessitates {IoT} load-balancing research. Several studies tried to address the communication overheads produced by significant {IoT} network traffic. These studies intended to control network loads by evenly spreading them across {IoT} nodes. Eventually, the practitioners decided to migrate the {IoT} node data and the apps processing it to the cloud. So, the difficulty is to design a cloud-based load balancer algorithm that meets the criteria of {IoT} network protocols. Defined as a unique method for controlling loads on cloud-integrated {IoT} networks. The suggested method analyses actual and virtual host machine needs in cloud computing environments. The purpose of the proposed model is to design a load balancer that improves network response time while reducing energy consumption. The proposed load balancer algorithm may be easily integrated with peer-existing {IoT} frameworks. Handling the load for cloud-based {IoT} architectures with the above-described methods. Significantly boosts response time for the {IoT} network by 60 \%. The proposed scheme has less energy consumption (31 \%), less execution time (24{\textbackslash}\%), decreased node shutdown time (45 \%), and less infrastructure cost (48{\textbackslash}\%) in comparison to existing frameworks. Based on the simulation results, it is concluded that the proposed framework offers an improved solution for {IoT}-based cloud load-balancing issues.},
	pages = {e21947},
	number = {11},
	journaltitle = {Heliyon},
	shortjournal = {Heliyon},
	author = {Moparthi, Nageswara Rao and Balakrishna, G. and Chithaluru, Premkumar and Kolla, Morarjee and Kumar, Manoj},
	urldate = {2024-01-29},
	date = {2023-11-01},
	keywords = {Energy consumption, {IoT}, Cloud, Load balancer, Response time, {WSN}},
	file = {Moparthi et al. - 2023 - An improved energy-efficient cloud-optimized load-.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\VGDT6YDG\\Moparthi et al. - 2023 - An improved energy-efficient cloud-optimized load-.pdf:application/pdf},
}

@article{khashan_efficient_2023,
	title = {Efficient hybrid centralized and blockchain-based authentication architecture for heterogeneous {IoT} systems},
	volume = {35},
	issn = {1319-1578},
	url = {https://www.sciencedirect.com/science/article/pii/S1319157823000113},
	doi = {10.1016/j.jksuci.2023.01.011},
	abstract = {With the rapid increase in the number of Internet of Things ({IoT}) devices in recent years, massive amounts of sensitive {IoT} data are being generated and transmitted over the Internet. Despite its growing adoption in various fields, {IoT} security remains a major challenge requiring further research. {IoT} authentication is an essential security mechanism for building trust in {IoT} systems. However, conventional authentication approaches use expensive cryptographic primitives that do not align with the resource-constrained nature of {IoT} devices. Furthermore, centralized authentication schemes have proven to be inapplicable for cross-domain authentication and do not limit the scalability of {IoT} networks. Recently, blockchain technology has been applied to building decentralized authentication between {IoT} devices. Nevertheless, most existing blockchain-based authentication approaches incur high overhead in {IoT} computation, storage, and energy consumption. Authentication time is another critical issue in real-time {IoT} systems. When numerous {IoT} authentication requests are transferred to the blockchain, an additional time delay is imposed, in addition to the high computational cost of the blockchain caused by the consensus mechanism. This study proposes a hybrid centralized and blockchain-based authentication architecture for {IoT} systems. Edge servers are deployed to provide centralized authentication for associated {IoT} devices. A blockchain network of centralized edge servers is then established to ensure decentralized authentication and verification of {IoT} devices that belong to different and heterogeneous {IoT} systems. Lightweight cryptographic methods are implemented to achieve efficient authentication, in which limiting the consumption of {IoT} resources is required. The architecture is demonstrated using a local Ethereum blockchain network. The results indicate that the proposed method achieves significant improvements in terms of computation cost, execution time, and power consumption for {IoT} compared with centralized and blockchain-based authentication schemes. A security analysis proves the ability of our architecture to mitigate attacks and satisfy the {IoT} security requirements.},
	pages = {726--739},
	number = {2},
	journaltitle = {Journal of King Saud University - Computer and Information Sciences},
	shortjournal = {Journal of King Saud University - Computer and Information Sciences},
	author = {Khashan, Osama A. and Khafajah, Nour M.},
	urldate = {2024-01-29},
	date = {2023-02-01},
	keywords = {Internet of Things, Security, Authentication, Blockchain, Decentralized authentication, Heterogeneous {IoT}},
	file = {Khashan e Khafajah - 2023 - Efficient hybrid centralized and blockchain-based .pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\FBP2REKQ\\Khashan e Khafajah - 2023 - Efficient hybrid centralized and blockchain-based .pdf:application/pdf},
}

@article{li_task_2023,
	title = {Task offloading mechanism based on federated reinforcement learning in mobile edge computing},
	volume = {9},
	issn = {2352-8648},
	url = {https://www.sciencedirect.com/science/article/pii/S2352864822000554},
	doi = {10.1016/j.dcan.2022.04.006},
	abstract = {With the arrival of 5G, latency-sensitive applications are becoming increasingly diverse. Mobile Edge Computing ({MEC}) technology has the characteristics of high bandwidth, low latency and low energy consumption, and has attracted much attention among researchers. To improve the Quality of Service ({QoS}), this study focuses on computation offloading in {MEC}. We consider the {QoS} from the perspective of computational cost, dimensional disaster, user privacy and catastrophic forgetting of new users. The {QoS} model is established based on the delay and energy consumption and is based on {DDQN} and a Federated Learning ({FL}) adaptive task offloading algorithm in {MEC}. The proposed algorithm combines the {QoS} model and deep reinforcement learning algorithm to obtain an optimal offloading policy according to the local link and node state information in the channel coherence time to address the problem of time-varying transmission channels and reduce the computing energy consumption and task processing delay. To solve the problems of privacy and catastrophic forgetting, we use {FL} to make distributed use of multiple users’ data to obtain the decision model, protect data privacy and improve the model universality. In the process of {FL} iteration, the communication delay of individual devices is too large, which affects the overall delay cost. Therefore, we adopt a communication delay optimization algorithm based on the unary outlier detection mechanism to reduce the communication delay of {FL}. The simulation results indicate that compared with existing schemes, the proposed method significantly reduces the computation cost on a device and improves the {QoS} when handling complex tasks.},
	pages = {492--504},
	number = {2},
	journaltitle = {Digital Communications and Networks},
	shortjournal = {Digital Communications and Networks},
	author = {Li, Jie and Yang, Zhiping and Wang, Xingwei and Xia, Yichao and Ni, Shijian},
	urldate = {2024-01-29},
	date = {2023-04-01},
	keywords = {Mobile edge computing, Deep reinforcement learning, Federated learning, Task offloading, {QoS}},
	file = {Li et al. - 2023 - Task offloading mechanism based on federated reinf.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\5NHGNZCD\\Li et al. - 2023 - Task offloading mechanism based on federated reinf.pdf:application/pdf},
}

@article{chen_container_2023,
	title = {Container cluster placement in edge computing based on reinforcement learning incorporating graph convolutional networks scheme},
	issn = {2352-8648},
	url = {https://www.sciencedirect.com/science/article/pii/S2352864823000470},
	doi = {10.1016/j.dcan.2023.02.012},
	abstract = {Container-based virtualization technology has been more widely used in edge computing environments recently due to its advantages of lighter resource occupation, faster startup capability, and better resource utilization efficiency. To meet the diverse needs of tasks, it is usually needs to instantiate multiple network functions in the form of containers interconnect various generated containers to build a Container Cluster ({CC}). Then {CCs} will be deployed on edge service nodes with relatively limited resources. However, the increasingly complex and time-varying nature of tasks brings great challenges to optimal placement of {CC}. This paper regards the charges for various resources occupied by providing services as revenue, the service efficiency and energy consumption as cost, thus formulates a Mixed Integer Programming ({MIP}) model to describe the optimal placement of {CC} on edge service nodes. Furthermore, an Actor-Critic based Deep Reinforcement Learning ({DRL}) incorporating Graph Convolutional Networks ({GCN}) framework named as {RL}-{GCN} is proposed to solve the optimization problem. The framework obtains an optimal placement strategy through self-learning according to the requirements and objectives of the placement of {CC}. Particularly, through the introduction of {GCN}, the features of the association relationship between multiple containers in {CCs} can be effectively extracted to improve the quality of placement. The experiment results show that under different scales of service nodes and task requests, the proposed method can obtain the improved system performance in terms of placement error ratio, time efficiency of solution output and cumulative system revenue compared with other representative baseline methods.},
	journaltitle = {Digital Communications and Networks},
	shortjournal = {Digital Communications and Networks},
	author = {Chen, Zhuo and Zhu, Bowen and Zhou, Chuan},
	urldate = {2024-01-29},
	date = {2023-03-01},
	keywords = {Edge computing, Deep reinforcement learning, Container cluster, Graph convolutional network, Network virtualization},
	file = {Chen et al. - 2023 - Container cluster placement in edge computing base.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\F4LSV3IM\\Chen et al. - 2023 - Container cluster placement in edge computing base.pdf:application/pdf},
}

@article{raghavendar_robust_2023,
	title = {A robust resource allocation model for optimizing data skew and consumption rate in cloud-based {IoT} environments},
	volume = {7},
	issn = {2772-6622},
	url = {https://www.sciencedirect.com/science/article/pii/S2772662223000401},
	doi = {10.1016/j.dajour.2023.100200},
	abstract = {The Internet of Things ({IoT}) is a network of connected objects designed to collect and exchange data using smart equipment and technologies. A significant challenge in guaranteeing a high level of end-user experience is the administration of {IoT} services. {IoT} networks are constructed using a variety of smart technologies such as detectors, controllers, Radio-frequency identification ({RFID}), Universal Mobile Telecommunications Systems ({UMTS}), Third Generation Cellular Networks (3G), and Global Systems for Mobile communications ({GSM}). Cloud technology significantly impacts how these networks grow by providing processing capabilities, network bandwidth, virtualized systems, and system software in an integrated environment. Capacity management, which assures effective resource use and load-balancing, avoids service level agreement ({SLA}) infractions, and enhances machine efficiency by minimizing operational expenses and power utilization, represents one of the fundamental problems in cloud-based ecosystems. To address these concerns, {IoT}-based robust decision-making resource management is often used. In this study, we investigate resource provisioning methods and identify the factors that must be considered for better utilization of resources in distributed systems. Specifically, we aim to improve the minimization rate, data skew rate, and approximate amount rate. We also highlight the challenges and complexities of hybrid optimization for efficient cloud-based capital allocation in the {IoT}.},
	pages = {100200},
	journaltitle = {Decision Analytics Journal},
	shortjournal = {Decision Analytics Journal},
	author = {Raghavendar, K. and Batra, Isha and Malik, Arun},
	urldate = {2024-01-29},
	date = {2023-06-01},
	keywords = {Cloud computing, Resource allocation, {IoT}, Average consumption rate, Data skew},
	file = {Raghavendar et al. - 2023 - A robust resource allocation model for optimizing .pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\MU7HAEGF\\Raghavendar et al. - 2023 - A robust resource allocation model for optimizing .pdf:application/pdf},
}

@article{ruiz-villafranca_mec-iiot_2023,
	title = {A {MEC}-{IIoT} intelligent threat detector based on machine learning boosted tree algorithms},
	volume = {233},
	issn = {1389-1286},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128623003134},
	doi = {10.1016/j.comnet.2023.109868},
	abstract = {In recent years, new management methods have appeared that mark the beginning of a new industrial revolution called Industry 4.0 or the Industrial Internet of Things ({IIoT}). {IIoT} brings together new emerging technologies, such as the Internet of Things ({IoT}), Deep Learning ({DL}) and Machine Learning ({ML}), that contribute to new applications, industrial processes and efficiency management in factories. This combination of new technologies and contexts is paired with Multi-access Edge Computing ({MEC}) to reduce costs through the virtualisation of networks and services. As these new paradigms increase in growth, so does the number of threats and vulnerabilities, making {IIoT} a very desirable target for cybercriminals. In addition, {IIoT} devices have certain intrinsic limitations, especially due to their limited resources, and this makes it impossible, in many cases, to detect attacks by using solutions designed for other paradigms. So it is necessary to design, implement and evaluate new solutions or adapt existing ones. Therefore, this paper proposes an intelligent threat detector based on boosted tree algorithms. Such detectors have been implemented and evaluated in an environment specifically designed to test {IIoT} deployments. In this way, we can learn how these algorithms, which have been successful in multiple contexts, behave in a paradigm with known constraints. The results obtained in the study show that our intelligent threat detector achieves a mean efficiency of between 95\%–99\% in the F1 Score metric, indicating that it is a good option for implementation in these scenarios.},
	pages = {109868},
	journaltitle = {Computer Networks},
	shortjournal = {Computer Networks},
	author = {Ruiz-Villafranca, Sergio and Roldán-Gómez, José and Carrillo-Mondéjar, Javier and Gómez, Juan Manuel Castelo and Villalón, José Miguel},
	urldate = {2024-01-29},
	date = {2023-09-01},
	keywords = {Industrial Internet of Things, Cybersecurity, Intrusion detection system, Machine Learning, Multi-access Edge Computing},
	file = {Ruiz-Villafranca et al. - 2023 - A MEC-IIoT intelligent threat detector based on ma.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\VMY5Z5BP\\Ruiz-Villafranca et al. - 2023 - A MEC-IIoT intelligent threat detector based on ma.pdf:application/pdf},
}

@inproceedings{naaz_secure_2023,
	title = {Secure and Efficient Edge Computing Framework For {IoT}},
	url = {https://ieeexplore.ieee.org/document/10307200/},
	doi = {10.1109/ICCCNT56998.2023.10307200},
	abstract = {Edge computing is considered a key enabling technology that enhances the Internet of Things ({IoT}) by processing data at the network's edge. It optimizes real-time data processing and reduces network congestion in {IoT} applications. One of the applications of edge computing in {IoT} is privacy-preserving data aggregation; many such techniques have been presented in the past. However, efficiency and security are still challenging in the edge computing framework for resource-constrained {IoT} nodes. We propose a secure and efficient edge computing framework for {IoT} to address this issue by utilizing encryption technique, digital signature, and data aggregation mechanisms. The proposed Framework ensures data confidentiality and authenticity and improves the efficiency of the {IoT} network. We have demonstrated the significance of our system model by simulation, where a comparison has been brought about. The simulation analysis demonstrates that our proposed Framework is efficient in terms of computational cost and energy consumption, and it can reduce energy consumption by up to 38\% compared to an {IoT} network without edge computation.},
	eventtitle = {2023 14th International Conference on Computing Communication and Networking Technologies ({ICCCNT})},
	pages = {1--5},
	booktitle = {2023 14th International Conference on Computing Communication and Networking Technologies ({ICCCNT})},
	author = {Naaz, Zaineb and Joshi, Gamini and Sharma, Vidushi},
	urldate = {2024-01-29},
	date = {2023-07},
	note = {{ISSN}: 2473-7674},
	keywords = {Internet of Things ({IoT}), Performance evaluation, Energy consumption, Real-time systems, Throughput, Edge Computing, Data aggregation, Encryption, Computational efficiency, Data Aggregation, Data Encryption, Digital Signature},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\WNJY4CCJ\\10307200.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\PGD9V8KL\\Naaz et al. - 2023 - Secure and Efficient Edge Computing Framework For .pdf:application/pdf},
}

@article{gao_federated_2023,
	title = {Federated Learning Based on {CTC} for Heterogeneous Internet of Things},
	volume = {10},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/document/10216957/},
	doi = {10.1109/JIOT.2023.3305189},
	abstract = {Federated learning ({FL}) is a machine learning technique that allows for on-site data collection and processing without sacrificing data privacy and transmission. Heterogeneity is a key challenge in federated settings. Recently, cross-technology communication ({CTC}) has emerged as a solution for Internet of Things ({IoT}) heterogeneity, enabling direct communication between different wireless devices without the need for hardware modifications or gateway intervention. For example, a sophisticated {WiFi} device can serve as a central coordinator for other heterogeneous devices, such as {LoRa}, {ZigBee}, Bluetooth, and {LTE}, leading to more efficient and ubiquitous cross-network information exchange. However, heterogeneous wireless technologies present different data transmission rates and computing resources, making it difficult to achieve high accuracy in predictions due to large amounts of multidimensional data, communication delays, transmission latency, limited processing capacity, and data privacy concerns. In this work, we propose an {FL} framework based on {CTC} for heterogeneous {IoT} applications, called {FLCTC}. To demonstrate the usability of {FLCTC}, we implemented {FLCTC} and a specific solution for forest fire prediction. {FLCTC} was concretely implemented as a federal deep learning based on long and short-term memory and used for forest fire prediction, addressing the challenge of data characterization in heterogeneous {IoT} networks. {FLCTC} promises to improve communication efficiency and prediction accuracy. Our platform-based evaluation results show that {FLCTC} is feasible, with a recall of 96\% and an accuracy of 88\%, offering valuable insights into the use of {FL} with {CTC} for heterogeneous {IoT} applications.},
	pages = {22673--22685},
	number = {24},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Gao, Demin and Wang, Haoyu and Guo, Xiuzhen and Wang, Lei and Gui, Guan and Wang, Weizheng and Yin, Zhimeng and Wang, Shuai and Liu, Yunhuai and He, Tian},
	urldate = {2024-01-29},
	date = {2023-12},
	note = {Conference Name: {IEEE} Internet of Things Journal},
	keywords = {Internet of Things, Wireless communication, Servers, Federated learning, Cross-technology communication ({CTC}), federated learning ({FL}), Forestry, heterogeneous Internet of Things ({IoT}) networks, Heterogeneous networks, Wireless fidelity, Zigbee},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\QI8I9PZW\\10216957.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\HZLRJI54\\Gao et al. - 2023 - Federated Learning Based on CTC for Heterogeneous .pdf:application/pdf},
}

@article{panda_energy-efficient_2023,
	title = {Energy-Efficient Computation Offloading With {DVFS} Using Deep Reinforcement Learning for Time-Critical {IoT} Applications in Edge Computing},
	volume = {10},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/document/9718518/},
	doi = {10.1109/JIOT.2022.3153399},
	abstract = {Internet of Things ({IoT}) is a technology that allows ordinary physical devices to collect, process, and share data with other physical devices and systems over the Internet. It provides pervasively connected infrastructures to support innovative applications and services that can automate otherwise intensely laborious manual effort. Edge computing ({EC}) complements the powerful centralized cloud servers by providing powerful computation capability close to the data source, minimizing communication latency, and securing data privacy. The energy consumption problem has continued to receive much attention from the {IoT} community in applying various techniques to reduce energy consumption while still meeting the computational demand. In this article, we propose an application-deadline-aware data offloading scheme using deep reinforcement learning and dynamic voltage and frequency scaling ({DVFS}) in an {EC} environment to reduce the energy consumption of {IoT} devices. The proposed scheme learns the optimal data distribution policies and local computation {DVFS} frequency scaling by interacting with the system environment and learning the behavior of the device, network, and edge servers. The proposed scheme was tested on multiple {EC} environments with different {IoT} devices. Experimental results show that this scheme can reduce energy consumption while achieving the {IoT} application and services timing and computational goals. The proposed scheme has substantial energy savings when compared with the native Linux governors.},
	pages = {6611--6621},
	number = {8},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Panda, Saroj Kumar and Lin, Man and Zhou, Ti},
	urldate = {2024-01-29},
	date = {2023-04},
	note = {Conference Name: {IEEE} Internet of Things Journal},
	keywords = {Internet of Things ({IoT}), Performance evaluation, Internet of Things, Computational modeling, Task analysis, edge computing ({EC}), Energy consumption, Real-time systems, Servers, offloading, energy consumption, Deep reinforcement learning ({DRL}), dynamic voltage and frequency scaling, edge server},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\KWRSZZCL\\9718518.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\PV6Q97Q3\\Panda et al. - 2023 - Energy-Efficient Computation Offloading With DVFS .pdf:application/pdf},
}

@article{sasikumar_decentralized_2023,
	title = {A Decentralized Resource Allocation in Edge Computing for Secure {IoT} Environments},
	volume = {11},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10286482/},
	doi = {10.1109/ACCESS.2023.3325056},
	abstract = {The expansion of Internet of Things ({IoT}) devices and their integration into a variety of vital sectors has created serious concerns regarding data protection, privacy, and resource management. As a promising model, edge computing has the ability to overcome these difficulties by putting the computing power closer to {IoT} devices. This article presents a novel approach for decentralized resource allocation in edge computing settings, with the goal of improving the security and efficiency of {IoT} systems. Edge nodes are critical in our proposed framework for managing and assigning computing resources to {IoT} devices, minimizing latency, and optimizing network traffic. The decentralization of resource distribution promotes resilience in the event of network outages or cyberattacks and provides robustness against single points of failure. We created a proof-of-importance ({PoI}) consensus mechanism for creating new blocks in the blockchain integrated edge-computing {IoT} devices. Therefore, the consensus mechanism will ensure the trust and security of {IoT} devices by authentication of each user in the network. We performed a series of experiments in a simulated edge-computing setting to assess the feasibility of our proposed method. We analyze the proposed system model based on the operation of three different file delivery and transactions. The simulation outcomes show that the blockchain system efficiently delivers the files and increases the transmission rate. We also compared our file delivery and transmission rate with existing techniques, and our proposed model provides a better result. Finally, we compared the power consumption of creating {IoT} nodes based on proof-of-work ({PoW}), proof-of-stake ({PoS}), and {PoI}. The proposed {PoI} consensus mechanism consumes less power than the other two methods.},
	pages = {117177--117189},
	journaltitle = {{IEEE} Access},
	author = {Sasikumar, A. and Ravi, Logesh and Devarajan, Malathi and Vairavasundaram, Subramaniyaswamy and Selvalakshmi, A. and Kotecha, Ketan and Abraham, Ajith},
	urldate = {2024-01-29},
	date = {2023},
	note = {Conference Name: {IEEE} Access},
	keywords = {Edge computing, Internet of Things, edge computing, Cloud computing, Servers, Resource management, resource allocation, Security, blockchain, Blockchains, proof-of-importance ({PoI})},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\KXAUAB2U\\10286482.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\WSKPA5UZ\\Sasikumar et al. - 2023 - A Decentralized Resource Allocation in Edge Comput.pdf:application/pdf},
}

@inproceedings{datiri_cluster_2023,
	title = {A Cluster enabled Blockchain-based Data management for {IoT} systems},
	url = {https://ieeexplore.ieee.org/document/10178949/},
	doi = {10.1109/ICCC57093.2023.10178949},
	abstract = {Internet of Things a flourishing societal luxury has seen massive evolutionary trends that have revolutionized the need for secure and competent data management schemes. Data Privacy, trust, and security in the {IoT} environment are essential matters that need confronting, especially when gathered data is prone to malicious attacks or activities. Moreso, latency requirements that rise exponentially with each added device necessitate effective management in order to meet expected Quality of Service standards. Blockchain-based {IoT}, a paradigm that decentralizes {IoT}’s topology has earned growing popularity over the years owing to its versatility, however, most works on Blockchain-based {IoT} focus on perspectives such as digital currencies, consensus algorithms, and smart contracts, with very few delving into Blockchain’s role in data management. Therefore, to solve the above-mentioned problems, this study proposes a three-tiered scheme, incorporating aspects of clustering, Edge-Computing, and Blockchain, that focuses on data management mechanism of the Blockchain architecture and data structure. The three-tiered framework aims to provide a decentralised, secure resource optimization and data management mechanism for {IoT} systems that includes permissioned authentication protocol for all nodes of contention, smart contract generation between permissioned nodes, immutable block transactions and node deployment, not limited or bound by a singular node. The first phase of the methodology presenting the framework paves way for the second phase of the methodology which evaluates and analyses the proposed scheme, thus illustrating how clustering, blockchain and edge computing bring about an efficient paradigm for tamper-resistant data management with improved latency and high-level credibility and security suitable for {IoT} systems.},
	eventtitle = {2023 24th International Carpathian Control Conference ({ICCC})},
	pages = {88--92},
	booktitle = {2023 24th International Carpathian Control Conference ({ICCC})},
	author = {Datiri, Dorcas Dachollom and Li, Maozhen},
	urldate = {2024-01-29},
	date = {2023-06},
	keywords = {Data privacy, Internet of Things, Quality of service, Data models, Topology, Blockchains, Data management, Blockchain ({BC}), Clustering, Edge computing ({EC}), Internet of Thing ({IoT}), Quality of Service ({QoS}), Resource optimization, Smart contracts},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\8NPUREBK\\10178949.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\54RP9ICJ\\Datiri e Li - 2023 - A Cluster enabled Blockchain-based Data management.pdf:application/pdf},
}

@inproceedings{yuhala_enhancing_2023,
	title = {Enhancing {IoT} Security and Privacy with Trusted Execution Environments and Machine Learning},
	url = {https://ieeexplore.ieee.org/document/10206694/},
	doi = {10.1109/DSN-S58398.2023.00047},
	abstract = {With the increasing popularity of Internet of Things ({IoT}) devices, security concerns have become a major challenge: confidential information is constantly being transmitted (sometimes inadvertently) from user devices to untrusted cloud services. This work proposes a design to enhance security and privacy in {IoT} based systems by isolating hardware peripheral drivers in a trusted execution environment ({TEE}), and leveraging secure machine learning classification techniques to filter out sensitive data, e.g., speech, images, etc. from the associated peripheral devices before it makes its way to an untrusted party in the cloud.},
	eventtitle = {2023 53rd Annual {IEEE}/{IFIP} International Conference on Dependable Systems and Networks - Supplemental Volume ({DSN}-S)},
	pages = {176--178},
	booktitle = {2023 53rd Annual {IEEE}/{IFIP} International Conference on Dependable Systems and Networks - Supplemental Volume ({DSN}-S)},
	author = {Yuhala, Peterson},
	urldate = {2024-01-29},
	date = {2023-06},
	note = {{ISSN}: 2833-292X},
	keywords = {Privacy, Data privacy, edge computing, Cloud computing, Hardware, {IoT}, Machine learning, machine learning, {ARM} {TrustZone}, confidential computing, Information filters, kernel drivers, {OP}-{TEE}, Speech enhancement, trusted execution environments},
	file = {Versione inviata:C\:\\Users\\Emanuele\\Zotero\\storage\\TBFJHHR2\\Yuhala - 2023 - Enhancing IoT Security and Privacy with Trusted Ex.pdf:application/pdf},
}

@article{el_houda_mec-based_2023,
	title = {A {MEC}-Based Architecture to Secure {IoT} Applications using Federated Deep Learning},
	volume = {6},
	issn = {2576-3199},
	url = {https://ieeexplore.ieee.org/document/10070397/},
	doi = {10.1109/IOTM.001.2100238},
	abstract = {Internet of Things ({IoT}) is a promising paradigm that is considered as major enabler of smart cities. However, with the emergence of {IoT} botnets, the number of unsecured {IoT} devices is increasing rapidly. This can give attackers more advanced tools to carry out large scale damaging {IoT} attacks. Advanced Machine Learning ({ML}) techniques can help enhance the effectiveness of conventional intrusion detection systems ({IDS}) to accurately detect {IoT} attacks. But there are ongoing challenges with centralized learning as well as the lack of up-to-date/ new datasets, covering key {IoT} attacks. In this context, we design a novel Multiple access Edge Computing ({MEC}) architecture to secure {IoT} applications with Federated Learning ({FL}). In particular, we propose a promising {eDge}-based {architEcTure} to {sEcure} {IoT} {appliCations} using {FL}, called {DETECT}. {DETECT} allows multiple {MEC} domains to collaboratively and securely mitigate {IoT} attacks, while ensuring the privacy of the {MEC} collaborator and consequently the privacy of {IoT} devices. The in-depth experiments results with well- known {IoT} attack using, the Edge-{IIoTset} and {NSL}-{KDD} datastets, show the significant accuracy of {DETECT} in terms of Accuracy (86 percent in {NSL}-{KDD} and 99 percent in Edge-{IIoTset}) and F1 score (87 percent in {NSL}-{KDD} and 99 percent in Edge-{IIoTset}).},
	pages = {60--63},
	number = {1},
	journaltitle = {{IEEE} Internet of Things Magazine},
	author = {El Houda, Zakaria Abou and Brik, Bouziane and Ksentini, Adlen and Khoukhi, Lyes},
	urldate = {2024-01-29},
	date = {2023-03},
	note = {Conference Name: {IEEE} Internet of Things Magazine},
	keywords = {Privacy, Deep learning, Smart cities, Image edge detection, Federated learning, Intrusion detection, Measurement},
	file = {El Houda et al. - 2023 - A MEC-Based Architecture to Secure IoT Application.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\FY7DWB4M\\El Houda et al. - 2023 - A MEC-Based Architecture to Secure IoT Application.pdf:application/pdf},
}

@inproceedings{majjari_deep_2023,
	title = {Deep Reinforcement Learning ({DRL}) based data analytics framework for Edge based {IoT} devices latency and resource optimization},
	url = {https://ieeexplore.ieee.org/document/10200511/},
	doi = {10.1109/ACCESS57397.2023.10200511},
	abstract = {Internet of Things ({IoT}) trends show rising data processing computational needs. Sensor data is uploaded to backend cloud nodes before data analyses at the network edge. {IoT} devices are usually resource-constrained and unable to execute operations quickly and accurately. Cloud servers are impractical and increase communication overhead. Cloud platforms offer machine learning services with pretrained models to understand {IoT} data. To use the cloud service, personal data must be transferred, and network problems may impede timely analysis results. Data and analysis are shifting to edge platforms to solve these concerns. Most edge devices can't analyze and train a lot of data. Edge-enabled systems provide efficient compute and control at the network edge to reduce scalability and latency. {IoT} applications provide large heterogeneous data, which makes edge computing difficult. To solve this issue, Deep Reinforcement Learning ({DRL}) based data analytics framework for Edge based {IoT} devices to enable devices to execute tasks jointly, leveraging proximity and resource complementarity. It supports parallel data input and strengthen the comprehensive communication overhead handling through data scheduling optimization. The simulation results conveys that the proposed approach uses {DRL} to optimize execution accuracy and time without requiring a priori {IoT} node information. Moreover, the average delay time, percentage of failure and cost of rewards are computed in which being compared with the existing scheduling methods includes Proximal Policy Optimization technique ({PPO}), and Deep Deterministic Policy Gradient technique ({DDPG}).},
	eventtitle = {2023 3rd International Conference on Advances in Computing, Communication, Embedded and Secure Systems ({ACCESS})},
	pages = {137--142},
	booktitle = {2023 3rd International Conference on Advances in Computing, Communication, Embedded and Secure Systems ({ACCESS})},
	author = {Majjari, Sudhakar and Anne, Koteswara Rao and George, Joseph},
	urldate = {2024-01-29},
	date = {2023-05},
	keywords = {Internet of Things, Deep learning, Cloud computing, Reinforcement learning, Delays, Data analysis, and Failure percentage, Average time delay, {DRL}, Low latency, Parallel task execution, Processor scheduling, scheduling policy},
	file = {Majjari et al. - 2023 - Deep Reinforcement Learning (DRL) based data analy.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\YYSL6U87\\Majjari et al. - 2023 - Deep Reinforcement Learning (DRL) based data analy.pdf:application/pdf},
}

@inproceedings{abo-soliman_edge_2023,
	title = {Edge Computing and Distributed Ledger Technology for The Industrial {IoT}},
	url = {https://ieeexplore.ieee.org/document/10391125/},
	doi = {10.1109/ICICIS58388.2023.10391125},
	abstract = {The tremendous increase in implementing {IoT} devices for critical infrastructures yells for higher performance and robust protection. Traditional cloud based {IoT} architecture is unsuitable for delay-sensitive or real-time applications and lacks the robust security needed by industrial systems. Thus, new technologies are introduced to endorse the industry's digital transformation. Edge computing greatly satisfies required performance while Distributed Ledger Technology ({DLT}) mitigates potential data compromises. This work proposes an integrated four layers architecture based on Edge Computing and {DLT} that provides efficient computing, security, and scalability. Edge computing handles transmission delay and scalability issues, while {DLT} handles data validation and trust. A lightweight {DLT} model is introduced to enable faster data commitment and better networking. The model incorporates two main features: a new grouping technique that enables network segmentation reducing network complexity. The second technique dynamically optimizes resource-utilization by adjusting {DLT} requirements according to the hardware capabilities of each participating node.},
	eventtitle = {2023 Eleventh International Conference on Intelligent Computing and Information Systems ({ICICIS})},
	pages = {247--252},
	booktitle = {2023 Eleventh International Conference on Intelligent Computing and Information Systems ({ICICIS})},
	author = {Abo-Soliman, Mohamed Ahmed and Shabaan, Eman and Al-Qutt, Mirvat and Emara, Kareem},
	urldate = {2024-01-29},
	date = {2023-11},
	note = {{ISSN}: 2831-5952},
	keywords = {Performance evaluation, Internet of Things, Computational modeling, Computer architecture, Real-time systems, Edge Computing, Security, Scalability, Consensus, Directed Acyclic Graph, Distributed ledger, Distributed Ledger Technology},
	file = {Abo-Soliman et al. - 2023 - Edge Computing and Distributed Ledger Technology f.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\FEF7R7XF\\Abo-Soliman et al. - 2023 - Edge Computing and Distributed Ledger Technology f.pdf:application/pdf},
}

@article{wang_ppefl_2023,
	title = {{PPeFL}: Privacy-Preserving Edge Federated Learning With Local Differential Privacy},
	volume = {10},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/document/10091486/},
	doi = {10.1109/JIOT.2023.3264259},
	shorttitle = {{PPeFL}},
	abstract = {Since traditional federated learning ({FL}) algorithms cannot provide sufficient privacy guarantees, an increasing number of approaches apply local differential privacy ({LDP}) techniques to {FL} to provide strict privacy guarantees. However, the privacy budget heavily increases proportionally with the dimension of the parameters, and the large variance generated by the perturbation mechanisms leads to poor performance of the final model. In this article, we propose a novel privacy-preserving edge {FL} framework based on {LDP} ({PPeFL}). Specifically, we present three {LDP} mechanisms to address the privacy problems in the {FL} process. The proposed filtering and screening with exponential mechanism ({FS}-{EM}) filters out the better parameters for global aggregation based on the contribution of weight parameters to the neural network. Thus, we can not only solve the problem of fast growth of privacy budget when applying perturbation mechanism locally but also greatly reduce the communication costs. In addition, the proposed data perturbation mechanism with stronger privacy ({DPM}-{SP}) allows a secondary scrambling of the original data of participants and can provide strong security. Further, a data perturbation mechanism with enhanced utility ({DPM}-{EU}) is proposed in order to reduce the variance introduced by the perturbation. Finally, extensive experiments are performed to illustrate that the {PPeFL} scheme is practical and efficient, providing stronger privacy protection while ensuring utility.},
	pages = {15488--15500},
	number = {17},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Wang, Baocang and Chen, Yange and Jiang, Hang and Zhao, Zhen},
	urldate = {2024-01-29},
	date = {2023-09},
	note = {Conference Name: {IEEE} Internet of Things Journal},
	keywords = {Privacy, Edge computing, Training, Cloud computing, Costs, Servers, Federated learning, federated learning ({FL}), local differential privacy ({LDP}), Perturbation methods, privacy protection},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\CB8LHKMJ\\10091486.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\XR3XHWKE\\Wang et al. - 2023 - PPeFL Privacy-Preserving Edge Federated Learning .pdf:application/pdf},
}

@inproceedings{alnuaimi_optimizing_2023,
	title = {Optimizing Edge Security: Comprehensive Analysis and Mitigation Strategies for Securing Edge Computing},
	url = {https://ieeexplore.ieee.org/document/10308853/},
	doi = {10.1109/ICOA58279.2023.10308853},
	shorttitle = {Optimizing Edge Security},
	abstract = {This research paper delves into the security challenges posed by the rapid expansion of {IoT} devices, particularly in edge computing. By examining real-world scenarios in smart home security systems, medical {IoT} devices, smart transportation systems, and edge computing, the study thoroughly investigates the vulnerabilities associated with these {IoT} systems. The paper identifies common weaknesses, including insufficient encryption, outdated firmware, weak passwords, and inadequate physical security, which expose users to risks such as identity theft, data breaches, device manipulation, and infrastructure attacks. To address these concerns and optimize edge security, the paper proposes effective mitigation strategies tailored to each specific area. The recommended strategies encompass the use of strong passwords, regular firmware updates, encryption, network segmentation, authentication and authorization systems, robust authentication and access control, frequent security audits, and encrypted data and communication protection. The study emphasizes the importance of collaboration among stakeholders, such as manufacturers, regulators, and users, to implement these measures and enhance the security and dependability of {IoT} systems, specifically in the context of edge computing. By prioritizing security, users can confidently embrace {IoT} technology while safeguarding their privacy and well-being. This research provides valuable insights and actionable recommendations for optimizing edge security and addressing the evolving challenges in the field of edge computing.},
	eventtitle = {2023 9th International Conference on Optimization and Applications ({ICOA})},
	pages = {1--7},
	booktitle = {2023 9th International Conference on Optimization and Applications ({ICOA})},
	author = {Alnuaimi, Rahaf Adam and Almasalmeh, Ranem Khaled and Alhammadi, Elyazi Abdulla and Hassan, Gasm El Bary Mohamed El and Zia, Huma},
	urldate = {2024-01-29},
	date = {2023-10},
	note = {{ISSN}: 2768-6388},
	keywords = {Internet of Things, {IoT}, Edge Computing, Encryption, Security, Authentication, Access Control, Software, {DoS}, Mitigation, Passwords, Security risks, Software reliability},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\LU7RN75Z\\10308853.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\RP5BJKRN\\Alnuaimi et al. - 2023 - Optimizing Edge Security Comprehensive Analysis a.pdf:application/pdf},
}

@inproceedings{li_wait_2023,
	title = {Wait for Fresh Data? Digital Twin Empowered {IoT} Services in Edge Computing},
	url = {https://ieeexplore.ieee.org/document/10298464/},
	doi = {10.1109/MASS58611.2023.00056},
	shorttitle = {Wait for Fresh Data?},
	abstract = {The Mobile Edge Computing ({MEC}) paradigm gives impetus to the vigorous advancement of Internet of Things ({IoT}), through provisioning low-latency computing services at network edges. The emerging digital twin technique has grown in the community of {IoT}, and bridges the gap between physical objects and their digital representations in {MEC}, thereby enabling real-time data analysis, simulating the dynamics of systems, and optimizing network resource allocation. In this paper, we consider query services for various {IoT} applications in an {MEC} network, built upon digital twin data in the network, with the aim to optimize the freshness of query results, measured by the Age of Information ({AoI}) and query service delays simultaneously. We first formulate a novel minimization problem that explores a nontrivial trade-off between these two critical yet conflicted optimization objectives, and show the {NP}-hardness of the problem. We then propose an approximation algorithm for the problem with a provable approximation ratio, at the expense of a moderate computing resource violation. We finally evaluate the performance of the proposed algorithm via simulations. Simulation results demonstrate that the proposed algorithm is promising, and outperforms the benchmarks, improving by no less than 18.9\% of the performance in comparison with that of the baseline algorithms.},
	eventtitle = {2023 {IEEE} 20th International Conference on Mobile Ad Hoc and Smart Systems ({MASS})},
	pages = {397--405},
	booktitle = {2023 {IEEE} 20th International Conference on Mobile Ad Hoc and Smart Systems ({MASS})},
	author = {Li, Jing and Guo, Song and Liang, Weifa and Wu, Jie and Chen, Quan and Xu, Zichuan and Xu, Wenzheng and Wang, Jianping},
	urldate = {2024-01-29},
	date = {2023-09},
	note = {{ISSN}: 2155-6814},
	keywords = {Computational modeling, Minimization, Approximation algorithms, Simulation, Real-time systems, Delays, Digital twins, mobile edge computing, digital twin, query services, age of information, service delays, approximation algorithms, resource allocation and optimization},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\LY9TNJ5Z\\10298464.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\WAXJMQD9\\Li et al. - 2023 - Wait for Fresh Data Digital Twin Empowered IoT Se.pdf:application/pdf},
}

@article{jiang_differential_2023,
	title = {Differential Privacy on Edge Computing},
	volume = {17},
	issn = {1942-7808},
	url = {https://ieeexplore.ieee.org/document/10274724/},
	doi = {10.1109/MNANO.2023.3316873},
	abstract = {This paper presents an overview of privacy protection, with a focus on differential privacy ({DP}), from the perspective of edge computing. It explores the application of {DP} in various associative analysis techniques, including heavy hitter mining, frequent itemset mining, and association rules mining, within the context of edge computing. The paper also highlights the current challenges and future research directions in this area, including differentially private hybrid models and federated learning. By examining the intersection of privacy protection and edge computing, this paper provides insights into the application of {DP} and its potential for preserving privacy in associative analysis tasks within edge computing environments.},
	pages = {14--22},
	number = {6},
	journaltitle = {{IEEE} Nanotechnology Magazine},
	author = {Jiang, Xiyu and Tsou, Yao-Tung and Kuo, Sy-Yen},
	urldate = {2024-01-29},
	date = {2023-12},
	note = {Conference Name: {IEEE} Nanotechnology Magazine},
	keywords = {Privacy, Data privacy, Edge computing, Computational modeling, Data models, Servers, Differential privacy},
	file = {Jiang et al. - 2023 - Differential Privacy on Edge Computing.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\AUT64QQU\\Jiang et al. - 2023 - Differential Privacy on Edge Computing.pdf:application/pdf},
}

@article{salama_decentralized_2023,
	title = {Decentralized Federated Learning on the Edge Over Wireless Mesh Networks},
	volume = {11},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10304146/},
	doi = {10.1109/ACCESS.2023.3329362},
	abstract = {The rapid growth of Internet of Things ({IoT}) devices has generated vast amounts of data, leading to the emergence of federated learning as a novel distributed machine learning paradigm. Federated learning enables model training at the edge, leveraging the processing capacity of edge devices while preserving privacy and mitigating data transfer bottlenecks. However, the conventional centralized federated learning architecture suffers from a single point of failure and susceptibility to malicious attacks. In this study, we delve into an alternative approach called decentralized federated learning ({DFL}) conducted over a wireless mesh network as the communication backbone. We perform a comprehensive network performance analysis using stochastic geometry theory and physical interference models, offering fresh insights into the convergence analysis of {DFL}. Additionally, we conduct system simulations to assess the proposed decentralized architecture under various network parameters and different aggregator methods such as {FedAvg}, Krum and Median methods. Our model is trained on the widely recognized {EMNIST} dataset for benchmarking handwritten digit classification. To minimize the model’s size at the edge and reduce communication overhead, we employ a cutting-edge compression technique based on genetic algorithms. Our simulation results reveal that the compressed decentralized architecture achieves performance comparable to the baseline centralized architecture and traditional {DFL} in terms of accuracy and average loss for our classification task. Moreover, it significantly reduces the size of shared models over the wireless channel by compressing participants’ local model sizes to nearly half of their original size compared to the baselines, effectively reducing complexity and communication overhead.},
	pages = {124709--124724},
	journaltitle = {{IEEE} Access},
	author = {Salama, Abdelaziz and Stergioulis, Achilleas and Zaidi, Syed Ali Raza and {McLernon}, Des},
	urldate = {2024-01-29},
	date = {2023},
	note = {Conference Name: {IEEE} Access},
	keywords = {Data privacy, Performance evaluation, Edge computing, Internet of Things, Data models, edge computing, Training, Cloud computing, Servers, federated learning, Federated learning, Decentralized applications, data privacy, decentralized federated learning, The Internet of Things ({IoT})},
	file = {Full text:C\:\\Users\\Emanuele\\Zotero\\storage\\5ZCT32NN\\Salama et al. - 2023 - Decentralized Federated Learning on the Edge Over .pdf:application/pdf},
}

@article{bai_model-driven_2023,
	title = {Model-Driven Dependability Assessment of Microservice Chains in {MEC}-Enabled {IoT}},
	volume = {16},
	issn = {1939-1374},
	url = {https://ieeexplore.ieee.org/document/10034800/},
	doi = {10.1109/TSC.2023.3241430},
	abstract = {Multi-access edge computing ({MEC})-enabled Internet of Things ({IoT}) is considered as a promising paradigm to deliver computation-intensive and delay-sensitive services to users. {IoT} service requests can be served by multiple microservices ({MSs}) that form a chain, called a microservice chain ({MSC}). However, the high complexity of {MSs} and security threats in {MEC}-enabled {IoT} pose new challenges to {MSC} dependability. Proactive rejuvenation techniques can mitigate the impact of resource degradation of {MSs} and host operating systems ({OSes}) executing them. In this article, we develop a multi-dimensional semi-Markov model to investigate the effectiveness of proactive rejuvenation techniques in improving the dependability (availability and reliability) of a dynamic and heterogeneous {MSC}. The results of numerical experiments firstly reveal how {MSs} can be effectively combined, in different deployment configurations, with host {OSes} to improve {MSC} dependability, secondly jointly optimize the rejuvenation trigger intervals of host {OS} and {MSs} running on it, and finally show the impact of time-varying parameters. We also identify the bottlenecks for {MSC} dependability improvement by sensitivity analysis, and give the ranges of important parameter values guaranteeing five-nines availability. In addition, the superiority of our model is demonstrated by comparison with the continuous-time Markov chain model.},
	pages = {2769--2785},
	number = {4},
	journaltitle = {{IEEE} Transactions on Services Computing},
	author = {Bai, Jing and Chang, Xiaolin and Machida, Fumio and Trivedi, Kishor S. and Li, Yaru},
	urldate = {2024-01-29},
	date = {2023-07},
	note = {Conference Name: {IEEE} Transactions on Services Computing},
	keywords = {Degradation, Internet of Things, Reliability, Analytical models, Behavioral sciences, Dependability, Microservice architectures, microservice chain, resource degradation, semi-Markov process, Switched mode power supplies},
	file = {Bai et al. - 2023 - Model-Driven Dependability Assessment of Microserv.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\ZJDZG5HM\\Bai et al. - 2023 - Model-Driven Dependability Assessment of Microserv.pdf:application/pdf},
}

@inproceedings{alawadhi_deep_2023,
	title = {Deep Learning Techniques in Mobile Edge Computing for Internet of Medical Things},
	url = {https://ieeexplore.ieee.org/document/10293737/},
	doi = {10.1109/eSmarTA59349.2023.10293737},
	abstract = {The fast expansion of the Internet of Medical Things ({IoMT}) has resulted in a ubiquitous home health diagnostic network. High patient demand results in high costs, short latency, and communication overload. As a result, 6G is the next generation of {IoT}, {IoMT}, and cellular networks, intending to considerably improve the quality of smart healthcare services through high throughput and decreased latency. So far, adopting cloud computing for time-critical applications and decreasing access delays to resources is difficult. Deep learning has been extensively employed to extract characteristics from complicated networks as artificial intelligence technology has advanced. On the other hand, deep learning models are often run in cloud computing data centres with tremendous processing resources. Conventional cloud computing systems primarily rely on the network, which has significant latency and security and privacy issues. One of the successful solutions is the Mobile Edge Computing ({MEC}) paradigm, which brings cloud computing services closer to the edge network and uses available resources. Mobile edge computing places computer and storage nodes near mobile devices at the Internet's edge, leading to considerable savings in system operating time, memory cost, and power usage. Deep learning is used in mobile edge computing to forecast changes in demand based on daily patient behaviours. It also prepares the network by scaling up network resources as required. This study aims to discuss {IoMT} and identfy the problems in deep learning for mobile edge computing technology and its applications.},
	eventtitle = {2023 3rd International Conference on Emerging Smart Technologies and Applications ({eSmarTA})},
	pages = {1--6},
	booktitle = {2023 3rd International Conference on Emerging Smart Technologies and Applications ({eSmarTA})},
	author = {Alawadhi, Abdulwadood and Ahmad, R. Badlishah and Almogahed, Abdullah and Abrar, Ahmad},
	urldate = {2024-01-29},
	date = {2023-10},
	keywords = {Privacy, Deep learning, Cloud computing, Costs, Multi-access edge computing, 6G, 6G mobile communication, Data centers, Internet of Medical Things, Mobile Edge cpomuting},
	file = {Alawadhi et al. - 2023 - Deep Learning Techniques in Mobile Edge Computing .pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\5XXQIPCK\\Alawadhi et al. - 2023 - Deep Learning Techniques in Mobile Edge Computing .pdf:application/pdf},
}

@article{wang_pcnncec_2023,
	title = {{PCNNCEC}: Efficient and Privacy-Preserving Convolutional Neural Network Inference Based on Cloud-Edge-Client Collaboration},
	volume = {10},
	issn = {2327-4697},
	url = {https://ieeexplore.ieee.org/document/9782521/},
	doi = {10.1109/TNSE.2022.3177755},
	shorttitle = {{PCNNCEC}},
	abstract = {Deploying convolutional neural network ({CNN}) inference on resource-constrained devices remains a remarkable challenge for Industrial Internet of Things ({IIoT}). Although the cloud computing shows great promise in machine learning training and prediction, outsourcing data to a remote cloud always incurs privacy risk and high latency. Therefore, we design a new framework for efficient and privacy-preserving {CNN} inference based on cloud-edge-client collaboration (named {\textbackslash}{textPCNN}\_{\textbackslash}{textCEC}). In {\textbackslash}{textPCNN}\_{\textbackslash}{textCEC}, the model of cloud and the data of client in {IIoT} are split into two secret shares and sent to two non-colluded edge servers. We proposed a new efficient private comparison protocol based on the additively secret sharing technique, which can be used to realize secure computation of {ReLU} function without approximation in semi-honest adversary model. By applying some secure two-party computation protocols, the two edge servers can jointly calculate the predicting results without learning anything about the model and data. Moreover, to speed up the pre-computation of offline phase but not sacrifice security, we delegate the task of triplets generation to the cloud, so that the edge servers do not require frequent interactions to generate triplets themselves or introducing additional trusted party. The experimental results show the proposed private comparison protocol achieves a better tradeoff between low latency and high throughput, when it is compared with garbled circuit based protocols and other secret sharing based protocols. Additionally, the benchmarks conducted on realistic {MNIST} and {CIFAR}-10 datasets demonstrate that {\textbackslash}{textPCNN}\_{\textbackslash}{textCEC} costs less communication and runtime than two recently related schemes under the same security level.},
	pages = {2906--2923},
	number = {5},
	journaltitle = {{IEEE} Transactions on Network Science and Engineering},
	author = {Wang, Jing and He, Debiao and Castiglione, Aniello and Gupta, Brij B. and Karuppiah, Marimuthu and Wu, Libing},
	urldate = {2024-01-29},
	date = {2023-09},
	note = {Conference Name: {IEEE} Transactions on Network Science and Engineering},
	keywords = {Computational modeling, edge computing, Convolutional neural networks, Servers, Industrial Internet of Things, Machine learning, Cryptography, Convolutional neural network, Protocols, industrial Internet of Things, privacy-preserving inference},
	file = {Wang et al. - 2023 - PCNNCEC Efficient and Privacy-Preserving Convolut.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\8D8989UJ\\Wang et al. - 2023 - PCNNCEC Efficient and Privacy-Preserving Convolut.pdf:application/pdf},
}

@inproceedings{primya_data_2023,
	title = {Data sharing in Cloud-Assisted {IoT}},
	url = {https://ieeexplore.ieee.org/document/10142285/},
	doi = {10.1109/ICONSTEM56934.2023.10142285},
	abstract = {Smart gadgets can now communicate from close to a long distance with one another and with the Internet or cloud. Internet of things ({IOT}) brings a paradigm shift of employing low resource {IOT} smart system with cloud computing. However, by employing cloud computing, resource-constrained {IoT} smart devices can gain a number of advantages, Excluding the weight of data processing and storing the data on the network cloud. By implementing it on network edge offers more merits instead of using network cloud in contra to internet of things ({IOT}) applications which needs high data rates, mobility, and latency-sensitive real-time data processing. In this paper mainly focused on data transfers to cloud and {IOT} devices form smart data transfer. Here a suggestion that is authenticated search method to look for required information among one's personal or shared data on storage. At last, by evaluating processing time performance of the suggested scheme, outcomes that discussed in the paper, show that our strategy has a chance of working well in {IoT} applications.},
	eventtitle = {2023 Eighth International Conference on Science Technology Engineering and Mathematics ({ICONSTEM})},
	pages = {1--8},
	booktitle = {2023 Eighth International Conference on Science Technology Engineering and Mathematics ({ICONSTEM})},
	author = {Primya, T. and M, Swetha and Ramya, V and Taanusri, S R and Ridhanya, G and Sekar, Rajasekaran Arun},
	urldate = {2024-01-29},
	date = {2023-04},
	keywords = {Performance evaluation, Cloud computing, Real-time systems, Aggregates, Baseline Drift, Data transfer, De-noising, {DWT}, Information sharing, {IOT}, {QRS}-complex, R-R interval, Search methods},
	file = {Primya et al. - 2023 - Data sharing in Cloud-Assisted IoT.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\DUPZJMKM\\Primya et al. - 2023 - Data sharing in Cloud-Assisted IoT.pdf:application/pdf},
}

@article{singh_secure_2023,
	title = {Secure Smart Healthcare Framework Using Lightweight {DNA} Sequence and Chaos for Mobile-Edge Computing},
	volume = {10},
	issn = {2327-4662},
	url = {https://ieeexplore.ieee.org/document/9936695/},
	doi = {10.1109/JIOT.2022.3219113},
	abstract = {Mobile-edge computing ({MEC}) is a new architecture that provides services to the edge of networks. The software and hardware platforms are positioned at the network edge close to end-users. Emerging developments in {MEC} can be used for healthcare applications, such as remote patient monitoring, diagnosis, and treatment purposes. The remote access to the data can arise security and privacy issues. Unauthorized access or data leakage can hamper the complete security of the system. This makes the system inconvenient, untrusted, less suitable, and vulnerable. This article is aimed to propose a security framework for the privacy preservation of patient data in a {MEC} environment where the services are accessed at the network edge. A lightweight cryptographic technique is proposed by including a chaotic map and a {DNA} sequence of organisms for encryption of electronic health records ({EHRs}). The identity privacy will be maintained by using anonymous authentication. The framework’s performance is evaluated with memory usage and encryption time and found satisfactory results.},
	pages = {4883--4890},
	number = {6},
	journaltitle = {{IEEE} Internet of Things Journal},
	author = {Singh, Ashish and Chatterjee, Kakali and Singh, Anish Kumar and Kumar, Neeraj},
	urldate = {2024-01-29},
	date = {2023-03},
	note = {Conference Name: {IEEE} Internet of Things Journal},
	keywords = {Privacy, Cloud computing, mobile-edge computing ({MEC}), Servers, Encryption, Security, Authentication, Medical services, chaotic maps, lightweight encryption, medical image privacy},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\SFQPGMAI\\9936695.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\B7MSVLH4\\Singh et al. - 2023 - Secure Smart Healthcare Framework Using Lightweigh.pdf:application/pdf},
}

@article{lyu_scalable_2023,
	title = {Scalable Aggregated Split Learning for Data-Driven Edge Intelligence on Internet-of-Things},
	volume = {6},
	issn = {2576-3199},
	url = {https://ieeexplore.ieee.org/document/10364651/},
	doi = {10.1109/IOTM.001.2300053},
	abstract = {By combining Al techniques with edge computing, edge intelligence (El) is a promising paradigm for future intelligent Internet-of-Things ({IoT}). Split learning is one of the underlying technologies for El, where the computation-intensive model portions are offloaded to the edge server and the privacy-sensitive model portions are kept locally. The merits of split learning include data privacy and computation efficiency, which are paramount to intelligent {IoT}. However, split learning may not be scalable to massive {IoT} devices due to the excessive training latency, and limited computation and communication resources of the edge server. This article presents a novel scalable aggregated split learning framework that can significantly reduce the server-side computation and communication overhead for intelligent {IoT}. By exploiting the empirical expectation definitions of loss functions, the edge server is meticulously designed to aggregate the local loss functions of mas-sive devices to the global loss function and perform only one time of aggregated server-side backpropagation. After receiving the multicast global cut-layer gradients from the edge server, the devices can perform local training to generate synchronized device-side models. Case studies are shown to validate the effectiveness of the proposed framework against typical decentralized learning frameworks.},
	pages = {124--129},
	number = {4},
	journaltitle = {{IEEE} Internet of Things Magazine},
	author = {Lyu, Xinchen and Liu, Shuhan and Liu, Junlin and Ren, Chenshan},
	urldate = {2024-01-29},
	date = {2023-12},
	note = {Conference Name: {IEEE} Internet of Things Magazine},
	keywords = {Data privacy, Performance evaluation, Internet of Things, Computational modeling, Training, Computational efficiency, Backpropagation},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\4Q8GM3Y7\\10364651.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\BFRF2GUN\\Lyu et al. - 2023 - Scalable Aggregated Split Learning for Data-Driven.pdf:application/pdf},
}

@inproceedings{trotta_optimizing_2023,
	title = {Optimizing {IoT}-based Human Activity Recognition on Extreme Edge Devices},
	url = {https://ieeexplore.ieee.org/document/10207611/},
	doi = {10.1109/SMARTCOMP58114.2023.00023},
	abstract = {Wearable Internet of Things ({IoT}) devices with inertial sensors can enable personalized and fine-grained Human Activity Recognition ({HAR}). While activity classification on the Extreme Edge ({EE}) can reduce latency and maximize user privacy, it must tackle the unique challenges posed by the constrained environment. Indeed, Deep Learning ({DL}) techniques may not be applicable, and data processing can become burdensome due to the lack of input systems. In this paper, we address those issues by proposing, implementing, and validating an {EE}-aware {HAR} system. Our system incorporates a feature selection mechanism to reduce the data dimensionality in input, and an unsupervised feature separation and classification technique based on Self-Organizing Maps ({SOMs}). We developed the system on an M5Stack {IoT} prototype board and implemented a new {SOM} library for the Arduino {SDK}. Experimental results on two {HAR} datasets show that our proposed solution is able to overcome other unsupervised approaches and achieve performance close to state-of-art {DL} techniques while generating a model small enough to fit the limited memory capabilities of {EE} devices.},
	eventtitle = {2023 {IEEE} International Conference on Smart Computing ({SMARTCOMP})},
	pages = {41--48},
	booktitle = {2023 {IEEE} International Conference on Smart Computing ({SMARTCOMP})},
	author = {Trotta, Angelo and Montori, Federico and Vallasciani, Giacomo and Bononi, Luciano and Di Felice, Marco},
	urldate = {2024-01-29},
	date = {2023-06},
	note = {{ISSN}: 2693-8340},
	keywords = {Performance evaluation, Image edge detection, {IoT}, Edge Computing, Feature extraction, Wearable computers, {HAR}, Human Activity Recognition, Inertial sensors, Prototypes, Self Organizing Maps, Self-organizing feature maps, Unsupervised Learning},
	file = {Trotta et al. - 2023 - Optimizing IoT-based Human Activity Recognition on.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\NIRMTLYL\\Trotta et al. - 2023 - Optimizing IoT-based Human Activity Recognition on.pdf:application/pdf},
}

@inproceedings{menon_architecture_2023,
	title = {Architecture and Implementation of a patient criticality aware Edge-Cloud offloading technique},
	url = {https://ieeexplore.ieee.org/document/10126178/},
	doi = {10.1109/I2CT57861.2023.10126178},
	abstract = {The Internet of Things ({IoT})-based remote health monitoring is one of the most promising technological interventions that is emerging to address the unique challenges of affordability, accessibility, and availability in global health, which denote equitable access to healthcare, particularly in remote-rural-developing regions. {IoT} devices can monitor multiple vital signs, which are then used for {AI}-assisted decision-making systems, which in turn assist physicians in forecasting remotely. However, there are many difficulties, like bandwidth issues, data loss, and overburdened doctors due to the massive amount of data. Shifting data from cloud to edge improves performance, cost efficiency, privacy, reduces communication between distant servers and the edge, resulting in less processing delay. We developed a clinical response requirement based cloud-to-edge offloading technique. As a use case, we developed an edge {AI} application for acute hypotensive episode prediction and compared its performance both in the cloud as well as on the edge.},
	eventtitle = {2023 {IEEE} 8th International Conference for Convergence in Technology (I2CT)},
	pages = {1--7},
	booktitle = {2023 {IEEE} 8th International Conference for Convergence in Technology (I2CT)},
	author = {Menon, Athira B and Rajeev, Krishna and S, Jyothika and Ratheesh, Karthika and Pathinarupothi, Rahul Krishnan},
	urldate = {2024-01-29},
	date = {2023-04},
	keywords = {Performance evaluation, Internet of Things, Cloud computing, Servers, Delays, Medical services, Edge {AI}, Healthcare, Machine Learning, Decision making, {IoT} Devices},
	file = {Menon et al. - 2023 - Architecture and Implementation of a patient criti.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\XBNB4NAC\\Menon et al. - 2023 - Architecture and Implementation of a patient criti.pdf:application/pdf},
}

@inproceedings{jerang_privacy-preserving_2023,
	title = {Privacy-Preserving of Edge Intelligence using Homomorphic Encryption},
	url = {https://ieeexplore.ieee.org/document/10205745/},
	doi = {10.1109/CONIT59222.2023.10205745},
	abstract = {Edge intelligence has paved the way for a stronger and more secure system by combining security and artificial intelligence. A lot of research have been undertaken, revealing remarkable development and a variety of viewpoints on this novel phenomenon. We suggested a way enabling edge intelligence to move via homomorphic encryption-enabled gadgets and automobiles. This encrypted data will be delivered to an edge node for the building of a machine learning model in order to gather any potential information hidden in the data as well as any potential obstacles that may need to be addressed before any event happens. Several machine learning models, such as {KNN}, K-means, {SVM}, and others, are used to gain the best possible data analysis. Once secure, decisions will be taken, and the outcome will be visible. All machine learning training will be done in encrypted data, which will be encrypted to ensure that no one’s privacy is abused. This may be set up for a variety of machine learning modules.},
	eventtitle = {2023 3rd International Conference on Intelligent Technologies ({CONIT})},
	pages = {1--6},
	booktitle = {2023 3rd International Conference on Intelligent Technologies ({CONIT})},
	author = {Jerang, Ronaldo and Nayak, Sumitra and Mahato, Ganesh Kumar and Kumar Chakraborty, Swarnendu},
	urldate = {2024-01-29},
	date = {2023-06},
	keywords = {Data privacy, Data models, Training, Cryptography, deep learning, Federated learning, privacy protection, Edge intelligence, homomorphic encryption, Industries, Paillier cryptosystem, Support vector machines},
	file = {Jerang et al. - 2023 - Privacy-Preserving of Edge Intelligence using Homo.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\6KKBUN8E\\Jerang et al. - 2023 - Privacy-Preserving of Edge Intelligence using Homo.pdf:application/pdf},
}

@inproceedings{ponnapalli_triple-tap_2023,
	title = {A Triple-Tap Hybrid Load Balancing System ({TTHLB}) for Health Monitoring System},
	url = {https://ieeexplore.ieee.org/document/10290416/},
	doi = {10.1109/I-SMAC58438.2023.10290416},
	abstract = {With the rapid development in innovation and a rising need for efficient healthcare services, innovative approaches to healthcare system design are required. In recent years, integrating cloud computing, edge computing, and fog computing has emerged as a promising solution to enhance the efficiency and effectiveness of healthcare systems. The paper proposes a triple-tap hybrid load balancing method ({TTHLB}) that leverages the capabilities of cloud computing, edge computing, and fog computing to provide seamless and efficient healthcare services. The {TTHLB} architecture comprises three layers: the cloud layer, the edge layer, and the fog layer. The cloud layer is the central repository for storing and processing large volumes of healthcare data. It provides on-demand access to computational resources and supports advanced data analytics techniques for decision-making and predictive analysis. The edge layer, consisting of edge devices such as wearable’s and sensors, collects real-time patient data and performs initial data processing. It enables real-time monitoring, early detection of health issues, and timely intervention. Between the cloud and edge layers, the fog layer acts as an intermediate data processing and storage layer. It reduces latency and bandwidth requirements by performing data processing closer to the edge devices. The {TTHLB} leverages the benefits of cloud computing, such as scalability, flexibility, and cost-effectiveness, by offloading resource-intensive tasks to the cloud layer. It also utilizes the capabilities of edge and fog computing to provide low-latency, real-time data processing and analysis, ensuring timely and personalized healthcare services. Integrating these computing paradigms enables seamless data exchange and collaboration among healthcare providers, patients, and other stakeholders, improving diagnosis, treatment, and patient outcomes. Finally, the {TTHLB} presented in this research work provides a comprehensive solution to traditional healthcare systems' challenges. It uses cloud, edge, and fog computing to deliver efficient, personalized, and timely healthcare services. The {TTHLB} can transform the healthcare industry and improve overall patient care quality.},
	eventtitle = {2023 7th International Conference on I-{SMAC} ({IoT} in Social, Mobile, Analytics and Cloud) (I-{SMAC})},
	pages = {616--622},
	booktitle = {2023 7th International Conference on I-{SMAC} ({IoT} in Social, Mobile, Analytics and Cloud) (I-{SMAC})},
	author = {Ponnapalli, Sudhir and Dornala, Raghunadha Reddi and Vallabaneni, S Parvathi},
	urldate = {2024-01-29},
	date = {2023-10},
	note = {{ISSN}: 2768-0673},
	keywords = {Performance evaluation, Edge computing, Cloud computing, Image edge detection, Medical services, Fog computing, Decision making, Industries, A Triple-Tap Hybrid Load Balancing System ({TTHLB}), Load management},
	file = {Ponnapalli et al. - 2023 - A Triple-Tap Hybrid Load Balancing System (TTHLB) .pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\9QRSEQBG\\Ponnapalli et al. - 2023 - A Triple-Tap Hybrid Load Balancing System (TTHLB) .pdf:application/pdf},
}

@inproceedings{rawat_blockchain_2023,
	title = {Blockchain based Federated Deep Learning Framework for Malware Attacks Detection in {IoT} Devices},
	url = {https://ieeexplore.ieee.org/document/10306828/},
	doi = {10.1109/ICCCNT56998.2023.10306828},
	abstract = {Over the recent years, billions of {IoT} devices that do not have adequate security features have been created and deployed over internet, and with the increased bandwidth and lower latency of 5G networks these numbers expected to grow exponentially. Consequently, there is a pressing requirement of reliable methods to identify malware infected {IoT} devices present in a network. Traditional Centralized Deep Learning approach was used to train a model capable of detecting infected {IoT} devices, but this approach faces major challenges like data privacy violation, scalability and high network latency. A more efficient process Federated Deep Learning was proposed which aims to improve privacy and security by keeping data on the devices and transmitting only model parameters to a central location for aggregation and then this aggregated model reflected to the edge devices. Because of the centralized aggregation this approach is prone to adversarial attacks. To resolve these vulnerabilities, we presented a decentralized framework consisting of a chain of Federated blocks at each edge devices with cohere-consensus mechanism ({FBCC}). The framework makes use of blockchain technology both for updating local models and to store global models. We also came up with a novel cohere-consensus technique to facilitate the suggested {FBCC}, which efficiently cut down on the quantity of consensus computing while simultaneously lowering the risk of malicious attacks. At last, we conducted comprehensive testing of the frameworks with real-world datasets, in both benign and malicious environments. The results revealed that our proposed framework outperformed the other frameworks in the malicious environment, while demonstrating comparable efficiency in the benign environment. Additionally, we conducted a thorough comparison of the frameworks in terms of memory requirements and training time. {FBCC} framework, due to its core architecture, exhibited slightly lower performance than {FDL}. However, it maintained privacy as a top priority.},
	eventtitle = {2023 14th International Conference on Computing Communication and Networking Technologies ({ICCCNT})},
	pages = {1--10},
	booktitle = {2023 14th International Conference on Computing Communication and Networking Technologies ({ICCCNT})},
	author = {Rawat, Pankaj and Kumar, Prashant},
	urldate = {2024-01-29},
	date = {2023-07},
	note = {{ISSN}: 2473-7674},
	keywords = {Internet of Things ({IoT}), Computational modeling, Data models, Deep learning, Training, Blockchains, Blockchain, Federated learning, Scalability, Centralized Deep Learning ({CDL}), Deep Neural Network ({DNN}), Federated Deep Learning ({FDL})},
	file = {Rawat e Kumar - 2023 - Blockchain based Federated Deep Learning Framework.pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\A9VZC3WY\\Rawat e Kumar - 2023 - Blockchain based Federated Deep Learning Framework.pdf:application/pdf},
}

@inproceedings{gong_intelligent_2023,
	title = {Intelligent Monitoring and Multi-parameter Identification of Power Distribution Network State},
	url = {https://ieeexplore.ieee.org/document/10136019/},
	doi = {10.1109/ACPEE56931.2023.10136019},
	abstract = {Intelligent monitoring and multi-parameter identification of power distribution network state is an important technology for the construction of new power system. The objective of this research is to develop algorithms and techniques for monitoring the state of power distribution networks, identifying any abnormal conditions, and taking appropriate actions to ensure the reliability and stability of the network. Intelligent monitoring involves the use of advanced sensors, communication networks, and data analytics tools to continuously monitor the key parameters of the power distribution network. These monitoring parameters include voltage, current, power flow, partial discharge, mechanical vibration, overheating temperature and other electrical quantities. The edge computing technique in electrical power equipment condition monitoring will be real-time, intelligent, but also has good data processing ability for intelligent monitoring of power distribution network. The data from these sensors is collected and analyzed by edge computing in real-time to detect any abnormalities or deviations from the normal operating conditions. Multi-parameter identification involves the use of advanced data analytics tools to identify the relationships between different parameters of the power distribution network. This enables the identification of any inter-dependencies or correlations between different parameters, which can be used to identify the root cause of any abnormalities in the network. The use of intelligent monitoring and multi-parameter identification can help power distribution companies to improve the reliability and stability of their networks, reduce downtime, and optimize their operations. It can also help to improve the quality of service provided to customers by ensuring that power is supplied reliably and consistently in new power system.},
	eventtitle = {2023 8th Asia Conference on Power and Electrical Engineering ({ACPEE})},
	pages = {1875--1879},
	booktitle = {2023 8th Asia Conference on Power and Electrical Engineering ({ACPEE})},
	author = {Gong, Cheng and Li, {YiFei} and Zhang, {BaoQun} and Yu, Zhao and Dai, Quanmin and Li, {TianLe} and Zhang, {DongYing}},
	urldate = {2024-01-29},
	date = {2023-04},
	keywords = {Monitoring, Real-time systems, Data analysis, Distribution networks, intelligent monitoring, multi - parameter identification, New Power System, power distribution network, Power system reliability, Power system stability, Temperature sensors},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\E7NTPGH4\\10136019.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\EZPXKY8F\\Gong et al. - 2023 - Intelligent Monitoring and Multi-parameter Identif.pdf:application/pdf},
}

@article{zhou_edge-cloud_2023,
	title = {An Edge-Cloud Collaboration Framework for Graph Processing in Smart Society},
	volume = {11},
	issn = {2168-6750},
	url = {https://ieeexplore.ieee.org/document/10192547/},
	doi = {10.1109/TETC.2023.3297066},
	abstract = {Due to the limitations of cloud computing on latency, bandwidth and data confidentiality, edge computing has emerged as a novel location-aware way to provide the capacity-constrained portable terminals with more processing capacity to improve the computing performance and quality of service ({QoS}) in several typical domains of the human activity in smart society, such as social networks, medical diagnosis, telecommunications, recommendation systems, internal threat detection, transportation, Internet of Things ({IoT}), etc. These application domains often manage a vast collection of entities with various relationships, which can be naturally represented by the graph data structure. Graph processing is a powerful tool to model and optimize complex problems where graph-based data is involved. In consideration of the relatively insufficient resource provisioning of the edge devices, in this article, for the first time to our knowledge, we propose a reliable edge-cloud collaboration framework that facilitates the graph primitives based on a lightweight interactive graph processing library ({GPL}), especially for shortest path search ({SPS}) operations as the demonstrative example. Two types of different practical cases are also presented to show the typical application scenarios of our graph processing strategy. Experimental evaluations indicate that the acceleration rate of performance can reach 6.87x via graph reduction, and less than 3\% and 20\% extra latency is required for much better user experiences for navigation and pandemic control, respectively, while the online security measures merely consume about 1\% extra time of the overall data transmission. Our framework can efficiently execute the applications with considering of user-friendliness, low-latency response, interactions among edge devices, collaboration between edge and cloud, and privacy protection at an acceptable overhead.},
	pages = {985--1001},
	number = {4},
	journaltitle = {{IEEE} Transactions on Emerging Topics in Computing},
	author = {Zhou, Jun and Kondo, Masaaki},
	urldate = {2024-01-29},
	date = {2023-10},
	note = {Conference Name: {IEEE} Transactions on Emerging Topics in Computing},
	keywords = {Privacy, Performance evaluation, Edge computing, Quality of service, Cloud computing, Collaboration, Edge-cloud collaboration, graph processing, interactivity, Libraries, network socket, reliability},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Emanuele\\Zotero\\storage\\PKH5GGCU\\10192547.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\98LNY5HB\\Zhou e Kondo - 2023 - An Edge-Cloud Collaboration Framework for Graph Pr.pdf:application/pdf},
}

@inproceedings{cesarano_security_2023,
	title = {Security Assessment and Hardening of Fog Computing Systems},
	url = {https://ieeexplore.ieee.org/document/10301338/},
	doi = {10.1109/ISSREW60843.2023.00037},
	abstract = {In recent years, there has been a shift in computing architectures, moving away from centralized cloud computing towards decentralized edge and fog computing. This shift is driven by factors such as the increasing volume of data generated at the edge, the growing demand for real-time processing and low-latency applications, and the need for improved privacy and data locality. Although this new paradigm offers numerous advantages, it also introduces significant security and reliability challenges. This paper aims to review the architectures and technologies employed in fog computing and identify opportunities for developing novel security assessment and security hardening techniques. These techniques include secure configuration and debloating to enhance the security of middleware, testing techniques to assess secure communication mechanisms, and automated rehosting to speed up the security testing of embedded firmware.},
	eventtitle = {2023 {IEEE} 34th International Symposium on Software Reliability Engineering Workshops ({ISSREW})},
	pages = {22--25},
	booktitle = {2023 {IEEE} 34th International Symposium on Software Reliability Engineering Workshops ({ISSREW})},
	author = {Cesarano, Carmine},
	urldate = {2024-01-29},
	date = {2023-10},
	keywords = {Computer architecture, Real-time systems, Security, Fog computing, Knowledge engineering, Software reliability, Configuration, Debloating, Fuzzing, Low latency communication, Middleware, Rehosting},
	file = {Versione inviata:C\:\\Users\\Emanuele\\Zotero\\storage\\Q2XM97MV\\Cesarano - 2023 - Security Assessment and Hardening of Fog Computing.pdf:application/pdf},
}

@article{yang_efficient_2023,
	title = {Efficient Edge Data Management Framework for {IIoT} via Prediction-Based Data Reduction},
	volume = {34},
	issn = {1558-2183},
	url = {https://ieeexplore.ieee.org/document/10297424/},
	doi = {10.1109/TPDS.2023.3327750},
	abstract = {Large amounts of time series data are required to support data analysis at the edge in the end-edge-cloud Industrial Internet of Things ({IIoT}) architecture. Reducing the storage cost is one of the main challenges in edge data management due to the limited storage resource of edge nodes. The state-of-the-art data reduction method has a high time overhead and poor reduction efficiency for unstable data sets. To solve this problem, this study proposes a time-series data management framework that combines data partition and data compression techniques. For the data partition technique, we propose an adaptive selection strategy to integrate the access pattern of the application and the characteristics of the time series data, thereby improving the partition accuracy. For the data compression technique, we propose a compression scheme based on time series data segmentation by using the idea of divide and conquer; we further introduce a change point detection technique to improve the compression efficiency for unstable data sets. Experimental results obtained with three types of real industrial data sets show that our framework is significantly better than the state-of-the-art method in terms of compression ratio and time overhead.},
	pages = {3309--3322},
	number = {12},
	journaltitle = {{IEEE} Transactions on Parallel and Distributed Systems},
	author = {Yang, Lei and Liao, Yuwei and Cheng, Xin and Xia, Mengyuan and Xie, Guoqi},
	urldate = {2024-01-29},
	date = {2023-12},
	note = {Conference Name: {IEEE} Transactions on Parallel and Distributed Systems},
	keywords = {Computer architecture, Real-time systems, Industrial Internet of Things, Image edge detection, Data compression, Data reduction, edge data management framework, industrial internet of things ({IIoT}), Streams, Time series analysis},
	file = {Yang et al. - 2023 - Efficient Edge Data Management Framework for IIoT .pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\UYNYINT9\\Yang et al. - 2023 - Efficient Edge Data Management Framework for IIoT .pdf:application/pdf},
}

@inproceedings{farrel_scalable_2023,
	location = {New York, {NY}, {USA}},
	title = {Scalable Edge Computing Cluster Using a Set of Raspberry Pi: A Framework},
	isbn = {9798400708503},
	url = {https://dl.acm.org/doi/10.1145/3626641.3626936},
	doi = {10.1145/3626641.3626936},
	series = {{SIET} '23},
	shorttitle = {Scalable Edge Computing Cluster Using a Set of Raspberry Pi},
	abstract = {In the context of edge computing, a cluster of small single-board computers like Raspberry Pi could serve as robust servers. These clusters not only offer robust server capabilities but also exhibit a remarkable versatility in handling incoming data streams from a multitude of sensors within the Internet of Things ({IoT}) ecosystem, particularly in underserved rural areas. Simultaneously, they can seamlessly double up as servers for web-based applications tailored to the specific requirements of small businesses. However, the operational context of such an edge computing cluster can present challenges. For instance, dynamic load fluctuations, ranging from high to low demands, may lead to performance service degradation or underutilized services. This is a typical problem in distributed computing environments, where the heterogeneity of devices, dynamic conditions, and reliability of connections can create scalability issues. This paper addresses these challenges through a selective set of integrated software suites aiming to autoscale an edge computing cluster. The software suites consist of a lightweight Kubernetes distribution called K3s, with an automation framework executed through Ansible. Rigorous testing, primarily focused on web-based applications, has showcased the efficacy of this approach. A compelling comparison has been drawn between this optimized edge computing setup and conventional desktop-based servers, emphasizing superior power efficiency and commendable performance levels. The service scaling can reduce power consumption by up to 45\%.},
	pages = {287--296},
	booktitle = {Proceedings of the 8th International Conference on Sustainable Information Engineering and Technology},
	publisher = {Association for Computing Machinery},
	author = {Farrel, Gabrielle Evan and Yahya, Widhi and Basuki, Achmad and Amron, Kasyful and Siregar, Reza Andria},
	urldate = {2024-01-29},
	date = {2023-12-27},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\SMPQYBC7\\Farrel et al. - 2023 - Scalable Edge Computing Cluster Using a Set of Ras.pdf:application/pdf},
}

@inproceedings{pfandzelter_serverless_2023,
	location = {New York, {NY}, {USA}},
	title = {Serverless Abstractions for Edge Computing in Large Low-Earth Orbit Satellite Networks},
	isbn = {9798400704291},
	url = {https://dl.acm.org/doi/10.1145/3626564.3629088},
	doi = {10.1145/3626564.3629088},
	series = {Middleware '23},
	abstract = {Private and public actors are building massive {LEO} satellite communication networks. Researchers have proposed extending edge computing to satellites for global low-latency access to application services for, e.g., {IoT} or metaverses. Building applications for this {LEO} edge means managing services at large scale on highly dynamic infrastructure, in addition to the usual constraints of edge computing. We seek to develop serverless abstractions for {LEO} edge applications. We introduce virtual testbed tooling that allows researchers, students, and practitioners to become familiar with the unique characteristics of the {LEO} edge and develop, test, and benchmark real software in a cost-efficient manner. Further, we develop abstractions for state and data management in geo-distributed edge-to-cloud environments. We then integrate these abstractions with a lightweight {FaaS} platform to allow building stateful yet scalable applications on the {LEO} edge. Finally, we propose applications for {LEO} edge computing to guide the evaluation of our design.},
	pages = {3--6},
	booktitle = {Proceedings of the 24th International Middleware Conference: Demos, Posters and Doctoral Symposium},
	publisher = {Association for Computing Machinery},
	author = {Pfandzelter, Tobias},
	urldate = {2024-01-29},
	date = {2023-12-11},
	keywords = {edge computing, {LEO} satellite networks, serverless},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\9BF3CW8P\\Pfandzelter - 2023 - Serverless Abstractions for Edge Computing in Larg.pdf:application/pdf},
}

@inproceedings{pourreza_empirical_2023,
	location = {New York, {NY}, {USA}},
	title = {An Empirical Study of Resource-Stressing Faults in Edge-Computing Applications},
	isbn = {9798400700828},
	url = {https://dl.acm.org/doi/10.1145/3578354.3592873},
	doi = {10.1145/3578354.3592873},
	series = {{EdgeSys} '23},
	abstract = {Our growing reliance on edge-computing applications makes it crucial to improve the reliability of edge-computing systems. With multiple classes of edge-computing applications, different types of faults, and different kinds of resources needed by the applications, it remains unclear which resource exhaustion has the most disruptive impact on the latency experienced by the edge applications. Without this information, it is challenging to determine which faults to prioritize when implementing fault tolerance for edge computing. To address this challenge, we conduct an empirical study on a representative edge computing environment using well-known edge-computing benchmark applications ({DeFog} and {ComB}) and injecting resource-stressing faults (via stress-ng and hping). Our study reveals that memory overloads, {CPU} cache thrashing, frequent context switching, and page faults are the biggest disruptors of latency for edge-based applications.},
	pages = {54--59},
	booktitle = {Proceedings of the 6th International Workshop on Edge Systems, Analytics and Networking},
	publisher = {Association for Computing Machinery},
	author = {Pourreza, Maryam and Narasimhan, Priya},
	urldate = {2024-01-29},
	date = {2023-05-08},
	keywords = {edge computing, benchmark, fault injection, fault tolerance},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\E4DRGCLM\\Pourreza e Narasimhan - 2023 - An Empirical Study of Resource-Stressing Faults in.pdf:application/pdf},
}

@article{al-qerem_transactional_2023,
	title = {Transactional Services for Concurrent Mobile Agents over Edge/Cloud Computing-Assisted Social Internet of Things},
	volume = {15},
	issn = {1936-1955},
	url = {https://dl.acm.org/doi/10.1145/3603714},
	doi = {10.1145/3603714},
	abstract = {The Web of Things ({WoT}) is a concept that aims to create a network of intelligent devices capable of remote monitoring, service provisioning, and control. Virtual and Physical Internet of Things ({IoT}) gateways facilitate communication, processing, and storage among social nodes that form the social Web of Things ({SWoT}). Peripheral {IoT} services commonly use device data. However, due to the limited bandwidth and processing power of edge devices in the {IoT}, they must dynamically alter the quality of service provided to their connected clients to meet each user's needs while also meeting the service quality requirements of other devices that may access the same data. Consequently, deciding which transactions get access to which Internet of Things data is a scheduling problem. Edge-cloud computing requires transaction management because several Internet of Things transactions may access shared data simultaneously. However, cloud transaction management methods cannot be employed in edge-cloud computing settings. Transaction management models must be consistent and consider {ACIDity} of transactions, especially consistency. This study compares three implementation strategies, Edge Host Strategy ({EHS}), Cloud Host Strategy ({CHS}), and Hybrid {BHS} ({BHS}), which execute all {IoT} transactions on the Edge host, the cloud, and both hosts, respectively. These transactions affect the Edge hosts as well. An {IoTT} framework is provided, viewing an Internet of Things transaction as a collection of fundamental and additional subtransactions that loosen atomicity. Execution strategy controls essential and additional subtransactions. The integration of edge and cloud computing demonstrates that the execution approach significantly affects system performance. {EHS} and {CHS} can waste wireless bandwidth, while {BHS} outperforms {CHS} and {EHS} in many scenarios. These solutions enable edge transactions to complete without restarting due to outdated {IoT} data or other edge or cloud transactions. The properties of these approaches have been detailed, showing that they often outperform concurrent protocols and can improve edge-cloud computing.},
	pages = {36:1--36:20},
	number = {3},
	journaltitle = {Journal of Data and Information Quality},
	shortjournal = {J. Data and Information Quality},
	author = {Al-Qerem, Ahmad and Ali, Ali Mohd and Nashwan, Shadi and Alauthman, Mohammad and Hamarsheh, Ala and Nabot, Ahmad and Jibreen, Issam},
	urldate = {2024-01-29},
	date = {2023-09-28},
	keywords = {Concurrency control, edge-cloud computing, execution framework, mobile agents, transactional services},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\YANZ2KP2\\Al-Qerem et al. - 2023 - Transactional Services for Concurrent Mobile Agent.pdf:application/pdf},
}

@inproceedings{dahi_microservices_2023,
	location = {New York, {NY}, {USA}},
	title = {Microservices Containerization in {SBCs} (Single Board Computers): A Cloud Edge Computing Approach},
	isbn = {978-1-4503-9874-9},
	url = {https://dl.acm.org/doi/10.1145/3582099.3582108},
	doi = {10.1145/3582099.3582108},
	series = {{AICCC} '22},
	shorttitle = {Microservices Containerization in {SBCs} (Single Board Computers)},
	abstract = {With the recent and unprecedented increase in demand for Cloud services, furtherly promoted by 5G, Edge computing is emerging as an indispensable technology. Tailored to mitigate the continuously growing load on Cloud data centers and cope with the rising proliferation of {IoT} (Internet of Things), Single Board Computers ({SBCs}), embedded systems, and microservices-based applications, edge computing is turning into an integral technology enabler in 5G. Arguably, most of edge microservices will be deployed using virtualization, and specifically using containers instead of {VMs} (Virtual Machines). Dubbed 5G-{MEC} (Multi-Access Edge Computing), the 5G edge has to cope with 3 major services: {eMBB} (enhanced Mobile Broadband), {mMTC} (Massive Machine Type Communication), and {URLLC} (Ultra Reliable Low Latency Communication). In this paper, we shed further light on the fundamentals of cloud edge computing and present the subtleties of deploying a real-world {SBC}-based distributed edge application. The latter is an {AI}-based application, embedding an image recognition microservice running in containers, deployed in Raspberry {PI} {SBCs}, and orchestrated using Kubernetes.},
	pages = {49--58},
	booktitle = {Proceedings of the 2022 5th Artificial Intelligence and Cloud Computing Conference},
	publisher = {Association for Computing Machinery},
	author = {Dahi, Othmane and Aboulfoujja, Maryem and Akiour, Mohammed and Elbouardi, Bilal and Choukri, Anass and Abid, Mohamed Riduan},
	urldate = {2024-01-29},
	date = {2023-04-20},
	keywords = {edge computing, microservices, Containerization, single board computers},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\JGP93HYW\\Dahi et al. - 2023 - Microservices Containerization in SBCs (Single Boa.pdf:application/pdf},
}

@inproceedings{tlemcani_advanced_2023,
	location = {New York, {NY}, {USA}},
	title = {An Advanced {IoT}-Based Architecture for Healthcare Systems: A Focus on Blockchain-based Edge Computing for Diabetes Management},
	isbn = {9798400700194},
	url = {https://dl.acm.org/doi/10.1145/3607720.3607756},
	doi = {10.1145/3607720.3607756},
	series = {{NISS} '23},
	shorttitle = {An Advanced {IoT}-Based Architecture for Healthcare Systems},
	abstract = {The healthcare industry has undergone a significant transformation with the emergence of Internet of Things ({IoT}) technology. Various computing paradigms, including cloud computing, fog computing, and edge computing, have emerged to address challenges in processing, storing, and analyzing data in modern systems. This paper proposes an advanced architecture for healthcare systems based on our research team's previous work. Our research focuses on developing a smart healthcare system to assist diabetes patients in managing their illness. Our novel architecture builds on the previous one, which included blockchain with {IoT}, by incorporating a blockchain-based edge layer to address scalability and security challenges that were previously encountered.},
	pages = {1--7},
	booktitle = {Proceedings of the 6th International Conference on Networking, Intelligent Systems \& Security},
	publisher = {Association for Computing Machinery},
	author = {Tlemçani, Khadija and Jai Andaloussi, Said and Azbeg, Kebira and Ouchetto, Ouail and Fetjah, Laila},
	urldate = {2024-01-29},
	date = {2023-11-13},
	keywords = {{IoT}, Edge Computing, Blockchain, Healthcare, Cloud Computing, Diabetes Management, Fog Computing},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\GCVI4DHD\\Tlemçani et al. - 2023 - An Advanced IoT-Based Architecture for Healthcare .pdf:application/pdf},
}

@inproceedings{qian_time-sensitive_2023,
	location = {New York, {NY}, {USA}},
	title = {Time-Sensitive Data Processing Strategy for Enhancing the Performance of {BFT} Consensus Mechanism in {IoT} Edge Computing Environment},
	isbn = {9798400707629},
	url = {https://dl.acm.org/doi/10.1145/3625403.3625436},
	doi = {10.1145/3625403.3625436},
	series = {{ADMIT} '23},
	abstract = {Applying the {BFT} consensus mechanism in the {IoT} edge computing environment effectively solves the problem of data consistency and trustworthiness. However, the existing {BFT} consensus mechanism needs to pay attention to the impact of the data processing flow on consensus performance, and the repetitive data processing operations lead to the waste of computing resources of consensus nodes. Therefore, in this paper, we analyze the data processing flow of the {BFT} consensus mechanism, propose a time-sensitive data processing strategy from the idea of reducing the number of consensus nodes involved in data processing, and select data processing nodes by taking data processing time as the optimization target to improve the resource utilization of consensus nodes while ensuring consensus reaching. Through simulation experiments, our proposed time-sensitive data processing strategy achieves the best latency and throughput performance in a simulated {IoT} edge computing environment, demonstrating that the time-sensitive data processing strategy can effectively improve the performance of the {BFT} consensus mechanism.},
	pages = {181--188},
	booktitle = {Proceedings of the 2023 2nd International Conference on Algorithms, Data Mining, and Information Technology},
	publisher = {Association for Computing Machinery},
	author = {Qian, Cheng and Tang, Wenzhong and Wang, Yanyang},
	urldate = {2024-01-29},
	date = {2023-11-17},
	keywords = {Edge computing, Internet of things, Blockchain, {BFT} consensus mechanism, Data processing strategy},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\YYZEM4D3\\Qian et al. - 2023 - Time-Sensitive Data Processing Strategy for Enhanc.pdf:application/pdf},
}

@inproceedings{wang_trust_2023,
	location = {New York, {NY}, {USA}},
	title = {Trust evaluation model based on improved Bayesian theory for the Internet of Things},
	isbn = {978-1-4503-9752-0},
	url = {https://dl.acm.org/doi/10.1145/3586102.3586125},
	doi = {10.1145/3586102.3586125},
	series = {{ICCNS} '22},
	abstract = {At present, the Internet of Things ({IoT}) is applied to all aspects of people's lives. The traditional cloud-based Internet of Things has been unable to support the development needs of the Internet of Things at this stage. The emergence of edge computing provides new opportunities for the development of the Internet of Things, but also brings new security threats.In view of the security requirements for nodes in the {IoT} edge computing scenario, this paper proposes a comprehensive trust evaluation model for terminal nodes based on improved Bayesian theory. Aiming at the time-effectiveness of trust, a trust decay strategy is designed, and a direct trust evaluation of {IoT} terminals is carried out based on improved Bayesian theory.At the same time, aiming at the problem of dishonest recommendation behavior in indirect trust evaluation, a consistent optimization strategy of node recommendation behavior is designed. Finally, the comprehensive trust evaluation value of the terminal node is obtained according to the direct trust evaluation and the indirect trust evaluation. The effectiveness of this scheme is verified by simulation experiments.},
	pages = {152--158},
	booktitle = {Proceedings of the 2022 12th International Conference on Communication and Network Security},
	publisher = {Association for Computing Machinery},
	author = {Wang, Xiaoliang and Zhang, Feng and Ma, Yanbo and Dai, Wenjuan and Jin, Yingying},
	urldate = {2024-01-29},
	date = {2023-07-24},
	keywords = {Bayesian Theory, edge computation, The Internet of Things, trust evaluation},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\67RLSG2T\\Wang et al. - 2023 - Trust evaluation model based on improved Bayesian .pdf:application/pdf},
}

@article{jeyaraj_resource_2023,
	title = {Resource Management in Cloud and Cloud-influenced Technologies for Internet of Things Applications},
	volume = {55},
	issn = {0360-0300},
	url = {https://dl.acm.org/doi/10.1145/3571729},
	doi = {10.1145/3571729},
	abstract = {The trend of adopting Internet of Things ({IoT}) in healthcare, smart cities, Industry 4.0, and so on is increasing by means of cloud computing, which provides on-demand storage and computation facilities over the Internet. To meet specific requirements of {IoT} applications, the cloud has also shifted its service offering platform to its next-generation models, such as fog, mist, and dew computing. As a result, the cloud and {IoT} have become part and parcel of smart applications that play significant roles in improving the quality of human life. In addition to the inherent advantages of advanced cloud models, to improve the performance of {IoT} applications further, it is essential to understand how the resources in the cloud and cloud-influenced platforms are managed to support various phases in the end-to-end {IoT} deployment. Considering this importance, in this article, we provide a brief description, a systematic review, and possible research directions on every aspect of resource management tasks, such as workload modeling, resource provisioning, workload scheduling, resource allocation, load balancing, energy management, and resource heterogeneity in such advanced platforms, from a cloud perspective. The primary objective of this article is to help early researchers gain insight into the underlying concepts of resource management tasks in the cloud for {IoT} applications.},
	pages = {242:1--242:37},
	number = {12},
	journaltitle = {{ACM} Computing Surveys},
	shortjournal = {{ACM} Comput. Surv.},
	author = {Jeyaraj, Rathinaraja and Balasubramaniam, Anandkumar and M.A., Ajay Kumara and Guizani, Nadra and Paul, Anand},
	urldate = {2024-01-29},
	date = {2023-03-02},
	keywords = {Internet of Things, edge computing, fog computing, Cloud computing, resource allocation, resource scheduling, dew computing, load balancing, mist computing, resource heterogeneity, resource provisioning},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\6B8PUP6X\\Jeyaraj et al. - 2023 - Resource Management in Cloud and Cloud-influenced .pdf:application/pdf},
}

@inproceedings{hosen_secblock-iiot_2023,
	location = {New York, {NY}, {USA}},
	title = {{SECBlock}-{IIoT}: A Secure Blockchain-enabled Edge Computing Framework for Industrial Internet of Things},
	isbn = {9798400701825},
	url = {https://dl.acm.org/doi/10.1145/3591365.3592945},
	doi = {10.1145/3591365.3592945},
	series = {{ASSS} '23},
	shorttitle = {{SECBlock}-{IIoT}},
	abstract = {The {IoT} is widely used in a number of industries and generates large amounts of data. The data are processed, computed, and stored through distributed computing for analytical purposes. This invokes serious security and privacy concerns, and presents scalability issues. This paper describes a secure P2P and group communication supportive edge computing framework for {IIoT} systems, a consortium blockchain, and {IPFS}-based immutable data storage system, and an intelligent threat detection model to protect confidential data and identify cyber-attacks. Secure communications were ensured using a hybrid security scheme that included modified {ECC}, {PUF}, and Lagrange interpolation. We utilized a modified {PoV} consensus algorithm to resolve latency issues due to overhead and point of failure errors during block mining. The threat intelligence model used an autoencoder to transform data into a new format which was then fed into an {RNN}-{DL} to identify cyber-attacks. The model detected normal and anomalous activity, and then identified the category of detected malicious activity. We evaluated the framework according to various metrics and compared it with {ECC}, {PoV}, and {ML}-based classifiers. The results showed that the proposed system demonstrated a higher efficiency and improved scalability than conventional frameworks.},
	pages = {1--14},
	booktitle = {Proceedings of the Third International Symposium on Advanced Security on Software and Systems},
	publisher = {Association for Computing Machinery},
	author = {Hosen, A. S. M. Sanwar and Sharma, Pradip Kumar and Puthal, Deepak and Ra, In-Ho and Cho, Gi Hwan},
	urldate = {2024-01-29},
	date = {2023-07-10},
	keywords = {Edge computing, Blockchain, Security and privacy, Industrial internet of things ({IIoT}), Intelligent threat detection ({ITD})},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\YZR345K8\\Hosen et al. - 2023 - SECBlock-IIoT A Secure Blockchain-enabled Edge Co.pdf:application/pdf},
}

@article{dar_upscaling_2023,
	title = {Upscaling Fog Computing in Oceans for Underwater Pervasive Data Science Using Low-Cost Micro-Clouds},
	volume = {4},
	url = {https://dl.acm.org/doi/10.1145/3575801},
	doi = {10.1145/3575801},
	abstract = {Underwater environments are emerging as a new frontier for data science thanks to an increase in deployments of underwater sensor technology. Challenges in operating computing underwater combined with a lack of high-speed communication technology covering most aquatic areas means that there is a significant delay between the collection and analysis of data. This in turn limits the scale and complexity of the applications that can operate based on these data. In this article, we develop underwater fog computing support using low-cost micro-clouds and demonstrate how they can be used to deliver cost-effective support for data-heavy underwater applications. We develop a proof-of-concept micro-cloud prototype and use it to perform extensive benchmarks that evaluate the suitability of underwater micro-clouds for diverse underwater data science scenarios. We conduct rigorous tests in both controlled and field deployments, using river and sea waters. We also address technical challenges in enabling underwater fogs, evaluating the performance of different communication interfaces and demonstrating how accelerometers can be used to detect the likelihood of communication failures and determine which communication interface to use. Our work offers a cost-effective way to increase the scale and complexity of underwater data science applications, and demonstrates how off-the-shelf devices can be adopted for this purpose.},
	pages = {9:1--9:29},
	number = {2},
	journaltitle = {{ACM} Transactions on Internet of Things},
	shortjournal = {{ACM} Trans. Internet Things},
	author = {Dar, Farooq and Liyanage, Mohan and Radeta, Marko and Yin, Zhigang and Zuniga, Agustin and Kosta, Sokol and Tarkoma, Sasu and Nurmi, Petteri and Flores, Huber},
	urldate = {2024-01-29},
	date = {2023-03-15},
	keywords = {computation offloading, cloud computing, edge computing, aquatic environments, Cloudlets},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\AQ87MC63\\Dar et al. - 2023 - Upscaling Fog Computing in Oceans for Underwater P.pdf:application/pdf},
}

@article{dong_watchdog_2023,
	title = {{WatchDog}: Real-time Vehicle Tracking on Geo-distributed Edge Nodes},
	volume = {4},
	url = {https://dl.acm.org/doi/10.1145/3549551},
	doi = {10.1145/3549551},
	shorttitle = {{WatchDog}},
	abstract = {Vehicle tracking, a core application to smart city video analytics, is becoming more widely deployed than ever before thanks to the increasing number of traffic cameras and recent advances in computer vision and machine-learning. Due to the constraints of bandwidth, latency, and privacy concerns, tracking tasks are more preferable to run on edge devices sitting close to the cameras. However, edge devices are provisioned with a fixed amount of computing budget, making them incompetent to adapt to time-varying and imbalanced tracking workloads caused by traffic dynamics. In coping with this challenge, we propose {WatchDog}, a real-time vehicle tracking system that fully utilizes edge nodes across the road network. {WatchDog} leverages computer vision tasks with different resource-accuracy tradeoffs, and decomposes and schedules tracking tasks judiciously across edge devices based on the current workload to maximize the number of tasks while ensuring a provable response time-bound at each edge device. Extensive evaluations have been conducted using real-world city-wide vehicle trajectory datasets, achieving exceptional tracking performance with a real-time guarantee.},
	pages = {2:1--2:23},
	number = {1},
	journaltitle = {{ACM} Transactions on Internet of Things},
	shortjournal = {{ACM} Trans. Internet Things},
	author = {Dong, Zheng and Lu, Yan and Tong, Guangmo and Shu, Yuanchao and Wang, Shuai and Shi, Weisong},
	urldate = {2024-01-29},
	date = {2023-02-23},
	keywords = {Edge computing, neural networks, real-time system, road network},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\NE2LYAMP\\Dong et al. - 2023 - WatchDog Real-time Vehicle Tracking on Geo-distri.pdf:application/pdf},
}

@inproceedings{zheng_trusted_2023,
	location = {New York, {NY}, {USA}},
	title = {Trusted authentication mechanism oriented to network computing offloading at the perception layer},
	isbn = {978-1-4503-9752-0},
	url = {https://dl.acm.org/doi/10.1145/3586102.3586124},
	doi = {10.1145/3586102.3586124},
	series = {{ICCNS} '22},
	abstract = {The current deep integration of the Internet of Things and edge computing has improved the computing capabilities of the perception layer of the Internet of Things. The existing edge computing offloading technology has the problems of lack of a security authentication mechanism and a single problem of solidification of offloading strategies. Based on this, this paper studies the trusted authentication mechanism for the Internet of Things and the optimization scheme of computing offloading. While ensuring the network security of the perception layer of the Internet of Things, according to the changes of the perception layer network, adaptively adjust the computing task offloading strategy for the Internet of Things terminal to improve the operating efficiency of the perception layer of the Internet of Things.},
	pages = {146--151},
	booktitle = {Proceedings of the 2022 12th International Conference on Communication and Network Security},
	publisher = {Association for Computing Machinery},
	author = {Zheng, Wei and Kang, Naixin and Ye, Tao and Tan, Haining},
	urldate = {2024-01-29},
	date = {2023-07-24},
	keywords = {Internet of things, perceptual layer, Trusted authentication mechanism},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\655FBB8H\\Zheng et al. - 2023 - Trusted authentication mechanism oriented to netwo.pdf:application/pdf},
}

@article{wang_fl4iot_2023,
	title = {{FL}4IoT: {IoT} Device Fingerprinting and Identification Using Federated Learning},
	volume = {4},
	url = {https://dl.acm.org/doi/10.1145/3603257},
	doi = {10.1145/3603257},
	shorttitle = {{FL}4IoT},
	abstract = {Unidentified devices in a network can result in devastating consequences. It is, therefore, necessary to fingerprint and identify {IoT} devices connected to private or critical networks. With the proliferation of massive but heterogeneous {IoT} devices, it is getting challenging to detect vulnerable devices connected to networks. Current machine learning-based techniques for fingerprinting and identifying devices necessitate a significant amount of data gathered from {IoT} networks that must be transmitted to a central cloud. Nevertheless, private {IoT} data cannot be shared with the central cloud in numerous sensitive scenarios. Federated learning ({FL}) has been regarded as a promising paradigm for decentralized learning and has been applied in many different use cases. It enables machine learning models to be trained in a privacy-preserving way. In this article, we propose a privacy-preserved {IoT} device fingerprinting and identification mechanisms using {FL}; we call it {FL}4IoT. {FL}4IoT is a two-phased system combining unsupervised-learning-based device fingerprinting and supervised-learning-based device identification. {FL}4IoT shows its practicality in different performance metrics in a federated and centralized setup. For instance, in the best cases, empirical results show that {FL}4IoT achieves ∼99\% accuracy and F1-Score in identifying {IoT} devices using a federated setup without exposing any private data to a centralized cloud entity. In addition, {FL}4IoT can detect spoofed devices with over 99\% accuracy.},
	pages = {17:1--17:24},
	number = {3},
	journaltitle = {{ACM} Transactions on Internet of Things},
	shortjournal = {{ACM} Trans. Internet Things},
	author = {Wang, Han and Eklund, David and Oprea, Alina and Raza, Shahid},
	urldate = {2024-01-29},
	date = {2023-07-25},
	keywords = {Internet of things, federated learning, machine learning, fingerprinting, identification},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\8NYS9WAV\\Wang et al. - 2023 - FL4IoT IoT Device Fingerprinting and Identificati.pdf:application/pdf},
}

@inproceedings{buschmann_task_2023,
	location = {New York, {NY}, {USA}},
	title = {Task Allocation in Industrial Edge Networks with Particle Swarm Optimization and Deep Reinforcement Learning},
	isbn = {978-1-4503-9665-3},
	url = {https://dl.acm.org/doi/10.1145/3567445.3571114},
	doi = {10.1145/3567445.3571114},
	series = {{IoT} '22},
	abstract = {To avoid the disadvantages of a cloud-centric infrastructure, next-generation industrial scenarios focus on using distributed edge networks. Task allocation in distributed edge networks with regards to minimizing the energy consumption is {NP}-hard and requires considerable computational effort to obtain optimal results with conventional algorithms like Integer Linear Programming ({ILP}). We extend an existing {ILP} problem including an {ILP} heuristic for multi-workflow allocation and propose a Particle Swarm Optimization ({PSO}) and a Deep Reinforcement Learning ({DRL}) algorithm. {PSO} and {DRL} outperform the {ILP} heuristic with a median optimality gap of and against . {DRL} has the lowest upper bound for the optimality gap. It performs better than {PSO} for problem sizes of more than 25 tasks and {PSO} fails to find a feasible solution for more than 60 tasks. The execution time of {DRL} is significantly faster with a maximum of 1 s in comparison to {PSO} with a maximum of 361 s. In conclusion, our experiments indicate that {PSO} is more suitable for smaller and {DRL} for larger sized task allocation problems.},
	pages = {239--247},
	booktitle = {Proceedings of the 12th International Conference on the Internet of Things},
	publisher = {Association for Computing Machinery},
	author = {Buschmann, Philippe and Shorim, Mostafa H. M. and Helm, Max and Bröring, Arne and Carle, Georg},
	urldate = {2024-01-29},
	date = {2023-01-05},
	keywords = {Internet of Things ({IoT}), Edge Computing, Deep Reinforcement Learning, Integer Linear Programming, Particle Swarm Optimization, Task Allocation},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\3KPI94EF\\Buschmann et al. - 2023 - Task Allocation in Industrial Edge Networks with P.pdf:application/pdf},
}


@inproceedings{zhang_pedestrian_2023,
	location = {New York, {NY}, {USA}},
	title = {Pedestrian recognition method based on Jetson nano},
	isbn = {9798400708015},
	url = {https://dl.acm.org/doi/10.1145/3617695.3617715},
	doi = {10.1145/3617695.3617715},
	series = {{BDIOT} '23},
	abstract = {This paper presents a novel pedestrian recognition method based on Jetson Nano, leveraging its advantages as an edge computing device with low latency and high privacy. Traditional methods for pedestrian recognition often require substantial computing resources and a strong network connection, making them unsuitable for edge devices. Thus, this paper proposes an edge computing method specifically designed for Jetson Nano, utilizing {CUDA} and {TensorRT} to achieve higher performance. This method utilizes a convolutional neural network to extract image features, which are then activated through Reshape, Transpose, and Sigmoid functions. The Slice operation is employed to extract objects within areas with relatively high probabilities. The position of the object is then adjusted using mathematical operations such as Mul, Sub, Add, Pow, etc., resulting in more accurate detection results. This paper demonstrates the effectiveness of using Jetson Nano as an edge computing device for pedestrian recognition and the potential of {CUDA} and {TensorRT} for optimizing performance on edge devices. The proposed method has broad applications in various fields, such as surveillance systems, autonomous vehicles, and robotics, where real-time pedestrian recognition tasks are essential.},
	pages = {93--97},
	booktitle = {Proceedings of the 2023 7th International Conference on Big Data and Internet of Things},
	publisher = {Association for Computing Machinery},
	author = {Zhang, Lemei and Xin, Yu and Zhang, Letao},
	urldate = {2024-01-29},
	date = {2023-11-02},
	keywords = {Edge Computing, Artificial Intelligence, {CUDA}, Jetson Nano, Neural Network},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\A77EQMQW\\Zhang et al. - 2023 - Pedestrian recognition method based on Jetson nano.pdf:application/pdf},
}

@article{picano_channel-aware_2023,
	title = {A Channel-aware {FL} Approach for Virtual Machine Placement in 6G Edge Intelligent Ecosystems},
	volume = {4},
	url = {https://dl.acm.org/doi/10.1145/3584705},
	doi = {10.1145/3584705},
	abstract = {This article deals with an artificial intelligence ({AI}) framework to support Internet-of-everything ({IoE}) applications over sixth-generation wireless (6G) networks. An integrated {IoE}-Edge Intelligence ecosystem is designed to effectively face the problems of Virtual Machines ({VMs}) placement based on their popularity, computation offloading optimization, and system reliability improvement predicting compute nodes faults. The main objective of the article is to increase performance in terms of minimization of worst end-to-end (e2e) delay, percentage of requests in outage, and the enhancement of reliability. The article focuses on the following main issues: (i) proposal of a channel-aware federated learning ({FL}) approach to forecast the popularity of the {VMs} required by {IoE} devices; (ii) use of an {AI}-based channel conditions forecasting module at the benefits of the {FL} process; (iii) development of a suitable {VMs} placement on the basis of their popularity and of an efficient tasks allocation technique based on a modified version of the auction theory ({AT}) and a proper matching game; (iv) enhancement of the system reliability by an echo-state-network ({ESN}), located on each computation node and running in the background to predict failures and anticipate tasks migration. Numerical results validate the effectiveness of the proposed strategy for {IoE} applications over 6G networks.},
	pages = {12:1--12:20},
	number = {2},
	journaltitle = {{ACM} Transactions on Internet of Things},
	shortjournal = {{ACM} Trans. Internet Things},
	author = {Picano, Benedetta and Fantacci, Romano},
	urldate = {2024-01-29},
	date = {2023-05-13},
	keywords = {offloading, Machine learning, placement},
	file = {Full text:C\:\\Users\\Emanuele\\Zotero\\storage\\JCTAJG25\\Picano e Fantacci - 2023 - A Channel-aware FL Approach for Virtual Machine Pl.pdf:application/pdf},
}

@inproceedings{melancon_blazeflow_2023,
	location = {New York, {NY}, {USA}},
	title = {{BlazeFlow}: a Multi-Layer Communication Middleware for Real-Time Distributed {IoT} Applications},
	isbn = {9798400704574},
	url = {https://dl.acm.org/doi/10.1145/3631309.3632837},
	doi = {10.1145/3631309.3632837},
	series = {Mid4CC '23},
	shorttitle = {{BlazeFlow}},
	abstract = {The Internet of Things landscape has grown steadily over the last decade, fueling digital transformation. Data is now regarded as a precious asset. As a result, many companies have shifted their operations to the cloud to avoid maintaining massive infrastructure to hold and process all the data. However, in many settings, sending all the raw data to the cloud for processing and storage is not possible due to the unreliability of wide-area connectivity, coupled with the high costs of data transfer, storage, and processing. Also, some applications exhibit stringent response-time requirements. Edge computing can mitigate some of these issues, but it also has some drawbacks. This paper presents {BlazeFlow}, our vision of a multilayer data flow solution that can transport data to and from any layer of the cloud-to-device continuum based on publish-subscribe abstractions. {BlazeFlow} handles data flows between different services deployed onto the same node, between different devices of the same layer, and between different layers (edge, fog, and cloud). This is realized by a cross-layer common bridging solution that can automatically aggregate various protocols that are appropriate for each layer/device (e.g., {ROS}2, {MQTT}, Redis, and Kafka). {BlazeFlow} is designed to support bandwidth-intensive and time-critical services deployed at the various layers of the system. We evaluate a preliminary design of {BlazeFlow} over an autonomous robotics use case, and we show that it can sustain multi-layer data lows at a high frequency and with a low latency.},
	pages = {30--35},
	booktitle = {Proceedings of the 1st International Workshop on Middleware for the Computing Continuum},
	publisher = {Association for Computing Machinery},
	author = {Melançon, Cédric and Simard, Guillaume and Saad, Maarouf and Kaur, Kuljeet and Gascon-Samson, Julien},
	urldate = {2024-01-29},
	date = {2023-12-11},
	keywords = {{IoT}, cloud, edge, autonomous robot, fog, real-time},
	file = {Full Text PDF:C\:\\Users\\Emanuele\\Zotero\\storage\\47UPDCJ5\\Melançon et al. - 2023 - BlazeFlow a Multi-Layer Communication Middleware .pdf:application/pdf},
}

 @inproceedings{li2016mobile,
  title={Mobile edge computing: Progress and challenges},
  author={Li, Hongxing and Shou, Guochu and Hu, Yihong and Guo, Zhigang},
  booktitle={2016 4th IEEE international conference on mobile cloud computing, services, and engineering (MobileCloud)},
  pages={83--84},
  year={2016},
  organization={IEEE}
}

@article{banabilah_federated_2022,
	title = {Federated learning review: {Fundamentals}, enabling technologies, and future applications},
	volume = {59},
	issn = {0306-4573},
	shorttitle = {Federated learning review},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457322001649},
	doi = {10.1016/j.ipm.2022.103061},
	abstract = {Federated Learning (FL) has been foundational in improving the performance of a wide range of applications since it was first introduced by Google. Some of the most prominent and commonly used FL-powered applications are Android’s Gboard for predictive text and Google Assistant. FL can be defined as a setting that makes on-device, collaborative Machine Learning possible. A wide range of literature has studied FL technical considerations, frameworks, and limitations with several works presenting a survey of the prominent literature on FL. However, prior surveys have focused on technical considerations and challenges of FL, and there has been a limitation in more recent work that presents a comprehensive overview of the status and future trends of FL in applications and markets. In this survey, we introduce the basic fundamentals of FL, describing its underlying technologies, architectures, system challenges, and privacy-preserving methods. More importantly, the contribution of this work is in scoping a wide variety of FL current applications and future trends in technology and markets today. We present a classification and clustering of literature progress in FL in application to technologies including Artificial Intelligence, Internet of Things, blockchain, Natural Language Processing, autonomous vehicles, and resource allocation, as well as in application to market use cases in domains of Data Science, healthcare, education, and industry. We discuss future open directions and challenges in FL within recommendation engines, autonomous vehicles, IoT, battery management, privacy, fairness, personalization, and the role of FL for governments and public sectors. By presenting a comprehensive review of the status and prospects of FL, this work serves as a reference point for researchers and practitioners to explore FL applications under a wide range of domains.},
	number = {6},
	urldate = {2023-11-27},
	journal = {Information Processing \& Management},
	author = {Banabilah, Syreen and Aloqaily, Moayad and Alsayed, Eitaa and Malik, Nida and Jararweh, Yaser},
	month = nov,
	year = {2022},
	keywords = {Federated learning, Machine learning, Data privacy, Distributed learning, Data security, Decentralized learning, Mobile edge networks},
	pages = {103061},
	file = {Banabilah et al. - 2022 - Federated learning review Fundamentals, enabling .pdf:C\:\\Users\\Emanuele\\Zotero\\storage\\LV5PI4RQ\\Banabilah et al. - 2022 - Federated learning review Fundamentals, enabling .pdf:application/pdf},
}

@article{h_review_2021,
	title = {A {Review} on {Fog} {Computing}: {Architecture}, {Fog} with {IoT}, {Algorithms} and {Research} {Challenges}},
	volume = {7},
	issn = {24059595},
	shorttitle = {A {Review} on {Fog} {Computing}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2405959521000606},
	doi = {10.1016/j.icte.2021.05.004},
	abstract = {With the increasing advancement in the applications of the Internet of Things (IoT), the integrated Cloud Computing (CC) faces numerous threats such as performance, security, latency, and network breakdown. With the discovery of Fog Computing these issues are addressed by taking CC nearer to the Internet of Things (IoT). The key functionality of the fog is to provide the data generated by the IoT devices near the edge. Processing of the data and data storage is done locally at the fog node rather than moving the information to the cloud server. In comparison with the cloud, Fog Computing delivers services with high quality and quick response time. Hence, Fog Computing might be the optimal option to allow the Internet of Things to deliver an efficient and highly secured service to numerous IoT clients. It allows the administration of the services and resource provisioning outside CC, nearer to devices, at the network edge, or ultimately at places specified by Service Level Agreements (SLA’s). Fog Computing is not a replacement to CC, but a prevailing component. It allows the processing of the information at the edge though still delivering the option to connect with the data center of the cloud. In this paper, we put forward various computing paradigms, features of fog computing, an in-depth reference architecture of fog with its various levels, a detailed analysis of fog with IoT, various fog system algorithms and also systematically examine the challenges in Fog Computing which acts as a middle layer between IoT sensors or devices and data centers of the cloud.},
	language = {en},
	number = {2},
	urldate = {2024-03-07},
	journal = {ICT Express},
	author = {H., Sabireen and V., Neelanarayanan},
	month = jun,
	year = {2021},
	pages = {162--176},
	file = {H. e V. - 2021 - A Review on Fog Computing Architecture, Fog with .pdf:C\:\\Users\\PC - Vera\\Zotero\\storage\\KXZW7NDX\\H. e V. - 2021 - A Review on Fog Computing Architecture, Fog with .pdf:application/pdf},
}

@article{tange_systematic_2020,
	title = {A {Systematic} {Survey} of {Industrial} {Internet} of {Things} {Security}: {Requirements} and {Fog} {Computing} {Opportunities}},
	volume = {22},
	issn = {1553-877X, 2373-745X},
	shorttitle = {A {Systematic} {Survey} of {Industrial} {Internet} of {Things} {Security}},
	url = {https://ieeexplore.ieee.org/document/9146364/},
	doi = {10.1109/COMST.2020.3011208},
	abstract = {A key application of the Internet of Things (IoT) paradigm lies within industrial contexts. Indeed, the emerging Industrial Internet of Things (IIoT), commonly referred to as Industry 4.0, promises to revolutionize production and manufacturing through the use of large numbers of networked embedded sensing devices, and the combination of emerging computing technologies, such as Fog/Cloud Computing and Artiﬁcial Intelligence. The IIoT is characterized by an increased degree of inter-connectivity, which not only creates opportunities for the industries that adopt it, but also for cyber-criminals. Indeed, IoT security currently represents one of the major obstacles that prevent the widespread adoption of IIoT technology. Unsurprisingly, such concerns led to an exponential growth of published research over the last few years. To get an overview of the ﬁeld, we deem it important to systematically survey the academic literature so far, and distill from it various security requirements as well as their popularity. This paper consists of two contributions: our primary contribution is a systematic review of the literature over the period 2011-2019 on IIoT Security, focusing in particular on the security requirements of the IIoT. Our secondary contribution is a reﬂection on how the relatively new paradigm of Fog computing can be leveraged to address these requirements, and thus improve the security of the IIoT.},
	language = {en},
	number = {4},
	urldate = {2024-03-07},
	journal = {IEEE Communications Surveys \& Tutorials},
	author = {Tange, Koen and De Donno, Michele and Fafoutis, Xenofon and Dragoni, Nicola},
	year = {2020},
	pages = {2489--2520},
	file = {Tange et al. - 2020 - A Systematic Survey of Industrial Internet of Thin.pdf:C\:\\Users\\PC - Vera\\Zotero\\storage\\XKPPGZ4U\\Tange et al. - 2020 - A Systematic Survey of Industrial Internet of Thin.pdf:application/pdf},
}

@article{iftikhar_ai-based_2023,
	title = {{AI}-based fog and edge computing: {A} systematic review, taxonomy and future directions},
	volume = {21},
	issn = {25426605},
	shorttitle = {{AI}-based fog and edge computing},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S254266052200155X},
	doi = {10.1016/j.iot.2022.100674},
	language = {en},
	urldate = {2024-03-07},
	journal = {Internet of Things},
	author = {Iftikhar, Sundas and Gill, Sukhpal Singh and Song, Chenghao and Xu, Minxian and Aslanpour, Mohammad Sadegh and Toosi, Adel N. and Du, Junhui and Wu, Huaming and Ghosh, Shreya and Chowdhury, Deepraj and Golec, Muhammed and Kumar, Mohit and Abdelmoniem, Ahmed M. and Cuadrado, Felix and Varghese, Blesson and Rana, Omer and Dustdar, Schahram and Uhlig, Steve},
	month = apr,
	year = {2023},
	pages = {100674},
	file = {Iftikhar et al. - 2023 - AI-based fog and edge computing A systematic revi.pdf:C\:\\Users\\PC - Vera\\Zotero\\storage\\UU3F8HCN\\Iftikhar et al. - 2023 - AI-based fog and edge computing A systematic revi.pdf:application/pdf},
}


@article{lu_edge_2023,
	title = {Edge {Computing} on {IoT} for {Machine} {Signal} {Processing} and {Fault} {Diagnosis}: {A} {Review}},
	volume = {10},
	issn = {2327-4662, 2372-2541},
	shorttitle = {Edge {Computing} on {IoT} for {Machine} {Signal} {Processing} and {Fault} {Diagnosis}},
	url = {https://ieeexplore.ieee.org/document/10026418/},
	doi = {10.1109/JIOT.2023.3239944},
	abstract = {Edge computing is an emerging paradigm that ofﬂoads the computations and analytics workloads onto the Internet of Things (IoT) edge devices to accelerate the computation efﬁciency, reduce the channel occupation of signal transmission, and reduce the storage and computation workloads on the cloud servers. These distinct merits make it a promising tool for IoT-based machine signal processing and fault diagnosis. This article reviews the edge computing methods in signal processing-based machine fault diagnosis from the aspects of concepts, state-of-the-art methods, case studies, and research prospects. In particular, the lightweight designed algorithms and application-speciﬁc hardware platforms of edge computing in the typical fault diagnosis procedures, including signal acquisition, signal preprocessing, feature extraction, and pattern recognition, are reviewed and discussed in detail. The review provides an insight into the edge computing framework, methods, and applications, so as to meet the requirements of IoT-based machine real-time signal processing, low-latency fault diagnosis, and high-efﬁcient predictive maintenance.},
	language = {en},
	number = {13},
	urldate = {2024-03-07},
	journal = {IEEE Internet of Things Journal},
	author = {Lu, Siliang and Lu, Jingfeng and An, Kang and Wang, Xiaoxian and He, Qingbo},
	month = jul,
	year = {2023},
	pages = {11093--11116},
	file = {Lu et al. - 2023 - Edge Computing on IoT for Machine Signal Processin.pdf:C\:\\Users\\PC - Vera\\Zotero\\storage\\I3UI8PXX\\Lu et al. - 2023 - Edge Computing on IoT for Machine Signal Processin.pdf:application/pdf},
}

@article{amin_edge_2021,
	title = {Edge {Intelligence} and {Internet} of {Things} in {Healthcare}: {A} {Survey}},
	volume = {9},
	issn = {2169-3536},
	shorttitle = {Edge {Intelligence} and {Internet} of {Things} in {Healthcare}},
	url = {https://ieeexplore.ieee.org/document/9294145/},
	doi = {10.1109/ACCESS.2020.3045115},
	abstract = {With the advent of new technologies and the fast pace of human life, patients today require a sophisticated and advanced smart healthcare framework that is tailored to suit their individual health requirements. Along with 5G and state-of-the-art smart Internet of Things (IoT) sensors, edge computing provides intelligent, real-time healthcare solutions that satisfy energy consumption and latency criteria. Earlier surveys on smart healthcare systems were centered on cloud and fog computing architectures, security, and authentication, and the types of sensors and devices used in edge computing frameworks. They did not focus on the healthcare IoT applications deployed within edge computing architectures. The ﬁrst purpose of this study is to analyze the existing and evolving edge computing architectures and techniques for smart healthcare and recognize the demands and challenges of different application scenarios. We examine edge intelligence that targets health data classiﬁcation with the tracking and identiﬁcation of vital signs using state-of-the-art deep learning techniques. This study also presents a comprehensive analysis of the use of cutting-edge artiﬁcial intelligence-based classiﬁcation and prediction techniques employed for edge intelligence. Even with its many advantages, edge intelligence poses challenges related to computational complexity and security. To offer a higher quality of life to patients, potential research recommendations for improving edge computing services for healthcare are identiﬁed in this study. This study also offers a brief overview of the general usage of IoT solutions in edge platforms for medical treatment and healthcare.},
	language = {en},
	urldate = {2024-03-07},
	journal = {IEEE Access},
	author = {Amin, Syed Umar and Hossain, M. Shamim},
	year = {2021},
	pages = {45--59},
	file = {Amin e Hossain - 2021 - Edge Intelligence and Internet of Things in Health.pdf:C\:\\Users\\PC - Vera\\Zotero\\storage\\LJ45YQPP\\Amin e Hossain - 2021 - Edge Intelligence and Internet of Things in Health.pdf:application/pdf},
}

@article{hamdan_edge-computing_2020,
	title = {Edge-{Computing} {Architectures} for {Internet} of {Things} {Applications}: {A} {Survey}},
	volume = {20},
	issn = {1424-8220},
	shorttitle = {Edge-{Computing} {Architectures} for {Internet} of {Things} {Applications}},
	url = {https://www.mdpi.com/1424-8220/20/22/6441},
	doi = {10.3390/s20226441},
	abstract = {The rapid growth of the Internet of Things (IoT) applications and their interference with our daily life tasks have led to a large number of IoT devices and enormous sizes of IoT-generated data. The resources of IoT devices are limited; therefore, the processing and storing IoT data in these devices are inefﬁcient. Traditional cloud-computing resources are used to partially handle some of the IoT resource-limitation issues; however, using the resources in cloud centers leads to other issues, such as latency in time-critical IoT applications. Therefore, edge-cloud-computing technology has recently evolved. This technology allows for data processing and storage at the edge of the network. This paper studies, in-depth, edge-computing architectures for IoT (ECAs-IoT), and then classiﬁes them according to different factors such as data placement, orchestration services, security, and big data. Besides, the paper studies each architecture in depth and compares them according to various features. Additionally, ECAs-IoT is mapped according to two existing IoT layered models, which helps in identifying the capabilities, features, and gaps of every architecture. Moreover, the paper presents the most important limitations of existing ECAs-IoT and recommends solutions to them. Furthermore, this survey details the IoT applications in the edge-computing domain. Lastly, the paper recommends four different scenarios for using ECAs-IoT by IoT applications.},
	language = {en},
	number = {22},
	urldate = {2024-03-07},
	journal = {Sensors},
	author = {Hamdan, Salam and Ayyash, Moussa and Almajali, Sufyan},
	month = nov,
	year = {2020},
	pages = {6441},
	file = {Hamdan et al. - 2020 - Edge-Computing Architectures for Internet of Thing.pdf:C\:\\Users\\PC - Vera\\Zotero\\storage\\P6XDMTDW\\Hamdan et al. - 2020 - Edge-Computing Architectures for Internet of Thing.pdf:application/pdf},
}

@article{ali_comprehensive_2022,
	title = {A {Comprehensive} {Review} of {Internet} of {Things}: {Technology} {Stack}, {Middlewares}, and {Fog}/{Edge} {Computing} {Interface}},
	volume = {22},
	issn = {1424-8220},
	shorttitle = {A {Comprehensive} {Review} of {Internet} of {Things}},
	url = {https://www.mdpi.com/1424-8220/22/3/995},
	doi = {10.3390/s22030995},
	abstract = {The Internet of Things (IoT) is an extensive network of heterogeneous devices that provides an array of innovative applications and services. IoT networks enable the integration of data and services to seamlessly interconnect the cyber and physical systems. However, the heterogeneity of devices, underlying technologies and lack of standardization pose critical challenges in this domain. On account of these challenges, this research article aims to provide a comprehensive overview of the enabling technologies and standards that build up the IoT technology stack. First, a layered architecture approach is presented where the state-of-the-art research and open challenges are discussed at every layer. Next, this research article focuses on the role of middleware platforms in IoT application development and integration. Furthermore, this article addresses the open challenges and provides comprehensive steps towards IoT stack optimization. Finally, the interfacing of Fog/Edge Networks to IoT technology stack is thoroughly investigated by discussing the current research and open challenges in this domain. The main scope of this study is to provide a comprehensive review into IoT technology (the horizontal fabric), the associated middleware and networks required to build future proof applications (the vertical markets).},
	language = {en},
	number = {3},
	urldate = {2024-03-07},
	journal = {Sensors},
	author = {Ali, Omer and Ishak, Mohamad Khairi and Bhatti, Muhammad Kamran Liaquat and Khan, Imran and Kim, Ki-Il},
	month = jan,
	year = {2022},
	pages = {995},
	file = {Ali et al. - 2022 - A Comprehensive Review of Internet of Things Tech.pdf:C\:\\Users\\PC - Vera\\Zotero\\storage\\4UGDM6Z6\\Ali et al. - 2022 - A Comprehensive Review of Internet of Things Tech.pdf:application/pdf},
}

@article{apat_comprehensive_2023,
	title = {A comprehensive review on {Internet} of {Things} application placement in {Fog} computing environment},
	volume = {23},
	issn = {25426605},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2542660523001890},
	doi = {10.1016/j.iot.2023.100866},
	abstract = {With the rise in Internet of Things (IoT) technology in recent years the amount of resource requirement of various IoT applications substantially increases. The data generated by various geo-distributed IoT devices is growing continuously. The existing IoT–Cloud paradigm limits the number of various emergent IoT applications as per the requirement. To utilize various IoT applications effectively and efficiently resource decentralization mechanism is a time of need. Fog computing is a novel computing approach for various IoT applications, specifically timesensitive. Though, the resource-constrained nature of Fog devices in the fog computing model certainly fails to cater to multiple services for these IoT applications. The heterogeneity and dynamicity of the application request from the IoT devices need a quick decision regarding the placement of the application in the fog layer. Hence, optimal allocation of resources is quite essential for providing uninterrupted services to the end-users. This article comprehensively analyzes the different types of possible IoT application models and strategies for allocating resources to these applications. Since the resource allocation problem has already been proven to be a computationally NP-hard problem, finding a non-deterministic algorithm for allocating resources is our target. In this article, we have taken the IoT application placement problem in fog computing (APFC) as a single and multiple objective optimization problems. We have conducted a survey based on single and multiple objectives to address other possible issues in APFC. Finally, the challenges and promising directions for further research are presented.},
	language = {en},
	urldate = {2024-03-07},
	journal = {Internet of Things},
	author = {Apat, Hemant Kumar and Nayak, Rashmiranjan and Sahoo, Bibhudatta},
	month = oct,
	year = {2023},
	pages = {100866},
	file = {Apat et al. - 2023 - A comprehensive review on Internet of Things appli.pdf:C\:\\Users\\PC - Vera\\Zotero\\storage\\B9FHLW4N\\Apat et al. - 2023 - A comprehensive review on Internet of Things appli.pdf:application/pdf},
}
